\abstract{확률론은 20세기 들어 급격하게 발전한 분야이다. 애초에 확률이라는 개념이 수학에 편입된 것이 그리 오래되지 않았다. 이는 \texttt{Descart}의 연역주의의 영향이 진하게 남아있던 근대 유럽의 수학에서 불확실성을 다루기를 꺼려했기 때문이다. 오죽했으면 ``거의 확실한 것은 거의 확실히 거짓이다.''라고까지 했을까. 하지만 도박 문제(\texttt{de M\'er\'e's problem})와 같이 불확실성을 계량하여 다루어야 할 필요성은 조금씩 늘어갔고, 이러한 현실적 요구에 확률은 \texttt{Pascal}, \texttt{Fermat}, \texttt{Lagrange} 등의 기라성같은 수학자들에 의해 조금씩 건드려지기 시작했다. 이때까지만 하더라도 확률이 무엇인지에 대한 수학자들의 생각은 `어떤 사건이 발생할 가능성' 정도였다. 이러한 확률의 의미가 직관적으로 분명하였기에 이에 의문을 제기하는 사람도 없었고, 그럴 필요도 느끼지 못했다. 그러나 미적분학에서 극한의 개념이 그러하였듯, 확률에 대한 연구가 계속될수록 미묘한 잡음이 발생하기 시작했고, 이는 확률의 개념에 대한 엄밀한 수학적 접근이 필요함을 암시했다. 결국 `확률은 무엇인가?'라는 질문의 답을 찾기 위한 긴 여정이 시작되었고, \texttt{Laplace}가 확률에 해석학을 끼얹은 것을 시작으로 \texttt{Kolomogorov}가 그의 명저 \textit{\texttt{Grundbegriffe der Wahrscheinlichkeitsrechnung}}(영어: \texttt{\textit{Foundations of the Theory of Probability}})에서 측도론으로 확률을 정의하면서 그 여정은 일단락되게 된다. 본 장에서는 그 여정의 끝에서 수학자들이 괘뚫어본 확률의 본질에 대해 살펴보도록 하자.}

\section{Probability Spaces}

단도직입적으로 말하면, 확률은 측도의 특별한 한 종류에 불과하다. 곧 확률은 일종의 넓이나 부피와 같은 개념으로 무언가를 재는 역할을 한다. 현실적인 의미를 생각하면 `가능성'을 잰다고도 할 수 있겠다.

\begin{definition}
    측도공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 $\mathbb{P}(\Omega)=1$이면 이때의 유한 측도 $\mathbb{P}$를 \textbf{확률측도(\texttt{probability measure})}라 하고, 유한 측도공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$를 \textbf{확률공간(\texttt{probability space})}이라 한다. 나아가 집합 $\Omega$를 \textbf{표본공간(\texttt{sample space})}이라 하고, $\sigma$-대수 $\mathcal{F}$에 속하는 임의의 집합 $E$를 \textbf{사건(\texttt{event})}이라 하여 $\mathbb{P}(E)$의 값을 사건 $E$의 \textbf{확률(\texttt{probability})}이라 한다.
\end{definition}

확률의 본질이 측도라는 위의 정의는 나름 설득력이 있다. 그렇다면 이걸로 다 된 것일까? 아쉽게도 이제부터 해야 할 일이 태산이다. 일단 위의 정의를 받아들이기로 했다면, 지금까지 우리가 배웠던 확률의 대한 모든 내용들을 측도론의 언어로 다시 써야 한다. 곧 확률론을 다루는 본 장의 내용은 기본적으로 `번역 작업'으로, 다행히 대부분의 경우 이 번역 작업은 크게 어렵지 않을 것이다. 이는 측도론이 확률의 내용들을 형식화하기에 좋은 이론이라서이기도 하지만, 앞서 우리가 측도론을 배우며 이 순간을 위해 조금씩 준비해 둔 것들이 꽤 많기 때문이다.

본격적으로 시작하기에 앞서, 맥락상 다소 뜬금없기는 하지만, 우리의 확률에 대한 인식의 근간을 이루는 \texttt{equally likely outcome model}을 한 번은 언급하고 지나가는 것이 좋을 것 같다. 고등학교에서 경우의 수를 세는 문제로 흔히 접하는 \texttt{equally likely outcome model}은 표본공간으로 항상 유한집합 $\Omega$를 가지고, 이의 모든 부분집합은 사건으로 간주된다. 나아가 한원소 집합인 사건은 특별히 \textbf{근원사건(\texttt{elementary event})}이라 불리며 각 근원사건의 확률은 정확히 $1/|\Omega|$로 주어진다. (이렇게 각 근원사건의 확률이 같으므로 `\texttt{equally likely}'이다. 고등학교에서는 흔히 `같은 정도로 확실하다'로 번역한다.) 이러한 \texttt{setting}에서 우리는 임의의 사건 $E$의 확률을 $|E|/|\Omega|$로 정하고, 여기서의 $|E|$를 구하기 위해 여태껏 경우의 수를 열심히 계산하여 왔다. 이상의 내용을 측도론의 언어로 담백하게 번역하면 \texttt{equally likely outcome model}은 `표본공간 $\Omega$에서의 셈측도 $\#$에 대해 $(\Omega,\,\mathcal{P}(\Omega),\,\#/|\Omega|)$로 주어진 확률공간'이 된다. 곧 측도론으로 바라보면 \texttt{equally likely outcome model}도 측도공간의 특별한 한 종류에 불과하다.

보통 초급 확률론 교재에서는 고등학교에서와 마찬가지로 이 \texttt{equally likely outcome model}에 집중하여 경우의 수를 계산하는 화려한 기교를 소개하는 데 많은 분량을 할애하곤 하지만, 여기서는 이에 대한 논의는 Sheldon Ross의 A First Course in Probability를 참고문헌으로 실어두는 것으로 대신한다. 우리는 일반적인 이론의 전개를 목표로 하기에 확률공간의 한 예시에 불과한 \texttt{equally likely outcome model}에 대해서는 그다지 관심이 없고, 곧 이 책에서 \texttt{equally likely outcome model}이 다시 등장하는 일은 (아마) 없을 것이다. 또한, 일반적으로 표본공간 위의 $\sigma$-대수 $\mathcal{F}$가 모든 한원소 집합을 포함한다는 보장이 없으므로 근원사건이라는 개념도 딱히 쓸모가 없을 것이다.

다시 원래의 이야기로 돌아와, 본격적으로 번역 작업을 시작해보자. 우선 확률의 기본적인 성질 정도는 측도의 성질로부터 거의 자명하게 얻어진다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건 $E,\,F$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $\mathbb{P}(\emptyset)=0$.
        \item ($\sigma$-가법성) 서로소인 사건열 $\{E_i\}$에 대해 $\mathbb{P}(\bigsqcup_{i=1}^\infty E_i)=\sum_{i=1}^\infty\mathbb{P}(E_i)$이다.
        \item $0\leq\mathbb{P}(E)\leq1$.
        \item $\mathbb{P}(E^c)=1-\mathbb{P}(E)$.
        \item (단조성) 만약 $E\subseteq F$이면 $\mathbb{P}(E)\leq\mathbb{P}(F)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    이는 정의와 측도의 기본적인 성질로부터 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item (포함배제의 원리) 사건 $E_1,\,\cdots,\,E_l$에 대해
        \begin{equation*}
            \mathbb{P}\bigg(\bigcup_{i=1}^lE_i\bigg)=\sum_{i=1}^l(-1)^{i-1}\sum_{1\leq j_1<\cdots<j_i\leq l}\mathbb{P}\bigg(\bigcap_{k=1}^i E_{j_k}\bigg)
        \end{equation*}
        이다.
        \item ($\sigma$-반가법성) 사건열 $\{E_i\}$에 대해 $\mathbb{P}(\bigcup_{i=1}^\infty E_i)\leq\sum_{i=1}^\infty\mathbb{P}(E_i)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i는 측도론의 포함배제의 원리를 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 적용한 결과이고, ii는 측도의 $\sigma$-가법성이 $\sigma$-반가법성을 함의한다는 점에서 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건열 $\{E_i\}$에 대해 
    \begin{equation*}
        \mathbb{P}(\liminf_{i\to\infty}E_i)\leq\liminf_{i\to\infty}\mathbb{P}(E_i)\leq\limsup_{i\to\infty}\mathbb{P}(E_i)\leq\mathbb{P}(\limsup_{i\to\infty}E_i)
    \end{equation*}
    가 성립한다. 특별히, $E_i\to E$이면 $\mathbb{P}(E_i)\to\mathbb{P}(E)$이다.
\end{theorem}

\begin{proof}
    이는 정리 \ref{thm:generalSeriesMeasure}로부터 자명하다.
\end{proof}

위의 정리의 후단을 흔히 \textbf{확률측도의 연속성(\texttt{continuity of probability measure})}이라 한다. 한편, 확률론에서는 사건열 $\{E_i\}$에 대해 이의 상극한 $\limsup_{i\to\infty}E_i$를 간단히 $E_i\io$라 쓰기도 한다. 여기서 \texttt{io.}는 \texttt{infinitely often}의 줄임말로 곧 $\omega\in E_i\io$는 $\omega\in\Omega$가 사건 $E_1,\,E_2,\,\cdots$에 무한히 많이 속한다는 것인데, 이는 $\limsup_{i\to\infty}E_i=\bigcap_{j=1}^\infty\bigcup_{i=j}^\infty E_i$임을 생각해보면 나름 \texttt{make sense}하는 표기법이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 영집합인 사건을 \textbf{영사건(\texttt{null event})}이라 한다.
\end{definition}

확률측도도 측도이기에 `($\mathbb{P}$-)거의 어디서나'라는 개념이 자주 쓰이는데, 확률론에서는 이를 \textbf{($\mathbb{P}$-)거의 확실하게(($\mathbb{P}$-)\texttt{almost surely})}라 하기도 한다. 이는 영사건이 확률이 $0$인 사건이므로 어떤 성질이 $\mathbb{P}$-거의 어디서나 성립하면 곧 $1$의 확률로 성립하게 되기 때문에 생겨난 관례이다.

이와 관련하여 `확률이 $0$인 사건'과 `불가능한 사건'은 서로 다르다는 것에 주의할 필요가 있다. 확률인 $0$인 사건은 표본공간 위의 $\sigma$-대수 $\mathcal{F}$에 속하는 사건이지만 그 확률이 $0$일 뿐이고, 불가능한 사건은 애초에 $\mathcal{F}$에 속하지 않아 그 이름과는 달리 엄밀히는 사건이 아니다. 간단한 예시를 위해 $[0,\,1]$에서 임의로 점 하나를 택하는 상황을 생각해보자. 이를 확률공간으로 형식화한다면, 표본공간은 $\Omega=[0,\,1]$이고 $\mathcal{F}=\mathcal{B}_1\vert_\Omega$, 확률측도는 $\mathbb{P}=(\mu_1)_\mathcal{F}$ 정도로 둘 수 있을 것이다. 그렇다면 $\mathbb{P}\{0.5\}=0$이므로 정확히 $0.5$를 뽑는 사건은 확률이 $0$인 사건이지만, 그렇다고 이가 일어나는 것 자체가 불가능한 것은 아니다. 한편, $2$를 뽑는 사건은 애초에 발생이 불가능한 사건으로 이 경우에 $\{2\}\notin\mathcal{F}$이므로 이는 엄밀하게는 사건이 아니어서 확률의 부여가 불가능하다. 이와 비슷하게, `확률이 $1$인 사건'과 `항상 발생하는 사건'도 서로 다르다.

이어서, 조건부확률을 도입하고 그 성질을 측도론으로 보이자. 다만, 이후에 조건부기댓값과 조건부분포를 엄밀히 도입하기 위해서는 조건부확률의 개념을 격변에 준할 정도로 일반화시켜야 하는데, 이에 하나의 절을 오롯히 할애해야 할 정도의 논의가 필요하므로 여기에서는 아주 간단하게만 다루도록 한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 영사건이 아닌 사건 $E$에 대해 \textbf{사건 $E$에 대한 조건부확률(\texttt{conditional probability under event} $E$)}을  $\mathbb{P}(\cdot\vert E):\mathcal{F}\to\mathbb{R}^+_0$로 쓰고 $\mathbb{P}(\cdot\vert E):F\mapsto\mathbb{P}(F\cap E)/\mathbb{P}(E)$로 정의한다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 영사건이 아닌 사건 $E$에 대해 조건부확률 $\mathbb{P}(\cdot\vert E)$는 $(\Omega,\,\mathcal{F})$ 위의 확률측도이다. 따라서 $(\Omega,\,\mathcal{F},\,\mathbb{P}(\cdot\vert E))$는 확률공간을 이룬다.
\end{proposition}

\begin{proof}
    우선 $\mathbb{P}(\emptyset\vert E)=\mathbb{P}(\emptyset)/\mathbb{P}(E)=0,\,\mathbb{P}(\Omega\vert E)=\mathbb{P}(E)/\mathbb{P}(E)=1$임은 분명하고, 임의의 서로소인 사건열 $\{E_i\}$에 대해
    \begin{align*}
        \mathbb{P}\bigg(\bigsqcup_{i=1}^\infty E_i\vert E\bigg)&=\frac{\mathbb{P}(\bigsqcup_{i=1}^\infty E_i\cap E)}{\mathbb{P}(E)}\\
        &=\frac{\mathbb{P}(\bigsqcup_{i=1}^\infty(E_i\cap E))}{\mathbb{P}(E)}\\
        &=\sum_{i=1}^\infty\frac{\mathbb{P}(E_i\cap E)}{\mathbb{P}(E)}\\
        &=\sum_{i=1}^\infty\mathbb{P}(E_i\vert E)
    \end{align*}
    이므로 $\mathbb{P}(\cdot\vert E)$가 확률측도임을 안다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item 사건 $E$와 영사건이 아닌 사건 $F$에 대해 $\mathbb{P}(E\cap F)=\mathbb{P}(E\vert F)\mathbb{P}(F)$이다.
        \item (전확률 공식) 서로소인 가산개의 사건 $E_1,\,E_2,\,\cdots$에 대해 각 $E_i$가 영사건이 아니고 $\bigsqcup_{i=1}^kE_i=\Omega$이면 임의의 사건 $E$에 대해 $\mathbb{P}(E)=\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)$이다. (여기서 $k$는 유한할 수도 있고, $\infty$일 수도 있다.)
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 조건부확률의 정의로부터 자명하다.
    
    ii. i로부터 $\mathbb{P}(E)=\mathbb{P}(E\cap\bigsqcup_{i=1}^kE_i)=\mathbb{P}(\bigsqcup_{i=1}^k(E\cap E_i))=\sum_{i=1}^k\mathbb{P}(E\cap E_i)=\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)$이다.
\end{proof}

\begin{theorem}[Bayes]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 서로소인 가산개의 사건 $E_1,\,E_2,\,\cdots$에 대해 각 $E_i$가 영사건이 아니고 $\bigsqcup_{i=1}^kE_i=\Omega$이면 임의의 사건 $E$에 대해
    \begin{equation*}
        \mathbb{P}(E_1\vert E)=\frac{\mathbb{P}(E\vert E_1)\mathbb{P}(E_1)}{\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)}
    \end{equation*}
    이다. (여기서 $k$는 유한할 수도 있고, $\infty$일 수도 있다.)
\end{theorem}

\begin{proof}
    전확률 공식으로부터 $\mathbb{P}(E_1\vert E)=\mathbb{P}(E\cap E_1)/\mathbb{P}(E)=\mathbb{P}(E\vert E_1)\mathbb{P}(E_1)/\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)$가 자명하다.
\end{proof}

비록 증명은 간단하지만 \texttt{Bayes}의 정리는 실험적으로 구하는 것이 불가능한 조건부확률을 구하게 해준다는 엄청난 실용성과 함의를 지닌다. 쉽고 즐거운 예시를 위해 유리가 예나에게 휴대전화로 0x2661(\texttt{UTF-16} ♡)과 0x2665(\texttt{UTF-16} ♥) 중 하나의 정보를 임의로 전송하였는데, 송수신의 과정에서 정보의 일부가 손상되어 결과적으로 예나는 0x2663(\texttt{UTF-16} ♣)을 수신한 상황을 생각해보자. 이를 복원하기 위해 예나는 $E$를 0x2663을 수신하는 사건, $F,\,G$를 각각 0x2661과 0x2665를 전송하는 사건이라 두고 두 조건부확률 $\mathbb{P}(F\vert E)$와 $\mathbb{P}(G\vert E)$를 비교하여 전자가 더 크다면 0x2661로 복원하고 후자가 더 크다면 0x2665로 복원하며, 만약 같다면 재전송을 요청하기로 하였다. 이는 훌륭한 통계적 사고방식이지만 $\mathbb{P}(F\vert E)$와 $\mathbb{P}(G\vert E)$는 일의 선후가 뒤바뀐 확률이라 실험적으로 구할 수가 없다는 치명적인 문제가 있다. 예나가 자신의 휴대전화로 자신에게 0x2661과 0x2665를 수 회 전송하는 실험을 통해 근사하게나마 구할 수 있는 확률은 $\mathbb{P}(E\vert F)$와 $\mathbb{P}(E\vert G)$ 뿐이다. 여기서 \texttt{Bayes}의 정리는 $\mathbb{P}(F\vert E)$와 $\mathbb{P}(G\vert E)$를 $\mathbb{P}(E\vert F)$와 $\mathbb{P}(E\vert G)$의 조합으로써 계산할 수 있도록 하여 문제를 해결하는 결정적인 역할을 한다. 따라서 예나가 실험적으로 구한 $\mathbb{P}(E\vert F)$와 $\mathbb{P}(E\vert G)$의 근사치가 만약 $1/200,\,1/300$이었다면 \texttt{Bayes}의 정리로부터 $\mathbb{P}(F\vert E)\approx3/5,\,\mathbb{P}(G\vert E)\approx2/5$가 되어 ♣를 ♡로 복원할 수 있다. 요컨대, \texttt{Bayes}의 정리는 선후관계나 인과관계를 역전시켜주는 마법의 공식이다.

이러한 \texttt{Bayes} 정리는 이후 통계학에 큰 지각변동을 일으켜 이를 기초로 하는 \texttt{Bayesian}이라는 독자적인 학파가 구성되기에 이르렀고, 오늘날 기계학습과 같은 분야에서 요긴하게 쓰이는 모양이다. (이와 구분하여 기존의 통계학 학파를 빈도주의라 한다.) 물론, 이런 학파는 어디까지나 확률의 해석에 대한 차이로 구분되는 것이지 확률의 측도론적 정의나 접근방식으로 구분되는 것은 아니기에 빈도주의와 \texttt{Bayesian}의 구분이 본 장에서는 필요하지 않지만, 이 책에서는 특별한 언급이 없는 이상 빈도주의의 관점에서 확률을 바라본다. 여기에는 통계학 교양 정도를 들은 수준에서는 빈도주의의 관점이 \texttt{Bayesian}의 관점보다 조금 더 친숙하다는 것을 빼면 다른 그럴싸한 이유는 없다. 만약 자신이 \texttt{Bayesian}이라면 그들의 방식대로 해석하면 그만이고, 당연히 \texttt{Bayesian}에게도 측도론적인 엄밀한 확률론은 훌륭한 이론의 토대가 될 것이다.

이번 절에서 마지막으로 다룰 것은 바로 독립에 관한 내용인데, 앞서 확률의 기본적인 성질과 기본적인 조건부확률을 큰 어려움 없이 도입할 수 있었던 것과는 달리, 독립성을 측도론의 언어로 번역해 내는 것은 살짝 어렵다. 이는 독립이라는 개념이 측도론에서는 그 느낌조차 찾아보기 힘든, 완전히 새로운 개념이기 때문이다. 우리는 측도론에서 적분을 정의할 때와 비슷하게 독립을 그 정의를 점차 일반화시키는 방법으로 도입할 것이다. 우선 가장 기본적인 독립의 정의로 시작한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건 $E_1,\,\cdots,\,E_k$를 생각하자. 만약 각 $l\leq k$과 임의의 서로다른 $i_1,\,\cdots,\,i_l\leq k$에 대해 $\mathbb{P}(\bigcap_{j=1}^lE_{i_j})=\prod_{j=1}^l\mathbb{P}(E_{i_j})$가 성립하면 이때의 사건 $E_1,\,\cdots,\,E_k$를 \textbf{(서로) 독립((\texttt{mutually}) \texttt{independent})}이라 한다. 한편, 만약 위의 성질이 $l=2$에 대해서만 만족되면, 즉 임의의 서로다른 $i,\,j\leq k$에 대해서 $\mathbb{P}(E_i\cap E_j)=\mathbb{P}(E_i)\mathbb{P}(E_j)$가 성립하는 것에 그치면 이때의 사건 $E_1,\,\cdots,\,E_k$를 \textbf{\texttt{pairwise} 독립(- \texttt{independent})}이라 한다.
\end{definition}

서로 독립인 것과 \texttt{pairwise} 독립이 다르다는 사실은 잘 알려진 사실이다. 흔해빠진 주사위와 동전 예시를 피하기 위해 해석개론을 수강신청한 수지와 이제훈이 같이 밤새 과제를 하게 된 것을 계기로 서로 어느정도 이성으로서 호감을 가지게 된, 이른바 `썸 탄다' 불리우는 상황을 생각하자. 수업을 듣던 어느날, 수지와 이제훈의 교재가 실수로 서로 바뀌어 다음 수업시간 전에 만나 책을 다시 바꾸기로 하였는데, 둘은 이를 앞두고 책 사이에 고백편지를 살짝 끼워넣을까 고민하고 있다고 하자. 여기서 사건 $E,\,F$를 각각 수지와 이제훈이 고백편지를 끼워넣는 사건이라 하고, 수지나 이제훈이 고백편지를 넣을 확률은 $1/2$로 같으며 이는 서로 독립이라 하자. 이제 사건 $G$를 어느 한쪽만 고백편지를 받는 사건이라 하면 $E,\,F,\,G$는 \texttt{pairwise} 독립이지만 서로 독립은 아니다. (직접 계산해보자.)

한편, 유한개의 사건 사이의 독립을 무한개의 사건 사이의 독립으로 확장하는 것은 어렵지 않다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건의 모임 $\mathcal{C}$를 생각하자. 만약 임의의 사건 $E_1,\,\cdots,\,E_k\in\mathcal{C}$가 서로 독립이면 이때의 집합족 $\mathcal{C}$를 \textbf{독립(\texttt{independent})}이라 한다.
\end{definition}

다음으로, 유한개의 사건의 모임 사이의 독립을 정의한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건의 모임 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k$를 생각하자. 만약 각 $i\leq k$에 대해 임의로 택한 사건 $E_i\in\mathcal{C}_i$가 서로 독립이면 이때의 집합족 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k$를 \textbf{독립(\texttt{independent})}이라 한다.
\end{definition}

마지막으로 이를 무한개의 사건의 모임 사이의 독립으로까지 확장하면 독립의 가장 일반적인 정의를 얻는다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건의 모임의 모임 $\Gamma$를 생각하자. 만약 임의의 사건의 모임 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k\in\Gamma$가 서로 독립이면 이때의 집합족 $\Gamma$를 \textbf{독립(\texttt{independent})}이라 한다.
\end{definition}

이렇게까지 일반적인 형태의 독립성을 고려하는 이유는 다음 정리 때문이다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 독립인 사건의 모임의 모임 $\{\mathcal{C}_\alpha\}$에 대해 각 $\mathcal{C}_\alpha$가 $\pi$-\texttt{system}이라 하면 $\{\sigma(\mathcal{C}_\alpha)\}$는 독립이다.
\end{theorem}

\begin{proof}
    집합족 $\{\mathcal{C}_\alpha\}$에서 임의로 유한개의 원소를 택하여 이를 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k$라 하고 이들이 생성하는 $\sigma$-대수 $\sigma(\mathcal{C}_1),\,\cdots,\,\sigma(\mathcal{C}_k)$가 서로 독립임을 보이면 증명은 충분하다. 이를 위해 사건 $E_2\in\mathcal{C}_2,\,\cdots,\,E_k\in\mathcal{C}_k$를 임의로 택하고 집합족 $\mathcal{L}=\{F\in\mathcal{F}:F,\,E_2,\,\cdots,\,E_k\textrm{가 서로 독립}\}$을 생각하면 주어진 조건으로부터 $\mathcal{C}_1\subseteq\mathcal{L}$임은 분명하다. 나아가 $\Omega\in\mathcal{L}$ 또한 분명하고, 임의의 $F\in\mathcal{L}$에 대해 $F,\,E_2,\,\cdots,\,E_k$가 서로 독립이면 $F^c,\,E_2,\,\cdots,\,E_k$도 서로 독립임을 쉽게 보일 수 있으므로 $F^c\in\mathcal{L}$이다. 비슷한 방법으로 $\mathcal{L}$에 속하는 임의의 서로소인 사건열 $\{F_i\}$에 대해 $\bigsqcup_{i=1}^\infty F_i,\,E_2,\,\cdots,\,E_k$가 서로 독립임을 보일 수 있으므로 $\bigsqcup_{i=1}^\infty F_i\in\mathcal{L}$도 성립한다. 이로부터 $\mathcal{L}$은 $\lambda$-\texttt{system}이 되어 $\mathcal{C}_1$이 $\pi$-\texttt{system}이라는 사실과 \texttt{Dynkin}의 $\pi$-$\lambda$ 정리로부터 $\sigma(\mathcal{C}_1)=\lambda(\mathcal{C}_1)\subseteq\mathcal{L}$이고, 곧 $\sigma(\mathcal{C}_1),\,\mathcal{C}_2,\,\cdots,\,\mathcal{C}_k$는 서로 독립이다. 이제 이를 $k-1$번 반복하면 $\sigma(\mathcal{C}_1),\,\cdots,\,\sigma(\mathcal{C}_k)$가 서로 독립임을 보일 수 있고, 증명이 끝난다.
\end{proof}

위의 정리는 서로 독립인 사건의 모임들이 생성하는 $\sigma$-대수도 서로 독립임을 함의하는데, 잠시 이 결과의 의미에 대해 생각해보자. 독립성은 기본적으로 `정보'에 대한 이야기이다. 가장 기본적인 형태로 두 사건 $E,\,F$가 서로 독립인 경우를 살펴보면, 이는 사건 $E$의 발생여부에 대한 정보가 주어지더라도 사건 $F$의 발생여부에 대한 정보는 일체 추론해 낼 수 없음을 의미한다. 이는 2개 이상의 사건, 나아가 무한개의 사건의 독립에 대해서도 마찬가지이다. 예컨대 앞서 든 수지와 이제훈의 예시에서 $E,\,F,\,G$는 서로 독립이 아니었는데, 이는 수지가 고백편지를 넣는 사건 $E$와 이제훈이 고백편지를 넣는 사건 $F$의 발생여부에 대한 정보가 사건 $G$의 발생여부에 대한 정보를 100\% 함의하기 때문이다.

사건의 모임 사이의 독립도 이와 비슷하게 이해할 수 있다. 앞서 사건들 사이의 독립에서 각 사건은 그 사건의 발생여부에 대한 이진 정보를 의미했다. 그렇다면 사건의 모임은 그 모임에 속한 각 사건들의 발생여부에 대한 이진 정보의 조합으로 이루어진 보다 풍성한 정보로 이해하는 것이 자연스러울 것이다. 따라서 사건의 모임 사이의 독립은 각 사건의 모임이 함의하는 정보가 서로 독립적이라는, 즉 어느 하나를 알더라도 다른 하나를 일체 추론해내지 못한다는 것을 의미한다. 이러한 관점에서 보면, 위의 정리의 결과는 어떤 사건의 모임들이 함의하는 정보가 서로 추론이 불가능하다면, 각 모임을 그가 생성하는 $\sigma$-대수로 확장하여 훨씬 더 많은 정보로 얻어도, 여전히 서로 추론이 불가능함을 의미한다. 뭔가 자명한 듯 자명하지 않은 이 결과를 보다 효율적으로 쓰기 위해 따름정리 하나를 소개한다.

\begin{corollary}\label{cor:independence}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 가산개의 무한한 행과 열을 가지는 사건의 배열
    \begin{equation*}
        \begin{matrix}
            E_{11}&E_{12}&\cdots\\
            E_{21}&E_{22}&\cdots\\
            \vdots&\vdots&\ddots
        \end{matrix}
    \end{equation*}
    에 대해 $\{E_{ij}\}_{ij}$가 독립이라 하고, 각 $i\in\mathbb{N}$에 대해 집합족 $\mathcal{G}_i$를 $\{E_{ij}\}_j$가 생성하는 $\sigma$-대수라 하면 $\{\mathcal{G}_i\}$는 독립이다. 한편, 행이나 열의 개수가 유한한 경우에도 같은 결과가 성립하며, 나아가 각 행의 열의 개수가 달라도 가산개이기만 하면 여전히 같은 결과가 성립한다.
\end{corollary}

\begin{proof}
    각 $i\in\mathbb{N}$에 대해 $\{E_{ij}\}_j$의 모든 유한 교집합의 모임 $\mathcal{P}_i$를 생각하면 $\mathcal{P}_i$는 $\pi$-\texttt{system}이고 $\sigma(\mathcal{P}_i)=\mathcal{G}_i$임이 거의 분명하다. 따라서 $\{\mathcal{P}_i\}$가 서로 독립이라는 사실만 보이면 앞선 정리로부터 $\{\mathcal{G}_i\}$가 독립이 되어 증명이 끝난다. 이를 위해 $\{\mathcal{P}_i\}$에서 임의로 유한개의 원소를 택하여 이를 $\mathcal{P}_1,\,\cdots,\,\mathcal{P}_k$라 하고 다시 임의로 사건 $F_1\in\mathcal{P}_1,\,\cdots,\,F_k\in\mathcal{P}_k$를 택하면 각 $i\leq k$에 대해 $\mathcal{P}_i$의 구성으로부터 적당한 사건 $E_{i1},\,\cdots,\,E_{il_i}$가 존재하여 $F_i=\bigcap_{j=1}^{l_i}E_{ij}$이다. 그렇다면 $\{E_{ij}\}_{ij}$가 독립이라는 사실로부터 $\mathbb{P}(\bigcap_{i=1}^kF_i)=\mathbb{P}(\bigcap_{i=1}^k\bigcap_{j=1}^{l_i}E_{ij})=\prod_{i=1}^k\prod_{j=1}^{l_i}\mathbb{P}(E_{ij})=\prod_{i=1}^k\mathbb{P}(\bigcap_{j=1}^{l_i}E_{ij})=\prod_{i=1}^k\mathbb{P}(F_i)$가 되어 $\{\mathcal{P}_i\}$가 서로 독립임을 알고, 증명은 이로써 충분하다. 한편, 행이나 열의 개수가 유한하거나 각 행의 열의 수가 다른 경우에도 이와 비슷하게 하면 된다.
\end{proof}

이 따름정리를 적당히 응용하면 독립성에 대한 진부한 연습문제들, 예컨대 사건 $E,\,F,\,G,\,H$가 서로 독립이라면 $E\cap F$와 $G\setminus H$가 독립임을 보이라는 식의 문제들을 아주 깔끔하게 해결할 수 있다. 예시로 든 문제의 경우 배열 $E\,\,F//G\,\,H$를 생각하면 그만이다. 한편, 앞서 사건의 모임을 그에 포함된 각 사건의 발생여부로 구성된 정보의 집합으로 해석하였는데, 이는 독립의 경우에만 한정되는 해석이 아니어서 특히 그 모임이 $\sigma$-대수 $\mathcal{G}$인 경우 모든 사건의 집합 $\mathcal{F}$를 `전체 정보'로, $\mathcal{G}$는 이의 `부분 정보'로 해석하는 것이 유용한 경우가 많다.

나중을 위해 측도론에서 잠시 등장했던 \texttt{Borel-Cantelli}의 정리를 조금 보강하는 것으로 이번 절을 마친다.

\begin{theorem}[Borel-Cantelli]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건열 $\{E_i\}$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item 만약 $\sum_{i=1}^\infty\mathbb{P}(E_i)<\infty$이면 $\mathbb{P}(E_i\io)=0$이다.
        \item 만약 $\sum_{i=1}^\infty\mathbb{P}(E_i)=\infty$이고 $\{E_i\}$가 독립이면 $\mathbb{P}(E_i\io)=1$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 측도론에서 배운 \texttt{Borel-Cantelli}의 정리로부터 자명하다.

    ii. 우선 $\{E_i\}$가 독립이므로 따름정리 \ref{cor:independence}로부터 $\{E_i^c\}$도 독립이다. 이제 임의의 $\epsilon>0$과 임의의 $j\in\mathbb{N}$를 택하면 $\sum_{i=j}^\infty\mathbb{P}(E_i)=\infty$이므로 $\lim_{k\to\infty}\exp(-\sum_{i=j}^k\mathbb{P}(E_i))=0$이다. 이로부터 적당한 $k_0\in\mathbb{N}$가 존재하여 $k_0\geq j$이고 $\exp(-\sum_{i=j}^{k_0}\mathbb{P}(E_i))<\epsilon$이므로 $\mathbb{P}(\bigcap_{i=j}^{k_0}E_i^c)=\prod_{i=j}^{k_0}\mathbb{P}(E_i^c)=\prod_{i=j}^{k_0}[1-\mathbb{P}(E_i)]\leq\prod_{i=j}^{k_0}\exp(-\mathbb{P}(E_i))=\exp(-\sum_{i=j}^{k_0}\mathbb{P}(E_i))<\epsilon$이다. 이는 곧 $\mathbb{P}(\bigcap_{i=j}^\infty E_i^c)\leq\mathbb{P}(\bigcap_{i=j}^{k_0}E_i^c)<\epsilon$임을 뜻하므로 $\mathbb{P}(\bigcap_{i=j}^\infty E_i^c)=0$임을 알고, 이는 다시 $\mathbb{P}(E_i\io)=\mathbb{P}((\liminf_{i\to\infty} E_i^c)^c)=1-\mathbb{P}(\liminf_{i\to\infty} E_i^c)\geq1-\sum_{j=1}^\infty\mathbb{P}(\bigcap_{i=j}^\infty E_i^c)=1$에서 $\mathbb{P}(E_i\io)=1$임을 뜻한다.
\end{proof}

\section{Random Variables and Random Vectors}

앞선 절에서 사건 그 자체에 관련된 확률의 내용들을 측도론의 틀에 맞추어 열심히 옮겨 놓았으니, 이번 절에서는 확률벡터라는 개념을 추가하여 내용을 보다 풍성하게 만들어보도록 하자. 확률벡터를 통해 우리는 일일히 사건을 정의하지 않고도 확률의 여러 개념들을 편리하게 사용할 수 있다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 가측함수 $X:\Omega\to\mathbb{R}^n$를 \textbf{($n$차원) 확률벡터(($n$ \texttt{dimensional}) \texttt{random vector})}라 하고, 특별히 $n=1$이면 \textbf{확률변수(\texttt{random variable})}라 한다.
\end{definition}

확률벡터는 본질적으로 가측함수이기에 확률벡터의 기본적인 성질들이 가측함수의 성질들로부터 자명하게 성립하는 것이 전혀 이상하지 않다.

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 함수 $X:\Omega\to\mathbb{R}^n$에 대해 $X$가 \texttt{rv.}일 필요충분조건은 $X_1,\,\cdots,\,X_n$이 모두 \texttt{rv.}인 것이다.
\end{proposition}

\begin{proof}
    이는 벡터함수가 가측일 필요충분조건은 그 성분이 모두 가측인 것이라는 점에서 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^m$와 \texttt{Borel} 함수 $g:\mathbb{R}^m\to\mathbb{R}^n$에 대해 합성 $g\circ X:\Omega\to\mathbb{R}^n$도 \texttt{rv.}이다.
\end{theorem}

\begin{proof}
    이는 \texttt{Borel} 함수와 가측함수의 합성은 가측이라는 점에서 자명하다.
\end{proof}

정의상 확률벡터는 엄연히 함수이지만, 그 이름에서도 잘 드러나듯이 확률론에서는 이를 마치 변수처럼 생각하고 사용하는 경우가 많다. 이는 이론적인 이유에서라기보다 실생활의 응용에서 이렇게 생각하는 편이 조금 더 직관적으로 편하기 때문이다. 이러한 우리의 인식은 확률벡터와 관련된 여러 표기상의 관례에 잘 나타나는데, 위의 정리에서의 합성 $g\circ X$를 마치 $g$에 $X$라는 변수를 대입한 것으로 생각하여 $g(X)$로 쓰는 관례가 대표적인 예시이다. 그러나 이런 표기법은 어디까지나 관례일 뿐, 확률벡터가 변수가 아닌 함수라는 사실은 항상 염두에 두고 있어야 한다.

이어서, 측도론에서 \texttt{FTC}를 일반화하는 과정에서 잠시 스쳐 지나갔던 \texttt{pushfowarding}이 다시 등장한다. 비록 측도론에서의 \texttt{pushfowarding}은 도구 역할에 그쳤지만, 확률론에서의 \texttt{pushfowarding}은 빼놓을 수 없는 핵심적인 개념이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{pushfoward} 측도 $X_*\mathbb{P}$를 \texttt{rv.} $X$의 \textbf{분포(\texttt{distribution})}라 하고 $\prob_X$로 쓴다. 특별히, $n\geq2$인 경우 $\prob_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합분포(\texttt{joint distribution})}라 하기도 한다.
\end{definition}

교양 통계학에서 배운 \texttt{PDF}나 \texttt{\texttt{CDF}}를 비롯하여 확률론에는 방금 정의한 분포와 쉽게 혼동될 법한 개념들이 많고, 실제로 각자의 정의도 서로 긴밀히 연결되어 있다. 여기에 한술 더 떠서 문헌마다 조금씩 용어를 다르게 쓰는 바람에 혼란이 가중되는 부분이 없지 않지만, 대부분 논의의 맥락으로 적당히 구별할 수 있다. 아무튼 구태여 혼란을 초래할 필요는 없기에, 이 책에서는 용어를 최대한 잘 구별하여 사용하였다.

나중에 하나씩 보겠지만, 확률벡터가 가지는 성질과 특성 중에는 그 확률벡터 자체가 아닌, 그 분포에 의존하는 성질들이 있다. 곧, 이러한 성질들은 서로다른 확률공간에서 정의된 서로다른 확률벡터라도 분포만 같다면 서로 공유하게 된다. 이를 뒤집어 생각하면 때로는 하나의 확률공간에 정의된 확률벡터를 그 분포에 의존하는 성질들을 그대로 유지하면서 다른 확률공간으로 옮길 수도 있다. 이러한 이유로 분포가 같은 확률벡터를 다루게 되는 경우가 많고, 표기의 편의를 위해 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P}),\,(\Omega',\,\mathcal{F}',\,\mathbb{P}')$에서 각각 정의된 확률벡터 $X:\Omega\to\mathbb{R}^n,\,Y:\Omega'\to\mathbb{R}^n$에 대해 $\prob_X=\prob_Y$이면 이를 간단히 $X\equiv Y$로 쓴다. 이때 $X\equiv Y$이지만 $X\ne Y$일 수 있다는 사실에 주의해야 한다.

\begin{proposition}\label{prop:rvProbSpace}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 분포 $\prob_X$는 $\mathcal{B}_n$ 위의 측도이다. 따라서 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\prob_X)$는 확률공간을 이룬다.
\end{proposition}

\begin{proof}
    먼저 $\mathcal{B}_n\subseteq X_*\mathcal{F}$임을 보이기 위해 임의의 $A\in\mathcal{B}_n$를 택하면 $X^{-1}(A)\in\mathcal{F}$이므로 $A\in X_*\mathcal{A}$에서 $\mathcal{B}_n\subseteq X_*\mathcal{F}$이다. 따라서 $\prob_X$가 확률측도임을 보이면 충분한데, 이는 $\prob_X(\mathbb{R}^n)=\mathbb{P}(X^{-1}(\mathbb{R}^n))=\mathbb{P}(\Omega)=1$에서 쉽게 알 수 있고, 곧 증명이 끝난다.
\end{proof}

위의 명제는 서로다른 확률공간에 정의된 확률측도를 각각 다루는 대신 이들을 \texttt{pushfowarding}하여 $\mathcal{B}_n$에서 정의된 확률측도인 분포로 일관되게 다룰 수 있음을 함의한다. 그리고 생각해보면, 이가 곧 사건을 직접 정의하고 사용하는 대신 확률벡터를 도입하여 사용하는 이유이다. 무엇이 될 지 모르는 확률공간 대신 우리가 잘 알고있는 실수공간에서의 확률측도를 다루는 것이 훨씬 편하다. 한편, 위의 정리의 역이 성립한다는 것도 꽤나 흥미로운 사실이다.

\begin{theorem}\label{thm:probSpaceRv}
    \texttt{Borel} $\sigma$-대수 $\mathcal{B}_n$ 위의 확률측도 $\mu$에 대해 적당한 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$가 존재하여 $\mu=\prob_X$이다. 특별히, 이때 $(\Omega,\,\mathcal{F})=(\mathbb{R}^n,\,\mathcal{B}_n)$이도록 잡을 수 있다.
\end{theorem}

\begin{proof}
    거의 자명하다. 함수 $X:\mathbb{R}^n\to\mathbb{R}^n$를 항등함수로 두면 이는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mu)$에서 정의된 \texttt{rv.}이고, 임의의 사건 $E$에 대해 $\prob_X(E)=\mu(X^{-1}(E))=\mu(E)$에서 $\mu=\prob_X$이다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^m$와 \texttt{Borel} 함수 $g:\mathbb{R}^m\to\mathbb{R}^n$에 대해 $\prob_{g(X)}=\prob_X\circ g^{-1}$이다.
\end{theorem}

\begin{proof}
    임의의 $A\in\mathcal{B}_n$에 대해 $\prob_{g(X)}(A)=\mathbb{P}((g\circ X)^{-1}(A))=\mathbb{P}(X^{-1}(g^{-1}(A)))=\prob_X(g^{-1}(A))=(\prob_X\circ g^{-1})(A)$이므로 $\prob_{g(X)}=\prob_X\circ g^{-1}$이다.
\end{proof}

자연스러운 다음 순서는 고등학교 시절부터 들어와 이름만은 익숙한 이산확률변수와 연속확률변수를 엄밀하게 측도론의 언어로 정의하는 것이다. 물론, 고등학교나 교양 통계학에서 각각을 정의하지 않는 것은 아니지만, 그 정의가 뭔가 어색하고 작위적이라는 느낌을 지우기 힘든데, 아래의 측도론적인 정의는 더할 나위 없이 깔끔하고 명쾌하다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $\prob_X$가 이산측도이면 이때의 \texttt{rv.} $X$를 \textbf{이산확률벡터(\texttt{discrete rv.})}라 한다. 또한, 만약 $\prob_X$가 $\mu_n$에 대해 절대연속이거나 특이연속이면 이때의 \texttt{rv.} $X$를 각각 \textbf{연속확률벡터(\texttt{continuous rv.})} 혹은 \textbf{특이확률벡터(\texttt{singular rv.})}라 한다. 특별히, $n=1$인 경우 이산확률벡터, 연속확률벡터, 특이확률벡터를 각각 \textbf{이산확률변수}, \textbf{연속확률변수}, \textbf{특이확률변수}라 한다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 이는 이산확률벡터, 연속확률벡터, 특이확률벡터의 정의 중에서 두 개의 이상을 동시에 만족시킬 수 없다.
\end{proposition}

\begin{proof}
    모순을 유도하기 위해 $X$가 이산확률벡터인 동시에 연속확률벡터라고 하자. 그렇다면 $\prob_X$는 가산 지지집합 $A\in\mathcal{B}_n$를 가지는데, $\mu_n(A)=0$에서 $\prob_X(A)=0$의 모순이 발생한다. 이번에는 $X$가 이산확률벡터인 동시에 특이확률벡터라 하자. 그렇다면 이건과 같이 $\prob_X$는 가산 지지집합 $A\in\mathcal{B}_n$를 가지는데, 이의 가산개의 원소를 $x_1,\,x_2,\,\cdots$와 같이 나열하면 $\prob_X(A)=\sum_{i=1}^k\prob_X\{x_i\}=0$에서 모순이 발생한다. (여기서 $k$는 유한할 수도 있고, $\infty$일 수도 있다.) 마지막으로 $X$가 연속확률벡터인 동시에 특이확률벡터라 하면 $\prob_X\ll\mu_n$이고 $\prob_X\perp\mu_n$이므로 명제 \ref{prop:singularMeasure}의 iv로부터 $\prob_X=0$의 모순이 발생하고, 증명은 이로써 충분하다.
\end{proof}

일반적으로, 어떤 확률벡터가 이산인지, 연속인지, \texttt{singular}인지는 확률측도 $\mathbb{P}$와 확률벡터 $X$ 모두에 의해 결정되는 것이지, 이 중 어느 하나에 의해 일방적으로 결정되는 것이 아니다. 즉, 둘 중 어느 하나만 보고서 $X$가 이산인지, 연속인지, \texttt{singular}인지는 알 수 없다. 이로 말미암아 우리가 확률벡터에 대해 당연하게 생각하던 사실들에 미묘한 혼란이 생겨나게 된다.

우선 $X$가 이산확률벡터이지만 그 치역은 가산이 아닐 수 있다. 물론, 대부분의 응용에서는 이산확률변수의 치역도 가산으로 주어지지만, 이는 우연의 일치 그 이상도 이하도 아니다. 극단적인 예시로 가측공간 $(\mathbb{R},\,\mathcal{B}_1)$ 위의 측도 $\mathbb{P}$를
\begin{equation*}
    \mathbb{P}:A\mapsto
    \begin{dcases*}
        1&$0\in A$인 경우\\
        0&\texttt{ow.}
    \end{dcases*}
\end{equation*}
로 잡아 확률공간 $(\mathbb{R},\,\mathcal{B}_1,\,\mathbb{P})$를 구성하고 확률변수 $X:\mathbb{R}\to\mathbb{R}$를 항등함수로 두면 명백히 $X$는 모든 실수를 그 함숫값으로 가지고 심지어 연속이지만, 분포 $\prob_X$가 한원소 집합 $\{0\}$을 지지집합으로 가지므로 $X$는 이산확률벡터이다. 다만, 정의로부터 분포가 가산 지지집합을 가지므로 $X$가 그 가산개의 값을 제외한 나머지 값을 가질 확률이 $0$이 되어 `사실상' 치역이 가산이라고 생각할 수는 있다. 하지만 영집합과 공집합이 비슷하지만 완전히 같지는 않은 것처럼 이 경우에도 `사실상' 치역이 가산인 것과 치역이 정말 가산인 것은 구분해야 할 것이다.

비슷하게, $X$가 연속확률벡터이지만 함수로서 연속이 아닐 수 있다. 애초에 표본공간 $\Omega$에 위상구조가 존재한다는 보장이 없으므로 연속성을 논할 수조차 없다. 그렇다고 표본공간에 위상구조가 적당히 정의되어 있고, 이에 대해 $X$가 연속이라고 해서 이가 연속확률변수냐 하면 이것 또한 아니다. 앞서 든 예시를 생각해보면 표본공간이 $\mathbb{R}$이고 이 위에 표준위상을 잡더라도 $X$가 연속이지만 연속확률변수가 아닐 수 있다. 다만, 정의로부터 연속확률벡터와 특이확률벡터는 \texttt{point mass}를 가질 수 없으므로 확률이 표본공간의 어느 한 점에 집중되어 있지 않고 전체에 고르게 퍼져 있으니, 이런 의미에서 `연속'이라 생각할 수는 있다.

한편, 위의 정의에서 고등학교나 교양 통계학에서는 들어보지 못한 특이확률벡터라는 새로운 종류의 확률벡터가 등장했다. 다른 두 종류의 확률벡터는 고등학교 수준에서도 접할 수 있는 반면, 이제서야 특이확률벡터를 도입하는 것에는 그럴만한 이유가 있다. 우선 특이확률벡터는 다분히 이론적인 필요에 의한 확률벡터로 실생활의 응용에서는 거의 쓸모가 없다. 또한, 이산확률변수나 연속확률변수의 경우 기댓값이나 분산과 같은 개념의 도입과 계산이 쉬운 반면, 특이확률변수의 경우 이에 상당한 이론적 뒷받침이 필요하다. 이런 이유에서 이 책에서도 특이확률변수가 구체적인 예시로 주어지는 것은 이후에 배울 \texttt{Cantor} 분포 하나 뿐이다. 그렇다면 이런 단점에도 불구하고 특이확률벡터를 도입해야 할 이론적인 필요가 대체 무엇인가? 다음 정리는 이 질문에 대한 답이자 측도론의 에필로그에서 예고한 이번 절의 클라이막스이다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$ 위의 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 다음의 조건
    \begin{enumerate}
        \item \texttt{Rv.} $X_\mathrm{ac}:\mathbb{R}^n\to\mathbb{R}^n$는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{ac})$에서 정의된 연속확률벡터이다.
        \item \texttt{Rv.} $X_\mathrm{pp}:\mathbb{R}^n\to\mathbb{R}^n$는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{pp})$에서 정의된 이산확률벡터이다.
        \item \texttt{Rv.} $X_\mathrm{sc}:\mathbb{R}^n\to\mathbb{R}^n$는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{sc})$에서 정의된 특이확률벡터이다.
    \end{enumerate}
    를 만족하는 적당한 $\mathcal{B}_n$ 위의 확률측도 $\mathbb{P}_\mathrm{ac},\,\mathbb{P}_\mathrm{pp},\,\mathbb{P}_\mathrm{sc}$와 \texttt{rv.} $X_\mathrm{ac},\,X_\mathrm{pp},\,X_\mathrm{sc}$가 존재하여 $\alpha+\beta+\gamma=1$인 적당한 $\alpha,\,\beta,\,\gamma\geq0$에 대해 $\prob_X=\alpha\prob_{X_\mathrm{ac}}+\beta\prob_{X_\mathrm{pp}}+\gamma\prob_{X_\mathrm{sc}}$이다.
\end{theorem}

\begin{proof}
    정리 \ref{prop:rvProbSpace}로부터 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\prob_X)$가 확률공간이므로 \texttt{Lebesgue}의 분해정리로부터 $\prob_X$는 절대연속성분 $(\prob_X)_\mathrm{ac}$, 순수 점 성분 $(\prob_X)_\mathrm{pp}$, 특이연속성분 $(\prob_X)_\mathrm{sc}$에 대해 $\prob_X=(\prob_X)_\mathrm{ac}+(\prob_X)_\mathrm{pp}+(\prob_X)_\mathrm{cs}$와 같이 분해된다. 또한, $\prob_X(\mathbb{R}^n)=1$이므로 $\alpha=(\prob_X)_\mathrm{ac}(\mathbb{R}^n),\,\beta=(\prob_X)_\mathrm{pp}(\mathbb{R}^n),\,\gamma=(\prob_X)_\mathrm{cs}(\mathbb{R}^n)$라 하면 $\alpha,\,\beta,\,\gamma$는 모두 유한하고 $\alpha+\beta+\gamma=1$이다. 이제 $\alpha,\,\beta,\,\gamma$가 모두 $0$이 아닌 특별한 경우를 생각해보자. 그렇다면 $\mathbb{P}_1:=(\prob_X)_\mathrm{ac}/\alpha,\,\mathbb{P}_2:=(\prob_X)_\mathrm{pp}/\beta,\,\mathbb{P}_3:=(\prob_X)_\mathrm{cs}/\gamma$가 모두 $\mathcal{B}_n$ 위의 확률측도이므로 $(\prob_X)_\mathrm{ac},\,(\prob_X)_\mathrm{pp},\,(\prob_X)_\mathrm{cs}$의 성질과 정리 \ref{thm:probSpaceRv}로부터 적당한 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{ac})$에서 정의된 연속확률벡터 $X_\mathrm{ac}:\mathbb{R}^n\to\mathbb{R}^n$, 적당한 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{pp})$에서 정의된 이산확률벡터 $X_\mathrm{pp}:\mathbb{R}^n\to\mathbb{R}^n$, 적당한 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{sc})$에서 정의된 특이확률벡터 $X_\mathrm{sc}:\mathbb{R}^n\to\mathbb{R}^n$가 존재하여 $\mathbb{P}_1=\prob_{X_\mathrm{ac}},\,\mathbb{P}_2=\prob_{X_\mathrm{pp}},\,\mathbb{P}_3=\prob_{X_\mathrm{sc}}$이고, 곧 $\prob_X=(\prob_X)_\mathrm{ac}+(\prob_X)_\mathrm{pp}+(\prob_X)_\mathrm{cs}=\alpha\mathbb{P}_1+\beta\mathbb{P}_2+\gamma\mathbb{P}_3=\alpha\prob_{X_\mathrm{ac}}+\beta\prob_{X_\mathrm{pp}}+\gamma\prob_{X_\mathrm{sc}}$이다. 한편, $\alpha,\,\beta,\,\gamma$ 중 일부가 $0$인 경우에 대해서도 이와 비슷하게 하면 된다.
\end{proof}

연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 분류가 서로 배타적인 관계인 것은 맞지만 그렇다고 임의의 확률벡터가 반드시 이 셋 중 하나에 속하는 것은 아니다. 즉, 확률벡터 중에는 연속도, 이산도, \texttt{singular}도 아닌 골치아픈 것들이 존재한다. (이런 확률벡터를 흔히 \textbf{\texttt{mixed type}}이라 부르며 특이확률벡터에 비할 바는 아니지만 그 실용성은 많이 떨어지는 편이다.) 이런 상황에서 위의 정리는 임의의 확률벡터에 대해 비록 이가 \texttt{mixed type}이더라도 그 분포는 적당한 연속확률벡터, 이산확률벡터, 특이확률벡터의 분포의 합으로 분해할 수 있다는 놀라운 결과를 함의한다. 곧 연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 분류는 확률벡터의 공간의 기저와 비슷한 역할을 하며, 이 세 가지 확률벡터를 정의한 순간 사실상 모든 확률벡터의 분류를 끝마친 것과 다름없다.

따라서 이론 전개에 있어서는 \texttt{mixed type rv.}를 고려할 필요 없이 연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 확률벡터만 생각하면 되고, \texttt{mixed type} 확률벡터는 이 세 종류의 확률벡터의 성질들을 적당히 섞어 가질 뿐이다. 이러니 고등학교 시절부터 연속확률벡터, 이산확률벡터의 두 가지 종류에만 지대한 관심을 가진 것은 너무나 당연하다. 이론적으로 다루기 힘든 특이확률벡터를 제외하면 이 둘을 다룸으로써 우리는 고등학교때부터 우리도 모르는 사이에 사실상 온갖 종류의 확률벡터를 모두 다루고 있던 셈이다!

이제 클라이막스의 여운을 뒤로 하고, \texttt{CDF}를 살펴볼 순서이다. 흔히 교양 통계학에서는 \texttt{PDF}를 배운 뒤 \texttt{CDF}를 배우므로 \texttt{PDF}의 개념을 도입하지도 않고 \texttt{CDF}를 정의하는 것이 의아할 수 있다. 하지만, 적어도 이론적으로는 \texttt{CDF}가 \texttt{PDF}보다 더 기본적인 개념이기에 이를 먼저 도입한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{rv.} $X$의 \textbf{(누적)분포함수((\texttt{cumulative}) \texttt{distribution function})}를 $F_X:\mathbb{R}^n\to\mathbb{R}$로 쓰고 $F_X:x\mapsto\prob_X(\prod_{i=1}^n(-\infty,\,x_i])$로 정의한다. 특별히, $n\geq2$인 경우 $F_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합(누적)분포함수(\texttt{joint} (\texttt{cumulative}) \texttt{distribution function})}라 하기도 한다.
\end{definition}

\texttt{CDF}의 기본적인 성질은 정리 \ref{thm:distributionProp}로부터 대부분 자명하게 유도된다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $0\leq F_X\leq 1$.
        \item 임의의 유계인 \texttt{semi-open box} $B\subseteq\mathbb{R}^n$에 대해 $\Delta_BF_X=\prob_X(B)\geq0$이다.
        \item \texttt{CDF} $F_X$는 각 변수에 대해 증가한다.
        \item \texttt{CDF} $F_X$는 오른쪽 연속이다.
        \item 각 $i\leq n$에 대해 $\lim_{x_i\to-\infty}F_X(x)=0$이다.\footnotemark
        \item $\lim_{x_1,\,\cdots,\,x_n\to\infty}F_X(x)=1$.\footnotemark
        \item 임의의 $x\in\mathbb{R}^n$에 대해 $B_x=(-\infty,\,x]$라 하면 $F_X(x-)=\prob_X(B_x^\circ)$이고 $F_X(x)-F_X(x-)=\prob_X(\partial B_x)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i - vi. 이는 \texttt{CDF}의 정의와 정리 \ref{thm:distributionProp}로부터 자명하다.
    
    vii. 임의의 $x\in\mathbb{R}^n$를 택하여 집합열 $\{B_j\}$를 $B_j:=B_{x-\ind/j}$로 두면 이는 $\mathcal{S}_n$에 속하는 증가하는 집합열로서 $B_j\uparrow(-\infty,\,x)=B_x^\circ$이다. 따라서 $F_X(x-\ind/j)=\prob_X(B_j)\uparrow\prob_X(B_x^\circ)$이므로 임의의 $\epsilon>0$을 택하면 적당한 $j_0\in\mathbb{N}$가 존재하여 $\prob_X(B_x^\circ)-\prob_X(B_{j_0})<\epsilon$이다. 이제 $\delta=1/j_0$라 하면 $||x-y||<\delta$이고 $x>y$인 모든 $y\in\mathbb{R}^n$에 대해 $B_{j_0}\subseteq(-\infty,\,y)\subseteq B_x^\circ$에서 $\prob_X(B_x^\circ)-\epsilon<\prob_X(B_{j_0})\leq F_X(y)=\prob_X((-\infty,\,y])\leq\prob_X(B_x^\circ)$이므로 $|F_X(y)-\prob_X(B_x^\circ)|<\epsilon$가 되어 $F_X(x-)=\prob_X(B_x^\circ)$임을 안다. 이제 $F_X(x)-F_X(x-)=\prob_X(B_x)-\prob_X(B_x^\circ)=\prob_X(\partial B_x)$임은 자명하다.
\end{proof}

위의 정리에서 $n=1$인 경우 vii는 $F_X(x)-F_X(x-)=\prob_X\{x\}$가 되어 이로써 \texttt{CDF}를 분포의 \texttt{point mass}를 구하는 용도로 사용할 수 있다. 한편, 위의 정리의 역 비슷한 정리도 성립한다.

\begin{theorem}
    함수 $F:\mathbb{R}^n\to\mathbb{R}$에 대해 이가
    \begin{enumerate}
        \item 함수 $F$는 오른쪽 연속이고 각 변수에 대해 증가한다.
        \item 유계인 \texttt{semi-open box} $B\subseteq\mathbb{R}^n$에 대해 $\Delta_BF\geq0$이다.
        \item 각 $i\leq n$에 대해 $\lim_{x_i\to-\infty}F(x)=0$이고 $\lim_{x_1,\,\cdots,\,x_n\to\infty}F_X(x)=1$이다.
    \end{enumerate}
    를 만족하면 적당한 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$가 존재하여 $F=F_X$이다. 특별히, 이때 $(\Omega,\,\mathcal{F})=(\mathbb{R}^n,\,\mathcal{B}_n)$이도록 잡을 수 있다.
\end{theorem}

\begin{proof}
    정리 \ref{thm:finiteBorelSpecify}로부터 적당한 $\mathcal{B}_n$ 위의 측도 $\mu$가 존재하여 임의의 $x\in\mathbb{R}^n$에 대해 $F(x)=\mu((-\infty,\,x])$이다. 그런데 정리 \ref{thm:distributionProp}의 vii와 주어진 조건으로부터 $\mu(\mathbb{R}^n)=1$이 되어 $\mu$는 확률측도이고, 곧 정리 \ref{thm:probSpaceRv}로부터 적당한 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$ 위의 $n$차원 \texttt{rv.} $X$가 존재하여 $\mu=\prob_X$이다. 이상으로부터 임의의 $x\in\mathbb{R}^n$에 대해 $F(x)=\mu((-\infty,\,x])=\prob_X((-\infty,\,x])=F_X(x)$가 성립한다. 한편, 이때 $(\Omega,\,\mathcal{F})=(\mathbb{R}^n,\,\mathcal{B}_n)$이도록 잡을 수 있음은 정리 \ref{thm:probSpaceRv}로부터 자명하다.
\end{proof}

곧 우리는 \texttt{CDF}가 될 수 있는 함수를 위의 정리의 조건 i - iii으로 완벽히 \texttt{characterize}할 수 있다. 한편, \texttt{CDF}의 연속성에 대한 다음 정리들도 꽤나 흥미롭다.

\begin{theorem}\label{thm:CDFContinuous}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 한 점 $x_0\in\mathbb{R}^n$ 대해 $B_{x_0}=(-\infty,\,x_0]$라 하면 \texttt{TFAE}.
    \begin{enumerate}
        \item \texttt{CDF} $F_X$가 $x_0$에서 연속이다.
        \item $F_X(x_0)=\prob_X(B_{x_0})=\prob_X(B_{x_0}^\circ)$.
        \item $\prob_X(\partial B_{x_0})=0$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i $\Rightarrow$ ii. 집합열 $\{B_j\}$를 $B_j=(-\infty,\,x_0-\ind/j]$로 두면 이는 $B_{x_0}^\circ$로 수렴하는 증가하는 집합열이므로 $F_X(x_0-\ind/j)=\prob_X(B_j)\uparrow\prob_X(B_{x_0}^\circ)$이다. 한편, 가정으로부터 $F_X$가 $x_0$에서 연속이므로 $\prob_X(B_j)=F_X(x_0-\ind/j)\uparrow F_X(x_0)=\prob_X(B_{x_0})$가 되어 $F_X(x_0)=\prob_X(B_{x_0})=\prob_X(B_{x_0}^\circ)$임을 안다.

    ii $\Rightarrow$ iii. 이는 $\prob_X(\partial B_{x_0})=\prob_X(B_{x_0})-\prob_X(B_{x_0}^\circ)=0$에서 자명하다.

    iii $\Rightarrow$ i. $0$으로 수렴하는 $\mathbb{R}^n$에 속하는 임의의 수열 $\{h_j\}$를 택하여 각 $j\in\mathbb{N}$에 대해 $a_j=\min_{i=1}^nh_j^i,\,b_j=\max_{i=1}^nh_j^i$라 하면 $F_X(x_0+a_j\ind)\leq F_X(x_0+h_j)\leq F_X(x_0+b_j\ind)$이고 $a_j,\,b_j\to 0$이다. 따라서 함수 $f:\mathbb{R}\to\mathbb{R}$를 $f:x\mapsto F_X(x_0+x\ind)$로 두고 이가 $0$에서 연속임을 보이는 것으로 증명은 충분한데, \texttt{CDF}의 성질로부터 $\lim_{x\downarrow0}f(x)=f(0)$임은 이미 알고 있으므로 $\lim_{x\uparrow0}f(x)=f(0)$이라는 사실만 보이면 된다. 이를 위해 $x_j\uparrow0$인 임의의 실수열 $\{x_j\}$를 택하여 집합열 $\{B_j\}$를 $B_j:=(-\infty,\,x_0+x_j]$로 두면 이는 $B_{x_0}^\circ$로 수렴하는 증가하는 집합열이다. 그렇다면 가정으로부터 $f(x_j)=F_X(x_0+x_j\ind)=\prob_X(B_j)\uparrow\prob_X(B_{x_0}^\circ)=\prob_X(B_{x_0})=F_X(x_0)=f(0)$이고, 증명이 끝난다.
\end{proof}

\begin{lemma}\label{lem:monotoneDiscontinuity}
    단조함수 $f:\mathbb{R}\to\mathbb{R}$는 가산개의 불연속점만을 가진다.
\end{lemma}

\begin{proof}
    우선 $f$가 증가함수라 하고 집합 $A=\{x\in\mathbb{R}:f\textrm{가 $x$에서 불연속}\}$를 생각하자. 그렇다면 임의의 $x\in A$에 대해 $f(x-)<f(x+)$이므로 $f(x-)<p_x<f(x+)$인 적당한 $p_x\in\mathbb{Q}$를 택할 수 있고, 이로써 함수 $g:A\to\mathbb{Q}$를 $g:x\mapsto p_x$로 두자. 한편, 임의의 $x,\,y\in A$에 대해 $x<y$인데 $f(y-)<f(x+)$이면 $z=(x+y)/2$에 대해 $f(z)\leq f(y-)<f(x+)\leq f(z)$의 모순이 발생하므로 $(f(x-),\,f(x+))$와 $(f(y-),\,f(y+))$는 서로소가 되어 $g$는 단사이고, 곧 $A$는 가산이다. 이제 $f$가 감소함수인 경우에는 $-f$를 대신 생각하면 된다.
\end{proof}

\begin{theorem}\label{thm:CDFContinuousDense}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $F_X$의 연속점의 집합은 조밀하다. 나아가, $n=1$인 경우 $F_X$는 가산개의 불연속점만을 가진다.
\end{theorem}

\begin{proof}
    임의의 $x_0\in\mathbb{R}^n$를 택하여 함수 $f:\mathbb{R}\to[0,\,1]$를 $f:h\mapsto F_X(x_0+h\ind)$로 두자. 그렇다면 $f$는 증가함수가 되어 위의 보조정리로부터 가산개의 불연속점만을 가지고, 곧 $0$으로 수렴하면서 각 점에서 $f$가 연속인 실수열 $\{h_i\}$를 적당히 택할 수 있다. 이는 각 $i\in\mathbb{N}$에 대해 $\prob_X((-\infty,\,x_0+h))=F_X((x_0+h_i\ind)-)=f(h_i-)=f(h_i)=F_X(x_0+h_i\ind)$임을 함의하므로 정리 \ref{thm:CDFContinuous}로부터 $F_X$는 $x_0+h_i\ind$에서 연속이고, $x_0+h_i\ind\to x_0$임은 자명하므로 $F_X$의 연속점의 집합이 조밀함을 안다. 한편, $n=1$인 경우에는 $F_X$가 증가함수이므로 다시 위의 보조정리로부터 가산개의 불연속점만을 가짐이 자명하다.
\end{proof}

이제 \texttt{PDF}를 도입하는 것으로 이번 절을 마무리하자. 측도론으로 \texttt{PDF}를 도입하는데 핵심적인 역할을 하는 것은 다름아닌 \texttt{Radon-Nikod\'ym} 도함수의 개념이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 적당한 $\mathcal{B}_n$ 위의 $\sigma$-유한 측도 $\mu$가 존재하여 $\prob_X\ll\mu$라 하자. 이때 \texttt{Radon-Nikod\'ym} 도함수 $d\prob_X/d\mu$를 $X$의 $\mu$에 대한 \textbf{(확률)밀도함수((\texttt{probability}) \texttt{density function})}라 하고 $f_X$로 쓴다. 특별히, $n\geq2$인 경우 $f_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합(확률)밀도함수(\texttt{joint} (\texttt{probability}) \texttt{density function})}라 하기도 한다.
\end{definition}

이렇게 \texttt{Radon-Nikod\'ym} 도함수로 \texttt{PDF}를 정의하면서 이번에도 우리가 \texttt{PDF}에 대해 당연하게 생각하던 사실들에 미묘한 혼란이 생겨나게 된다. 우선, \texttt{Radon-Nikod\'ym} 도함수가 유일하기는 하지만 그 유일성이 `거의 어디서나 같은 함수를 하나로 볼 때' 성립하는 것이므로 엄밀히는 유일하지 않다. 즉, 영집합에서 조금씩 다른 무한히 많은 함수들이 모두 하나의 확률벡터의 \texttt{PDF}가 될 수 있으므로 일반적으로 특정 점에서의 \texttt{PDF}의 값을 물어보는 것은 의미가 없다. 그러나 \texttt{Radon-Nikod\'ym} 도함수를 추상적인 도구로만 사용했던 측도론에서와 달리 확률론에서는 \texttt{PDF}를 구체적인 함수로 다루어야 할 필요가 있으므로 혼란을 피하기 위해 \texttt{PDF}가 될 수 있는 무한히 많은, 거의 어디서나 같은 함수 중 특정한 하나를 \texttt{PDF}의 \textbf{\texttt{version}}이라 한다. 물론, 표기상의 편의를 이유로 논의의 대상이 \texttt{PDF}인지, \texttt{PDF}의 \texttt{version}인지를 명시적으로 밝히지 않는 경우가 대부분이지만, $L^p$ 공간에서 동치류로서의 $f$와 구체적인 함수 $f$를 논의의 맥락으로 큰 혼란 없이 구분하였듯이 이 둘 또한 구분에 큰 어려움은 없을 것이다.

다음으로, 지금까지는 연속확률벡터와 이산확률벡터에 대해서만 \texttt{PDF}를 생각했지만 위의 정의에서 볼 수 있듯이 임의의 확률벡터 $X$에 대해서도 $\prob_X\ll\mu$인 $\sigma$-유한 측도 $\mu$만 잘 잡아주면 이의 \texttt{PDF}를 생각할 수 있다. 한편, 연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 확률벡터만 생각해도 충분하다는 사실에 놀라워했던 것이 불과 몇 페이지 전인데 굳이 이렇게 지나칠 정도로 일반적인 \texttt{PDF}를 도입하는 것에 의아할 수 있다. 그러나 이는 \texttt{mixed-type} 확률벡터의 \texttt{PDF}를 직접 다루기 위함이 아니라 연속확률벡터와 이산확률벡터의 \texttt{PDF}를 동시에 다루기 위함이다. 고등학교나 교양 통계학에서 연속확률변수와 이산확률변수의 기댓값이나 분산 같은 성질들을 논할 때, 각각 경우를 나누어 전자는 적분으로, 후자는 합으로 접근했던 것을 기억할 것이다. 우리는 위에서 일반적으로 정의된 \texttt{PDF}와 측도론의 에필로그에서 소개한 셈측도를 이용해 드디어 이런 번거로움에서 벗어날 수 있다.

한편, 정의에서 볼 수 있듯이 $\prob_X\ll\mu$인 $\sigma$-유한 측도 $\mu$를 무엇으로 택하는지에 따라 그 \texttt{PDF}가 달라지므로 $\mu$를 반드시 명시해 주어야 하는데, 우리가 주로 다룰 연속확률벡터와 이산확률벡터의 경우 이에 대한 관례가 있다. 먼저 연속확률벡터 $X:\Omega\to\mathbb{R}^n$의 경우 그 정의상 $\prob_X\ll\mu_n$이 항상 성립하므로 특별한 언급이 없는 이상 연속확률벡터의 \texttt{PDF}는 $\mu_n$에 대한 \texttt{PDF}로 생각한다. 이산확률벡터 $X:\Omega\to\mathbb{R}^n$의 경우는 조금 복잡한데, 우선 정의상 $\prob_X$는 가산 지지집합 $A\in\mathcal{B}_n$를 가진다. 물론, 이때의 가산 지지집합은 유일하지 않지만 임의의 $x\in A$에 대해 $\prob_X\{x\}>0$이라는 조건을 추가하면 유일하게 주어진다. 그렇다면 $(\prob_X,\,\mathcal{B}_n,\,\#)$에 대해 $\prob_X\ll\#_A$임이 자명하고, 이때 $\#_A$가 $\sigma$-유한임도 자명하므로 특별한 언급이 없는 이상 이산확률벡터의 \texttt{PDF}는 $\#_A$에 대한 \texttt{PDF}로 생각한다. 나아가, 이산확률벡터의 경우 특별한 언급이 없는 이상 \texttt{PDF}의 \texttt{version}으로 $\mathbb{R}^n\setminus A$에서 $0$인 \texttt{version}을 택하는 관례도 있다. 이런 관례를 따르면 이때의 \texttt{PDF}가 우리가 기존에 알던 \texttt{PMF}가 된다는 것을 잠시 후에 알게 될 것이다.

이제 \texttt{PDF}의 기본적인 성질을 보자. 이는 대부분 적분의 성질로부터 거의 자명하게 얻어진다.

\begin{theorem}\label{thm:PDFProp}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 적당한 $\mathcal{B}_n$ 위의 $\sigma$-유한 측도 $\mu$가 존재하여 $\prob_X\ll\mu$라 하자. 그렇다면 $\mu$에 대한 $X$의 \texttt{PDF} $f_X$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $f_X\geq0$ ($\mu$-\texttt{ae.}).
        \item $\int_{\mathbb{R}^n}f_X\,d\mu=1$.
        \item 임의의 $A\in\mathcal{B}_n$에 대해 $\int_Af_X\,d\mu=\prob_X(A)=\mathbb{P}\{X\in A\}$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    iii. 이는 $\int_Af_X\,d\mu=\int_A(d\prob_X/d\mu)\,d\mu=\int_A\,d\prob_X=\prob_X(A)$에서 자명하다.

    i. 만약 $f_X\geq0$ ($\mu$-\texttt{ae.})가 아니라면 집합 $A=\{x\in\mathbb{R}^n:-f_X(x)>0\}$이 양의 측도를 가지므로 iii과 따름정리 \ref{cor:zeroAeIntegral}의 iii으로부터 $\prob_X(A)=\int_Af_X\,d\mu<0$의 모순이 발생한다. 따라서 $f_X\geq0$ ($\mu$-\texttt{ae.})이어야 한다.
    
    ii. iii으로부터 $\int_{\mathbb{R}^n}f_X\,d\mu=\prob_X(\mathbb{R}^n)=1$이므로 자명하다.
\end{proof}

특별히, 이산확률벡터의 경우 위의 정리는 다음 따름정리와 같이 합의 형태로 표현된다.

\begin{corollary}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 이산확률벡터 $X:\Omega\to\mathbb{R}^n$에 대해 $A\in\mathcal{B}_n$를 $\prob_X$의 가산 지지집합이라 하고 임의의 $x\in A$에 대해 $\prob_X\{x\}>0$이라 하면 다음이 성립한다.
    \begin{enumerate}
        \item 임의의 $x\in\mathbb{R}^n$에 대해 $f_X(x)=\prob_X\{x\}$이고, 따라서 $0\leq f_X\leq1$이다.
        \item $\sum_{x\in\mathbb{R}^n}f_X(x)=1$.
        \item 임의의 $B\in\mathcal{B}_n$에 대해 $\sum_{x\in B}f_X(x)=\prob_X(B)=\mathbb{P}\{X\in B\}$이다.
    \end{enumerate}
\end{corollary}

\begin{proof}
    표기의 편의를 위해 $\mathcal{A}=\mathcal{B}_n\vert_A$라 하면 $\#_A\vert_\mathcal{A}=\#\vert_\mathcal{A}$는 가측공간 $(A,\,\mathcal{A})$ 위의 셈측도이다.

    i. 만약 $x\in A$이면 정리 \ref{thm:intRistriction}의 iii으로부터 $\prob_X\{x\}=\int_{\{x\}}f_X\,d\#_A=\int_{\{x\}}f_X\vert_A\,d\#\vert_\mathcal{A}=f_X(x)$이고 $x\notin A$이면 $f_X$의 \texttt{version}을 택하는 관례로부터 $\prob_X\{x\}=0=f_X(x)$이다.

    ii. 위의 정리와 셈측도의 성질 그리고 $f_X$의 \texttt{version}을 택하는 관례와 정리 \ref{thm:intRistriction}의 iii으로부터 $1=\prob_X(A)=\int_Af_X\,d\#_A=\int_Af_X\vert_A\,d\#\vert_\mathcal{A}=\sum_{x\in A}f_X(x)=\sum_{x\in\mathbb{R}^n}f_X(x)$이다.

    iii. 위의 정리와 셈측도의 성질 그리고 $f_X$의 \texttt{version}을 택하는 관례와 정리 \ref{thm:intRistriction}의 iii으로부터 $\prob_X(B)=\prob_X(A\cap B)=\int_{A\cap B}f_X\,d\#_A=\int_{A\cap B}f_X\vert_A\,d\#\vert_\mathcal{A}=\sum_{x\in A\cap B}f_X(x)=\sum_{x\in B}f_X(x)$이다.
\end{proof}

다음 정리는 연속확률벡터의 \texttt{CDF}와 \texttt{PDF}의 관계에 대한 정리로서 연속확률벡터의 \texttt{CDF}와 \texttt{PDF}를 계산하는 데 유용하게 사용된다.

\begin{theorem}\label{thm:CDFPDFRel}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 연속확률벡터 $X:\Omega\to\mathbb{R}^n$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $f_X(x)=F_X^{(s)}(x)$.\footnotemark
        \item $F_X(x)=\int_{(-\infty,\,x]}f_X\,d\mu_n$.
    \end{enumerate}
    특별히, $x_0\in\mathbb{R}^n$의 근방에서 $\partial^\ind F_X$가 존재하고 이가 $x_0$에서 연속이면 $f_X(x_0)=\partial^\ind F_X(x_0)$이다.
\end{theorem}

\begin{proof}
    이는 따름정리 \ref{cor:FTC1}와 정리 \ref{thm:PDFProp}의 iii으로부터 자명하다
\end{proof}

비슷하게, 다음 정리는 어떤 확률벡터가 연속인지를 판단할 때 유용하다.

\begin{theorem}\label{thm:rvContinuous}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{TFAE}.
    \begin{enumerate}
        \item \texttt{Rv.} $X$는 연속확률벡터이다.
        \item \texttt{CDF} $F_X$가 절대연속이다.
        \item 적분가능한 \texttt{Borel} 함수 $f:\mathbb{R}^n\to\overline{\mathbb{R}}$가 존재하여 $F_X(x)=\int_{(-\infty,\,x]}f\,d\mu_n$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i $\Leftrightarrow$ ii. 이는 정리 \ref{thm:AbsContiRel}로부터 자명하다.

    i $\Rightarrow$ iii. 이는 $f=f_X$로 두고 정리 \ref{thm:CDFPDFRel}의 ii를 생각하면 자명하다.

    iii $\Rightarrow$ ii. 함수 $f$가 적분가능하므로 거의 어디서나 유한하고, 따라서 \texttt{WLOG}, 필요다하면 영집합에서의 $f$의 값을 $0$으로 바꾸어 $|f|<\infty$라 하자. 이제 집합열 $\{A_j\}$를 $A_j=|f|^{-1}((j,\,\infty))$로 두면 이는 $\emptyset$으로 수렴하는 감소하는 집합열이 되어 $\int_{A_j}|f|\,d\lambda_n\to\int_\emptyset|f|\,d\lambda_n=0$이다. 이로부터 임의의 $\epsilon>0$을 택하면 적당한 $j_0\in\mathbb{N}$가 존재하여 $\int_{A_{j_0}}|f|\,d\lambda_n<\epsilon/2$이고, $\mu_n(A)<\epsilon/2j_0=:\delta$인 임의의 $A\in\mathcal{B}_n$에 대해 $\int_A|f|\,d\mu_n\leq\int_{A\setminus A_{j_0}}|f|\,d\mu_n+\int_{A_{j_0}}|f|\,d\mu_n<\mu_n(A\setminus A_{j_0})j_0+\epsilon/2<\epsilon$이다. 따라서 임의의 유계이고 서로소인 $B_1,\,\cdots,\,B_l\in\mathcal{S}_n$에 대해 $\sum_{k=1}^l\mu_n(B_k)=\mu_n(\bigsqcup_{k=1}^lB_k)<\delta$이면 $\sum_{k=1}^l\Delta_{B_k}F_X=\sum_{k=1}^l\int_{B_k}f\,d\mu_n=\int_{\bigsqcup_{k=1}^lB_k}f\,d\mu<\epsilon$이 되어 $F_X$가 절대연속임을 안다.
\end{proof}

\section{Expectation}

이번 절에서는 확률변수의 대표적인 통계량 중 하나인 기댓값과 분산을 엄밀하게 도입하고, 이와 관련된 부등식을 증명한다. 통계학의 큰 연구주제 중 하나는 `정보의 단순화'라 할 것이다. 당연히, 이때 단순화의 정도와 이에 따른 정보의 손실은 서로 \texttt{trade-off}의 관계에 있어서 단순화를 많이 하면 할수록 정보의 전달이 용이하지만 그만큼 손실되는 정보도 많아지고, 역으로 손실되는 정보의 양을 줄이면 줄일수록 단순화의 정도가 감소하여 전달이 어려워진다. 이런 상황에서 우리는 정보의 손실을 최소한으로 유지하면서 정보를 단순하게 전달할 수 있는 좋은 방법을 찾고자 하는데, 이번 절에서 알아볼 기댓값은 어떤 분포의 정보를 단 하나의 통계량으로 단순화하여 전달할 수 있는 좋은 방법 중 하나이다. (이와 같이 분포의 정보를 요약하는 통계량을 그 분포의 대푯값이라 하며 기댓값 외에도 중앙값, 최빈값 등이 있다. 각 대푯값은 나름의 장단점이 있기에 어떤 상황에서 무엇을 써야 하는지를 잘 판단하여 사용해야 한다.) 

기댓값은 확률변수가 가질 것으로 가장 기대할 수 있는 값이라 해석할 수 있다. 기댓값은 분포의 여러 대푯값 중에서 가장 널리 이용되는 통계량으로 추정이나 관련 가설의 검정 등에 있어 많은 장점을 지니지만, \texttt{outlier}와 같은 극단치에 민감하여 때로는 분포에 대해 다소 오인의 가능성이 있는 정보를 전달할 수 있다는 단점을 가진다. 이러한 기댓값은 기본적으로 확률변수의 적분으로 정의된다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $X$가 적분가능하다면 $\int_\Omega X\,d\mathbb{P}$를 $X$의 \textbf{기댓값(\texttt{expectation})} 혹은 \textbf{평균(\texttt{mean})}이라 하고 $\expect(X),\,\mu_X$ 혹은 간단히 $\mu$로 쓴다.
\end{definition}

기댓값이 정의되기 위해서는 확률공간과 그 위에서 정의된 \texttt{rv.}만 있으면 충분하다는 점에 주목하기 바란다. 고등학교나 교양 통계학에서는 기댓값이 정의되려면 확률변수가 반드시 연속이거나 이산이어서 \texttt{PDF}나 \texttt{PMF}가 있어야 했다. 그러나 위의 정의는 일반적인 \texttt{mixed-type} 확률변수에 대해서도 기댓값을 정의할 수 있도록 해준다. 한편, 정의에서 볼 수 있듯이 기댓값은 확률변수의 적분에 불과하므로 이에 관한 기본적인 성질은 대부분 적분의 성질로부터 자명하게 유도된다.

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\expect(X)$가 존재할 필요충분조건은 $\expect(|X|)$가 존재하는 것이다.
\end{proposition}

\begin{proof}
    이는 $X$가 적분가능할 필요충분조건이 $|X|$가 적분가능할 것이라는 점에서 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$에 대해 $\expect(X),\,\expect(Y)$가 모두 존재한다면 다음이 성립한다.
    \begin{enumerate}
        \item (선형성) 임의의 $a,\,b\in\mathbb{R}$에 대해 $\expect(aX+bY)$가 존재하고 $\expect(aX+bY)=a\expect(X)+b\expect(Y)$이다.
        \item 만약 $X=Y$ (\texttt{as.})라면 $\expect(X)=\expect(Y)$이다.
        \item 만약 $X\leq Y$ (\texttt{as.})라면 $\expect(X)\leq\expect(Y)$이다.
        \item $\expect(1)=1$.
        \item $\inf_{\omega\in\Omega}X(\omega)\leq\expect(X)\leq\sup_{\omega\in\Omega}X(\omega)$.
        \item $|\expect(X)|\leq\expect(|X|)$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i - iii, vi. 이는 적분의 성질로부터 자명하다.

    iv. 이는 $\expect(1)=\int_\Omega\,d\mathbb{P}=\mathbb{P}(\Omega)=1$에서 분명하다.

    v. 이는 iii과 iv로부터 자명하다.
\end{proof}

기댓값의 선형성으로부터 $X-\mu_X$의 기댓값은 항상 $0$이다. 이렇게 원래의 확률변수에서 그 기댓값을 빼는 것을 \textbf{\texttt{centering}}이라 하며, 기댓값이 서로다른 분포를 비교할 때에 자주 사용되는 방법이다. 한편, 다양한 수렴정리들도 동일하게 성립한다.

\begin{theorem}[Monotone convergence theorem]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 음이 아닌 \texttt{rv.} $X_i:\Omega\to\mathbb{R}^+_0$의 열 $\{X_i\}$와 음이 아닌 \texttt{rv.} $X:\Omega\to\mathbb{R}^+_0$에 대해 $X_i\uparrow X$ (\texttt{as.})이고 $\expect(X)$가 존재한다고 하면 모든 $i\in\mathbb{N}$에 대해 $\expect(X_i)$도 존재하고 $\expect(X_i)\uparrow\expect(X)$이다.
\end{theorem}

\begin{proof}
    모든 $i\in\mathbb{N}$에 대해 $0\leq X_i\leq X$이므로 $\expect(X_i)$가 존재한다. 이제 나머지는 측도론에서 배운 \texttt{MCT}에서 자명하다.
\end{proof}

\begin{theorem}[Lebesgue's dominated convergence theorem]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X_i:\Omega\to\mathbb{R}$의 열 $\{X_i\}$와 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $X_i\to X$ (\texttt{as.})라 하자. 또한 어떤 \texttt{rv.} $Y:\Omega\to\mathbb{R}^+_0$가 존재하여 $\expect(Y)$가 존재하고 모든 $i\in\mathbb{N}$에 대해 $|X_i|\leq Y$이면 $\expect(X_i)$와 $\expect(X)$가 모두 존재하고 $\expect(X_i)\to\expect(X)$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{DCT}에서 자명하다.
\end{proof}

\begin{corollary}[Bounded convergence theorem]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X_i:\Omega\to\mathbb{R}$의 열 $\{X_i\}$와 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $X_i\to X$ (\texttt{as.})라 하자. 또한 $\{X_i\}$가 균등하게 유계라 하자. 즉, 어떤 $M>0$이 존재하여 모든 $i\in\mathbb{N}$에 대해 $|X_i|\leq M$이라 하자. 그렇다면 $\expect(X_i)$와 $\expect(X)$가 모두 존재하고 $\expect(X_i)\to\expect(X)$이다.
\end{corollary}

\begin{proof}
    이는 측도론에서 배운 유계수렴정리로부터 자명하다.
\end{proof}

비록 기댓값의 정의는 충분히 일반적이지만, 이가 기댓값을 계산하는 구체적인 방법을 알려주지는 않는다. 결국 기댓값을 계산하기 위해서는 우리가 여태껏 해왔던 것처럼 \texttt{PDF}의 도움을 받아야 한다.

\begin{theorem}\label{thm:expectDistribution}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 \texttt{Borel} 함수 $g:\mathbb{R}^n\to\mathbb{R}$에 대해 $\expect(g(X))$가 존재한다면(혹은 $g$가 $\prob_X$-적분가능하다면) $\expect(g(X))=\int_{\mathbb{R}^n}g\,d\prob_X$이고, 이때 $g$는 $\prob_X$-적분가능하다(혹은 $\expect(g(X))$가 존재한다).
\end{theorem}

\begin{proof}
    기댓값 $\expect(g(X))$가 존재한다면 $\expect(g(X))=\int_\Omega g\circ X\,d\mathbb{P}=\int_{\mathbb{R}^n}g\,d\prob_X<\infty$이므로 이는 자명하다. 한편, $\prob_X$-적분가능한 $g$에 대해서도 비슷하게 하면 된다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 \texttt{Borel} 함수 $g:\mathbb{R}^n\to\mathbb{R}$에 대해 적당한 $\mathcal{B}_n$ 위의 $\sigma$-유한 측도 $\mu$가 존재하여 $\prob_X\ll\mu$라 하자. 만약 $\expect(g(X))$가 존재한다면(혹은 $f_Xg$는 $\mu$-적분가능하다면) $\expect(g(X))=\int_{\mathbb{R}^n}f_Xg\,d\mu$이고, 이때 $f_Xg$는 $\mu$-적분가능하다(혹은 $\expect(g(X))$가 존재한다).
\end{theorem}

\begin{proof}
    기댓값 $\expect(g(X))$가 존재한다면 $\expect(g(X))=\int_{\mathbb{R}^n}g\,d\prob_X=\int_{\mathbb{R}^n}f_Xg\,d\mu<\infty$이므로 이는 자명하다. 한편, $f_Xg$가 $\mu$-적분가능한 경우에 대해서도 비슷하게 하면 된다.
\end{proof}

특별히, 이산확률벡터의 경우 위의 정리는 다음 따름정리와 같이 합의 형태로 표현된다.

\begin{corollary}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 이산확률벡터 $X:\Omega\to\mathbb{R}^n$와 \texttt{Borel} 함수 $g:\mathbb{R}^n\to\mathbb{R}$에 대해 $\expect(g(X))$가 존재한다면 $\expect(g(X))=\sum_{x\in\mathbb{R}^n}f_X(x)g(x)$이다.
\end{corollary}

\begin{proof}
    가정으로부터 $\prob_X$의 가산 지지집합 $A\in\mathcal{B}_n$가 존재하고, \texttt{WLOG}, 필요하다면 몇몇 원소를 제거하여 임의의 $x\in A$에 대해 $\prob_X\{x\}>0$이라 해도 된다. 표기의 편의를 위해 $\mathcal{A}=\mathcal{B}_n\vert_A$라 하면 $\#_A\vert_\mathcal{A}=\#\vert_\mathcal{A}$는 가측공간 $(A,\,\mathcal{A})$ 위의 셈측도이므로 위의 정리와 $f_X$의 \texttt{version}을 택하는 관례 그리고 정리 \ref{thm:intRistriction}의 iii으로부터 $\expect(g(X))=\int_{\mathbb{R}^n}f_Xg\,d\#_A=\int_Af_Xg\,d\#_A=\int_A(f_Xg)\vert_A\,d\#\vert_\mathcal{A}=\sum_{x\in A}f_X(x)g(x)=\sum_{x\in\mathbb{R}^n}f_X(x)g(x)$이다.
\end{proof}

만약 확률변수가 음이 아니라면 \texttt{CDF}를 사용하여 기댓값을 계산할 수도 있다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 음이 아닌 \texttt{rv.} $X:\Omega\to\mathbb{R}_0^+$에 대해 $\expect(X)$가 존재하면 $1-F_X$는 $\mathbb{R}_0^+$에서 $\mu_1$-적분가능하고 $\expect(X)=\int_{\mathbb{R}_0^+}1-F_X\,d\mu_1$이다.
\end{theorem}

\begin{proof}
    함수 $\ind_{\{0\leq x<y\}}(x,\,y)$가 음이 아닌 \texttt{Borel}이므로 \texttt{Fubini}의 정리로부터
    \begin{align*}
        \expect(X)&=\int_\mathbb{R}x\,d\prob_X(x)\\
        &=\int_{\mathbb{R}_0^+}x\,d\prob_X(x)\\
        &=\int_{\mathbb{R}_0^+}\bigg(\int_{[0,\,x]}\,d\mu_1\bigg)\,d\prob_X(x)\\
        &=\int_{\mathbb{R}_0^+}\bigg(\int_{\mathbb{R}_0^+}\ind_{[0,\,x)}(y)\,d\mu_1(y)\bigg)\,d\prob_X(x)\\
        &=\int_{\mathbb{R}_0^+}\bigg(\int_{\mathbb{R}_0^+}\ind_{[0,\,x)}(y)\,d\prob_X(x)\bigg)\,d\mu_1(y)\\
        &=\int_{\mathbb{R}_0^+}\bigg(\int_{\mathbb{R}_0^+}\ind_{(y,\,\infty)}(x)\,d\prob_X(x)\bigg)\,d\mu_1(y)\\
        &=\int_{\mathbb{R}_0^+}\prob_X((y,\,\infty))\,d\mu_1(y)\\
        &=\int_{\mathbb{R}_0^+}1-F_X(y)\,d\mu_1(y)
    \end{align*}
    이고 이때 $1-F_X$는 $\mathbb{R}_0^+$에서 $\mu_1$-적분가능하다.
\end{proof}

다음으로 넘어가기 전에, 기댓값에 대해 한 가지 유념해야 할 점이 있다. 기댓값의 정의에는 이가 마치 어떤 확률변수의 특성인 것처럼 쓰여 있지만 사실 기댓값은 확률변수의 특성이 아닌, 분포의 특성이어서 서로 다른 확률공간에서 정의된 서로다른 확률변수라도 그 분포가 같다면 기댓값도 같다. 실제로 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 $(\Omega',\,\mathcal{F}',\,\mathbb{P}')$에서 각각 정의된 확률변수 $X:\Omega\to\mathbb{R},\,Y:\Omega'\to\mathbb{R}$에 대해 만약 $X\equiv Y$라면 정리 \ref{thm:expectDistribution}로부터 $\expect(X)=\int_{\mathbb{R}^n}x\,d\prob_X(x)=\int_{\mathbb{R}^n}y\,d\prob_Y(y)=\expect(Y)$이다. 이러한 사실은 기댓값이 분포의 정보를 요약하여 전달하는 통계량이라는 점에서 어떻게 보면 당연한 것이다.

기댓값에 이어 살펴볼 통계량은 분산이다. 기댓값이 분포의 정보를 요약하여 전달하는 좋은 통계량인 것은 사실이지만, 이가 분포의 정보를 완벽하게 전달하지는 못한다. 이때 발생하는 정보의 손실이 크게 중요하지 않은 경우도 있지만, 때로는 기댓값만으로는 부족한 경우도 있다. 이에 기댓값만을 전달할 때 손실되는 정보를 보충할 목적으로 보조적인 통계량을 제공할 수 있는데, 보통 분포가 기댓값으로부터 퍼져있는 정도를 의미하는 분산이나 표준편차를 제공한다. (이와 같이 분포가 퍼져있는 정도를 의미하는 통계량을 그 분포의 산포도라 하며 분산과 표준편차 이외에도 평균절대편차, 사분위수범위 등이 있다.) 이러한 분산은 기본적으로 기댓값으로 정의된다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $\expect((X-\mu_X)^2)$이 존재한다면 이를 $X$의 \textbf{분산(\texttt{variance})}이라 하고 $\var(X),\,\sigma_X^2$ 혹은 간단히 $\sigma^2$으로 쓴다. 나아가, $\var(X)$가 존재한다면 $\sqrt{\var(X)}$를 $X$의 \textbf{표준편차(\texttt{standard deviation})}라 하고 $\sd(X),\,\sigma_X$ 혹은 간단히 $\sigma$로 쓴다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재할 필요충분조건은 $\expect(X^2)$이 존재하는 것이다.
\end{proposition}

\begin{proof}
    만약 $\var(X)$가 존재한다면 정의로부터 $\expect(X)$와 $\expect((X-\mu_X)^2)$이 존재하고, 곧 $X^2=(X-\mu_X)^2+2\mu_XX-\mu_X^2$에서 $\expect(X^2)$이 존재함을 안다. 역으로 $\expect(X^2)$이 존재한다면 $|X|\leq X^2\ind_{\{|X|\geq1\}}+\ind_{\{|X|<1\}}\leq X^2+1$에서 $\expect(X)$가 존재함을 알고,곧 $(X-\mu_X)^2=X^2-2\mu_XX+\mu_X^2$에서 $\var(X)=\expect((X-\mu_X)^2)$이 존재한다.
\end{proof}

분산의 기본적인 성질은 모두 기댓값의 성질에 기인하다. 특히 다음 정리의 ii는 간단한 공식이지만 분산을 실제로 계산할 때 유용하게 사용되는 공식이다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재한다면 다음이 성립한다.
    \begin{enumerate}
        \item $\var(X)\geq0$.
        \item $\var(X)=\expect(X^2)-\mu_X^2$.
        \item 임의의 $a,\,b\in\mathbb{R}$에 대해 $\var(aX+b)$가 존재하고 $\var(aX+b)=a^2\var(X)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 $(X-\mu_X)^2\geq0$에서 자명하다.

    ii. 이는
    \begin{align*}
        \var(X)&=\expect((X-\mu_X)^2)\\
        &=\expect(X^2-2\mu_XX+\mu_X^2)\\
        &=\expect(X^2)-2\mu_X\expect(X)+\mu_X^2\\
        &=\expect(X^2)-\mu_X^2
    \end{align*}
    에서 자명하다.

    ii. 우선 $\var(X)$가 존재하므로 $\expect(X)$와 $\expect(X^2)$이 존재하여 $\expect((aX+b)^2)=\expect(a^2X^2+2abX+b^2)$가 존재하여 $\var(aX+b)$도 존재한다. 이제
    \begin{align*}
        \var(aX+b)&=\expect([aX+b-\expect(aX+b)]^2)\\
        &=\expect(a^2[X-\expect(X)]^2)\\
        &=a^2\expect((X-\mu_X)^2)\\
        &=a^2\var(X)
    \end{align*}
   에서 정리는 자명하다.
\end{proof}

기댓값과 분산의 성질로부터 $\var(X)$가 존재하고 $0$이 아니라면 $(X-\mu_X)/\sigma_X$의 기댓값과 분산은 항상 각각 $0,\,1$이다. 이렇게 원래의 확률변수에서 그 기댓값을 빼고, 그 표준편차로 나누는 것을 \textbf{표준화(\texttt{standardization})}라 하며, 기댓값과 분산이 서로다른 분포를 비교할 때 자주 사용되는 방법이다. 한편, 기댓값과 분산은 각각 다음과 같이 $\expect((X-x)^2)$가 최솟값을 갖도록 하는 값과 그 최솟값으로 정의할 수도 있다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재하면 함수 $x\mapsto\expect((X-x)^2)$는 \texttt{well-define}되고 $\expect(X)$에서 최솟값 $\var(X)$를 가진다.
\end{theorem}

\begin{proof}
    가정으로부터 $\expect(X)$와 $\expect(X^2)$이 존재하고 곧 임의의 $x\in\mathbb{R}$에 대해 $(X-x)^2=X^2-2xX+x^2$에서 $\expect((X-x)^2)$이 존재하므로 함수 $x\mapsto\expect((X-x)^2)$가 \texttt{well-define}된다. 한편, 임의의 $x\in\mathbb{R}$에 대해 $(X-x)^2=(X-\mu_X)^2+2(X-\mu_X)(\mu_X-x)+(\mu_X-x)^2$이므로 $\expect((X-x)^2)=\expect((X-\mu_X)^2)+2(\mu_X-x)\expect(X-\mu_X)+(\mu_X-x)^2=\var(X)+(\mu_X-x)^2$에서 정리가 성립한다.
\end{proof}

이제 기댓값에 관한 다양한 부등식을 알아보는 것으로 이번 절을 마무리하자. 이러한 부등식은 이후 확률론의 다양한 정리를 증명할 때에 약방의 감초와 같이 사용될 것이다.

\begin{theorem}[Jensen's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$와 함수 $g:\mathbb{R}\to\mathbb{R}$에 대해 적당한 구간 $I\subseteq\mathbb{R}$가 존재하여 $g$가 $I$에서 볼록하고(혹은 오목하고) $X\in I$ (\texttt{as.})라 하자. 만약 $\expect(X)$와 $\expect(g(X))$가 존재한다면 $g(\expect(X))\leq\expect(g(X))$이다(혹은 $g(\expect(X))\geq\expect(g(X))$이다).
\end{theorem}

\begin{proof}
    먼저 $I$가 열린구간인 경우를 생각하여 $I=(a,\,b)$로 두면 가정과 따름정리 \ref{cor:zeroAeIntegral}의 iii으로부터 $\expect(X)\in I$이다. 한편, $g$가 $I$에서 볼록하므로 $(\expect(X),\,g(\expect(X)))$를 지나는 \texttt{supporting line} $l:y=mx+n$이 존재하여 $mX+n\leq g(X)$ (\texttt{as.})이고, 따라서 $g(\expect(X))=m\expect(X)+n=\expect(mX+n)\leq\expect(g(X))$이다.

    이제 $I$가 닫힌구간인 경우를 생각하여 $I=[a,\,b]$로 두면 가정으로부터 $\expect(X)\in I$인데, 만약 $\expect(X)\in I^\circ$라면 이전과 같이 하여 $g(\expect(X))\leq\expect(g(X))$임을 보일 수 있으므로 $\expect(X)$가 $I$의 양 끝점인 경우만 고려하면 된다. 간결한 논의를 위해, $\expect(X)=b$라 하자. (반대로 $\expect(X)=a$인 경우에도 이와 비슷하게 하면 된다.) 그렇다면 정리 \ref{thm:zeroAeIntegral}의 ii로부터 $X=b$ (\texttt{as.})이므로 $g(X)=g(b)$ (\texttt{as.})에서 $g(\expect(X))=g(b)=\expect(g(X))$이고, 증명이 끝난다.

    한편, 구간 $I$가 한쪽 끝점만 포함하는 경우에도 $I$가 닫힌구간인 경우와 비슷하게 하면 같은 결론을 얻고, $g$가 $I$에서 오목한 경우에는 $-g$를 생각하면 되므로 증명은 이로써 충분하다.
\end{proof}

\begin{theorem}[H\"older's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$와 $1/p+1/q=1$인 $p,\,q>1$에 대해 $\expect(|X|^p)$와 $\expect(|Y|^q)$가 존재한다면 $\expect(|XY|)$도 존재하고 $\expect(|XY|)\leq[\expect(|X|^p)]^{1/p}[\expect(|Y|^q)]^{1/q}$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{H\"older}의 부등식으로부터 자명하다.
\end{proof}

\begin{theorem}[Minkowski's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$와 $p\geq1$에 대해 $\expect(|X|^p)$와 $\expect(|Y|^p)$가 존재한다면 $\expect(|X+Y|^p)$도 존재하고 $[\expect(|X+Y|^p)]^{1/p}\leq[\expect(|X|^p)]^{1/p}+[\expect(|Y|^p)]^{1/p}$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{Minkowski}의 부등식으로부터 자명하다.
\end{proof}

\begin{corollary}[Cauchy-Schwarz's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$에 대해 $\expect(X^2)$과 $\expect(Y^2)$이 존재한다면 $\expect(|XY|)$도 존재하고 $\expect(|XY|)\leq\sqrt{\expect(X^2)\expect(Y^2)}$이다.
\end{corollary}

\begin{proof}
    이는 \texttt{H\"older}의 부등식에서 $p=q=2$인 특수한 경우이다.
\end{proof}

\begin{theorem}[Liapounov's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 $0<p<q$인 $p,\,q\in\mathbb{R}$에 대해 $\expect(|X|^q)$가 존재한다면 $\expect(|X|^p)$도 존재하고 $[\expect(|X|^p)]^{1/p}\leq[\expect(|X|^q)]^{1/q}$이다.
\end{theorem}

\begin{proof}
    우선 $|X|^p\leq|X|^q\ind_{\{|X|\geq1\}}+\ind_{\{|X|<1\}}\leq|X|^q+1$에서 $\expect(|X|^p)$가 존재함을 안다. 이제 함수 $g:\mathbb{R}\to\mathbb{R}$를 $g:x\mapsto x^{q/p}\ind_{\mathbb{R}_0^+}(x)$로 두면 이는 볼록함수이므로 \texttt{Jensen}의 부등식으로부터 $[\expect(|X|^p)]^{q/p}=g(\expect(|X|^p))\leq\expect(g(|X|^p))=\expect(|X|^q)$이고, 곧 증명이 끝난다.
\end{proof}

아래의 두 부등식은 증명의 도구로 쓰일 뿐만 아니라 어떤 확률분포가 특정 값을 얼마 이상 벗어날 확률에 대한 상계의 역할을 한다. 이를 두고 아래의 두 부등식이 `\texttt{tail probability}를 \texttt{bounding}한다'고 한다.

\begin{theorem}[Markov's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 $p>0$에 대해 $\expect(|X|^p)$가 존재한다면 임의의 $x>0$에 대해 $\mathbb{P}\{|X|\geq x\}\leq\expect(|X|^p)/x^p$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{Markov}의 부등식으로부터 자명하다.
\end{proof}

\begin{corollary}[Chebyshev's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재한다면 임의의 $x>0$에 대해 $\mathbb{P}\{|X-\mu_X|\geq x\}\leq\var(X)/x^2$이다.
\end{corollary}

\begin{proof}
    이는 \texttt{rv.} $X-\mu_X$에 $p=2$인 경우의 \texttt{Markov}의 부등식을 적용한 결과이다.
\end{proof}

다음은 \texttt{Chebyshev}의 부등식의 기초적인 응용으로, 분산이 $0$이라는 것의 의미를 잘 나태내준다. 이 결과는 이후에 이따금씩 쓰일 것이다.

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)=0$이면 $\expect(X)$가 존재하고 $X=\expect(X)$ (\texttt{as.})이다.
\end{proposition}

\begin{proof}
    우선 $\expect(X)$가 존재함은 자명하다. 이제 사건열 $\{E_i\}$를 $E_i=\{|X-\mu_X|>1/i\}$로 두면 이는 $\{X\ne\mu_X\}$로 수렴하는 사건열로 $\mathbb{P}\{X=\mu_X\}=1-\mathbb{P}\{X\ne\mu_X\}=1-\lim_{i\to\infty}\mathbb{P}(E_i)$이다. 한편, 각 $i\in\mathbb{N}$에 대해 \texttt{Chebyshev}의 부등식으로부터 $\mathbb{P}(E_i)\leq\var(X)/i^2=0$이므로 $\mathbb{P}(E_i)\to0$에서 $\mathbb{P}\{X=\mu_X\}=1$임을 안다.
\end{proof}

\section{Moments}

이번 절에서는 적률이라는 통계량에 대해 알아본다. 앞서 어떤 분포에 대한 정보를 간단히 전달하기 위해 기댓값이나 분산을 사용하였듯이 적률 또한 어떤 분포의 정보를 전달하기 위해 사용한다. 당장에 기댓값과 분산도 적률의 일종이다. 형식적으로 $k$차 적률은 확률변수 $X$의 $k$제곱의 기댓값으로 정의되는데, 기댓값이나 분산이 그 자체로 나름의 의미를 가지는 것과 달리 $k$차 적률 그 자체의 의미를 해석하는 것은 쉽지 않다. 그럼에도 불구하고, 하나의 절을 할애하여 적률에 대해 논하는 까닭은 많은 경우에 적률은 분포의 정보를 `손실 없이' 전달할 수 있기 때문이다. 즉, 모든 차수의 적률을 수열의 형태로 전달하면 그것만으로 분포를 완벽하게 복원해낼 수 있다. 그렇다면 적률의 정의부터 시작하자.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 $k\in\mathbb{N}_0$에 대해 다음을 정의한다.
    \begin{enumerate}
        \item 만약 $\expect(X^k)$가 존재한다면 이를 $X$의 \textbf{$k$차 적률($k$\texttt{th moment})}이라 하고 $\mu_{k,\,X}$ 혹은 간단히 $\mu_k$로 쓴다.
        \item 만약 $\expect((X-\mu_X)^k)$가 존재한다면 이를 $X$의 \textbf{$k$차 중심화된 적률($n$\texttt{th centeral moment})}이라 하고 $\tau_{k,\,X}$ 혹은 간단히 $\tau_k$로 쓴다.
        \item 만약 $\expect([(X-\mu_X)/\sigma_X]^k)$가 존재한다면 이를 $X$의 \textbf{$k$차 표준화된 적률($k$\texttt{th standardized moment})}이라 하고 $\kappa_{k,\,X}$ 혹은 간단히 $\kappa_k$로 쓴다.
        \item 만약 $\expect(X^{\underline{k}})$가 존재한다면 이를 $X$의 \textbf{$k$차 (하향)계승적률($k$\texttt{th} (\texttt{falling}) \texttt{factorial moment})}이라 하고 $\mu_{\underline{k},\,X}$ 혹은 간단히 $\mu_{\underline{k}}$로 쓴다.
        \item 만약 $\expect(X^{\overline{k}})$가 존재한다면 이를 $X$의 \textbf{$k$차 (상향)계승적률($n$\texttt{th} (\texttt{rising}) \texttt{factorial moment})}이라 하고 $\mu_{\overline{k},\,X}$ 혹은 간단히 $\mu_{\overline{k}}$로 쓴다.
    \end{enumerate}
\end{definition}

위에서 정의한 적률을 제외하고도 많은 종류의 적률이 존재하는데, 이는 계산상의 편의를 위한 목적이 크다. 나아가 중심화된 적률과 표준화된 적률은 그 이름에서도 알 수 있듯이 각각 원래 확률변수의 평행이동과 \texttt{Affine} 변환에 대해 불변이라는 유용한 특성을 가지기도 한다. 한편, 적률의 존재성을 따지는 데에는 다음 두 명제가 유용하다.

\begin{proposition}\label{prop:lowerMomentExist}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $X$의 $k$차 적률(혹은 중심화된 적률, 표준화된 적률, 하향계승적률, 상향계승적률)이 존재하면 $X$의 $1,\,\cdots,\,k$차 적률(혹은 중심화된 적률, 표준화된 적률, 하향계승적률, 상향계승적률)이 존재한다.
\end{proposition}

\begin{proof}
    만약 $k\leq1$이면 명제가 자명하므로 $k>1$이라 하자. 먼저 적률, 중심화된 적률, 표준화된 적률의 경우는 \texttt{Liapounov}의 부등식으로부터 자명하다. 한편, 하향계승적률의 경우, 만약 $X$의 $k$차 하향계승적률이 존재한다면 $X^{\underline{k}}=X^{\underline{k-1}}(X-k+1)$에서
    \begin{align*}
        |X^{\underline{k-1}}|&=\bigg|\frac{X^{\underline{k}}}{X-k+1}\bigg|\ind_{\{|X-k+1|\geq1\}}+|X^{\underline{k-1}}|\ind_{\{|X-k+1|<1\}}\\
        &\leq|X^{\underline{k}}|\ind_{\{|X-k+1|\geq1\}}+|X^{\underline{k-1}}|\ind_{\{|X-k+1|<1\}}\\
        &<|X^{\underline{k}}|+k!
    \end{align*}
    이다. 여기서 마지막 부등호는 함수 $x\mapsto|x^{\underline{k-1}}|$이 $(k-2,\,\infty)$에서 증가하므로 성립한다. 이로부터 $X$의 $k-1$차 하향계승적률이 존재함을 알고, 이를 $k-2$번 반복하면 $X$의 $1,\,\cdots,\,k$차 하향계승적률이 존재함을 안다. 마지막으로 상향계승적률의 경우에는 하향계승적률과 비슷하게 하면 된다.
\end{proof}

\begin{proposition}\label{prop:momentExist}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 \texttt{TFAE}.
    \begin{enumerate}
        \item \texttt{Rv.} $X$의 $k$차 적률이 존재한다.
        \item \texttt{Rv.} $X$의 $k$차 중심화된 적률이 존재한다.
        \item \texttt{Rv.} $X$의 $k$차 표준화된 적률이 존재한다.
        \item \texttt{Rv.} $X$의 $k$차 하향계승적률이 존재한다.
        \item \texttt{Rv.} $X$의 $k$차 상향계승적률이 존재한다.
    \end{enumerate}
    단, ii의 경우 $\expect(X)$가 존재함을 전제로 하고, iii의 경우 $\var(X)$가 존재하며 $0$이 아님을 전제로 한다.
\end{proposition}

\begin{proof}
    만약 $k=0$이면 명제가 자명하므로 $k>0$이라 하자.

    i $\Leftrightarrow$ ii. 만약 $X$의 $k$차 적률이 존재하면 명제 \ref{prop:lowerMomentExist}로부터 $X$의 $1,\,\cdots,\,k$차 적률이 존재한다. 이로부터
    \begin{equation*}
        (X-\mu_X)^k=\sum_{l=0}^k(-1)^{k-l}\binom{k}{l}X^l\mu_X^{k-l}
    \end{equation*}
    에서 $X$의 $k$차 중심화된 적률이 존재한다. 역으로, $\expect(X)$가 존재하고 $X$의 $k$차 중심화된 적률이 존재하면 다시 명제 \ref{prop:lowerMomentExist}로부터 $X$의 $1,\,\cdots,\,k$차 중심화된 적률이 존재한다. 그렇다면
    \begin{align*}
        X^k&=(X-\mu_X+\mu_X)^k\\
        &=\sum_{l=0}^k\binom{k}{l}(X-\mu_X)^l\mu_X^{k-l}
    \end{align*}
    에서 $X$의 $k$차 적률이 존재한다.

    ii $\Leftrightarrow$ iii. 이는 정의로부터 자명하다.

    i $\Rightarrow$ iv. 명제 \ref{prop:lowerMomentExist}로부터 $X$의 $1,\,\cdots,\,k$차 적률이 존재하는데, 적당한 $a_0,\,\cdots,\,a_k\in\mathbb{R}$에 대해 $X^{\underline{k}}=\prod_{l=0}^{k-1}(X-l)=\sum_{l=0}^ka_lX^l$이므로 곧 $X$의 $k$차 하향계승적률이 존재한다.

    iv $\Rightarrow$ i. 이번에도 명제 \ref{prop:lowerMomentExist}로부터 $X$의 $1,\,\cdots,\,k$차 하향계승적률이 존재한다. 한편, 적당한 $a_0,\,\cdots,\,a_k\in\mathbb{R}$에 대해 $X^{\underline{k}}=\prod_{l=0}^{k-1}(X-l)=\sum_{l=0}^ka_lX^l$이고 이때 $a_k=1$임이 명백하므로 $X^k=X^{\underline{k}}-\sum_{l=0}^{k-1}a_lX^l$이다. 이를 $k-1$번 반복하면 다시 적당한 $b_0,\,\cdots,\,b_k\in\mathbb{R}$에 대해 $X^k=\sum_{l=0}^kb_lX^{\underline{l}}$이고, 곧 $X$의 $k$차 적률이 존재한다.

    i $\Leftrightarrow$ v. 이는 i $\Leftrightarrow$ iv의 증명과 비슷하게 하면 된다.
\end{proof}

앞서 적률 그 자체에 의미를 해석하는 것은 쉽지 않다고 했는데, 특별히 $3$차와 $4$차 표준화된 적률에 대해서는 어느정도 널리 받아들여지는 해석이 있어 잠시 소개한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $X$의 $3$차 표준화된 적률이 존재한다면 이를 특별히 $X$의 \textbf{왜도(\texttt{skewness})}라 하고 $\skew(X),\,\tau_X$ 혹은 간단히 $\tau$로 쓴다. 비슷하게, $X$의 $4$차 표준화된 적률이 존재한다면 $\kappa_{4,\,X}-3$을 특별히 $X$의 \textbf{(\texttt{excess}) 첨도(- \texttt{kurtosis})}라 하고 $\kurt(X),\,\kappa_X$ 혹은 간단히 $\kappa$로 쓴다.
\end{definition}

왜도는 분포가 얼마나 치우쳤는가, 즉 얼마나 비대칭인가에 대한 척도이다. 정규분포와 같이 분포가 기댓값을 기준으로 정확히 대칭을 이루면 왜도는 $0$이 되고, 기댓값이 분포의 중앙값보다 작아서 분포가 왼쪽으로 치우쳐 있으면 왜도는 양수가 되며 이때 그 분포는 \textbf{\texttt{positively skewed}}되었다고 한다. 반대로 기댓값이 분포의 중앙값보다 커서 분포가 오른쪽으로 치우쳐 있으면 왜도는 음수가 되며 이때 그 분포는 \textbf{\texttt{negatively skewed}}되었다고 한다.

첨도는 분포가 얼마나 뾰족한가, 즉 분포의 꼬리가 얼마나 두꺼운가에 대한 척도이다. 왜도와는 달리 $4$차 표준화된 적률에서 $3$을 뺀 것으로 정의되어 있는데, 이는 표준정규분포의 $4$차 표준화된 적률이 $3$인 바, 비교의 기준이 되는 표준정규분포의 첨도를 $0$으로 만들기 위함이다. 표준정규분포와 같이 첨도가 $0$이면 이때 그 분포는 \textbf{\texttt{mesokurtic}}하다고 하고, 표준정규분포보다 얇은 꼬리를 가지면 첨도는 양수가 되며 이때 그 분포는 \textbf{\texttt{leptokurtic}}하다고 한다. 반대로 표준정규분포보다 두꺼운 꼬리를 가지면 첨도는 음수가 되며 이때 그 분포는 \textbf{\texttt{platykurtic}}하다고 한다. 일반적으로 꼬리의 두께는 \texttt{outlier}와 같은 극단적 사건의 발생확률을 의미하므로 \texttt{leptokurtic}한 분포와 \texttt{platykurtic}한 분포는 표준정규분포에 비해 극단적 사건의 확률이 각각 더 낮고 높다.

한편, 왜도와 첨도는 모두 \texttt{Affine} 변환에 대해 불변이다. 다만, 왜도의 경우 부호 정도의 영향은 받으며, 이는 그 정의를 생각해보면 당연하다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 임의의 $a,\,b\in\mathbb{R}$에 대해 $a\ne0$이면 다음이 성립한다.
    \begin{enumerate}
        \item 만약 $\skew(X)$가 존재하면 $\skew(aX+b)$도 존재하고 $\skew(aX+b)=\sgn(a)\skew(X)$이다.
        \item 만약 $\kurt(X)$가 존재하면 $\kurt(aX+b)$도 존재하고 $\kurt(aX+b)=\kurt(X)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    먼저 $a\ne0$이므로 $\var(aX+b)=a^2\var(X)\ne0$이다. 또한, $\skew(X)$가 존재하면 $X$의 $3$차 적률이 존재하여 곧 $\expect(X),\,\expect(X^2),\,\expect(X^3)$이 모두 존재하며, 이로부터 $\expect((aX+b)^3)=a^3\expect(X^3)+3a^2b\expect(X^2)+3ab^2\expect(X)+b^3$이 존재하므로 $\skew(aX+b)$도 존재한다. 한편,
    \begin{align*}
        \skew(aX+b)&=\expect\bigg(\bigg(\frac{aX+b-\mu_{aX+b}}{\sigma_{aX+b}}\bigg)^3\bigg)\\
        &=\expect\bigg(\bigg[\frac{a(X-\mu_X)}{|a|\sigma_X}\bigg]^3\bigg)\\
        &=\expect\bigg(\sgn(a)\bigg(\frac{X-\mu_X}{\sigma_X}\bigg)^3\bigg)\\
        &=\sgn(a)\skew(X)
    \end{align*}
    에서 i이 성립한다. 비슷하게 $\kurt(X)$가 존재하면 $\kurt(aX+b)$도 존재하고
    \begin{align*}
        \kurt(aX+b)&=\expect\bigg(\bigg(\frac{aX+b-\mu_{aX+b}}{\sigma_{aX+b}}\bigg)^4\bigg)-3\\
        &=\expect\bigg(\bigg[\frac{a(X-\mu_X)}{|a|\sigma_X}\bigg]^4\bigg)-3\\
        &=\expect\bigg(\bigg(\frac{X-\mu_X}{\sigma_X}\bigg)^4\bigg)-3\\
        &=\kurt(X)
    \end{align*}
    에서 ii가 성립한다.
\end{proof}

적률은 확률벡터에 대해 보다 일반적으로 정의할 수도 있다. 물론, 이렇게 확률벡터에 대해 정의된 적률에 대해서도 명제 \ref{prop:lowerMomentExist}, \ref{prop:momentExist}는 비슷하게 성립한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 $\alpha\in\mathbb{N}_0^n$에 대해 다음을 정의한다.
    \begin{enumerate}
        \item 만약 $\expect(X^\alpha)$가 존재한다면 이를 $X$의 \textbf{$|\alpha|$차 (결합)적률($|\alpha|$\texttt{th} (\texttt{joint}) \texttt{moment})}이라 하고 $\mu_{\alpha,\,X}$ 혹은 간단히 $\mu_\alpha$로 쓴다.
        \item 만약 $\expect((X_i-\mu_{X_i})^\alpha)$가 존재한다면 이를 $X$의 \textbf{$|\alpha|$차 중심화된 (결합)적률($|\alpha|$\texttt{th} (\texttt{joint}) \texttt{centeral moment})}이라 하고 $\tau_{\alpha,\,X}$ 혹은 간단히 $\tau_\alpha$로 쓴다.
        \item 만약 $\expect(((X_i-\mu_{X_i})/\sigma_{X_i})^\alpha)$가 존재한다면 이를 $X$의 \textbf{$|\alpha|$차 표준화된 (결합)적률($|\alpha|$\texttt{th} (\texttt{joint}) \texttt{standardized moment})}이라 하고 $\kappa_{\alpha,\,X}$ 혹은 간단히 $\kappa_\alpha$로 쓴다.
        \item 만약 $\expect(X^{\underline{\alpha}})$가 존재한다면 이를 $X$의 \textbf{$|\alpha|$차 (하향결합)계승적률($|\alpha|$\texttt{th} (\texttt{joint falling}) \texttt{factorial moment})}이라 하고 $\mu_{\underline{\alpha},\,X}$ 혹은 간단히 $\mu_{\underline{\alpha}}$로 쓴다.
        \item 만약 $\expect(X^{\overline{\alpha}})$가 존재한다면 이를 $X$의 \textbf{$|\alpha|$차 (상향결합)계승적률($|\alpha|$\texttt{th} (\texttt{joint rising}) \texttt{factorial moment})}이라 하고 $\mu_{\overline{\alpha},\,X}$ 혹은 간단히 $\mu_{\overline{\alpha}}$로 쓴다.
    \end{enumerate}
\end{definition}

\begin{proposition}\label{prop:lowerJointMomentExist}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 만약 $X$의 모든 $k$차 적률(혹은 중심화된 적률, 표준화된 적률, 하향계승적률, 상향계승적률)이 존재하면 $X$의 모든 $1,\,\cdots,\,k$차 적률(혹은 중심화된 적률, 표준화된 적률, 하향계승적률, 상향계승적률)이 존재한다.
\end{proposition}

\begin{proof}
    만약 $k=0$이면 명제가 자명하므로 $k>0$이라 하고, 적률에 대해서는 수학적 귀납법을 사용하자. 우선 각 $i\leq n$에 대해 $\expect(X_i^k)$가 존재하므로 $\expect(X_i)$도 존재하여 모든 $1$차 적률이 존재한다. 이제 귀납가정으로서 $l<k$에 대해 모든 $1,\,\cdots,\,l$차 적률이 존재한다고 하고 $|\alpha|=l+1$인 임의의 $\alpha\in\mathbb{N}_0^n$를 택하여 \texttt{WLOG}, $\alpha_1\ne0$이라 하면
    \begin{align*}
        |X^\alpha|&\leq|X_1|^{\alpha_1+k-l-1}\prod_{i=2}^n|X_i|^{\alpha_i}\ind_{\{|X_1|\geq1\}}+\prod_{i=2}^n|X_i|^{\alpha_i}\ind_{\{|X_1|<1\}}\\
        &\leq|X_1|^{\alpha_1+k-l-1}\prod_{i=2}^n|X_i|^{\alpha_i}+\prod_{i=2}^n|X_i|^{\alpha_i}
    \end{align*}
    에서 $\expect(|X^\alpha|)$가 존재함을 알고, 곧 모든 $l+1$차 적률이 존재하여 모든 $1,\,\cdots,\,k$차 적률이 존재함을 안다. 한편, 중심화된 적률과 표준화된 적률에 대해서도 이와 비슷하게 하면 된다.

    다음으로 $X$의 하향계승적률에 대해서도 수학적 귀납법을 사용하자. 우선 각 $i\leq n$에 대해 $\expect(X_i^{\underline{k}})$가 존재하므로 $\expect(X_i)$도 존재하여 모든 $1$차 하향계승적률이 존재한다. 이제 귀납가정으로서 $l<k$에 대해 모든 $1,\,\cdots,\,l$차 하향계승적률이 존재한다고 하고 $|\alpha|=l+1$인 임의의 $\alpha\in\mathbb{N}_0^n$을 택하여 \texttt{WLOG}, $\alpha_1\ne0$이라 하자. 한편, 함수 $f,\,g:\mathbb{R}\to\mathbb{R}$를 각각 $f:x\mapsto|(x-\alpha_1)^{\underline{k-l-1}}|,\,g:x\mapsto|x^{\underline{\alpha_1}}|$이라 두면 적당한 $M>\alpha_1+k-l-2$이 존재하여 $(-\infty,\,-M)$와 $(M,\,\infty)$에서 $f$는 각각 감소하고 증가하며 $f(-M),\,f(M)\geq1$이고 $(-M,\,M)$에서 $g<g(M)=M^{\underline{\alpha_1}}$이다. 이상을 종합하면 $X^{\underline{\alpha_1+k-l-1}}=X^{\underline{\alpha_1}}(X_1-\alpha_1)^{\underline{k-l-1}}$에서
    \begin{align*}
        |X^{\underline{\alpha}}|&=\frac{|X_1^{\underline{\alpha_1+k-l-1}}|}{|(X_1-\alpha_1)^{\underline{k-l-1}}|}\bigg(\prod_{i=2}^n|X_i^{\underline{\alpha_i}}|\bigg)\ind_{\{|X_1|\geq M\}}+|X^{\underline{\alpha}}|\ind_{\{|X_1|<M\}}\\
        &\leq|X_1^{\underline{\alpha_1+k-l-1}}|\bigg(\prod_{i=2}^n|X_i^{\underline{\alpha_i}}|\bigg)\ind_{\{|X_1|\geq M\}}+M^{\underline{\alpha_1}}\bigg(\prod_{i=2}^n|X_i^{\underline{\alpha_i}}|\bigg)\ind_{\{|X_1|<M\}}\\
        &<|X_1^{\underline{\alpha_1+k-l-1}}|\prod_{i=2}^n|X_i^{\underline{\alpha_i}}|+M^{\underline{\alpha_1}}\prod_{i=2}^n|X_i^{\underline{\alpha_i}}|
    \end{align*}
    이므로 $\expect(|X^{\underline{\alpha}}|)$가 존재함을 알고, 곧 모든 $l+1$차 하향계승적률이 존재하여 모든 $1,\,\cdots,\,k$차 하향계승적률이 존재함을 안다. 마지막으로 상향계승적률의 경우에는 하향계승적률과 비슷하게 하면 된다.
\end{proof}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{TFAE}.
    \begin{enumerate}
        \item \texttt{Rv.} $X$의 모든 $k$차 적률이 존재한다.
        \item \texttt{Rv.} $X$의 모든 $k$차 중심화된 적률이 존재한다.
        \item \texttt{Rv.} $X$의 모든 $k$차 표준화된 적률이 존재한다.
        \item \texttt{Rv.} $X$의 모든 $k$차 하향계승적률이 존재한다.
        \item \texttt{Rv.} $X$의 모든 $k$차 상향계승적률이 존재한다.
    \end{enumerate}
    단, ii의 경우 각 $i\leq n$에 대해 $\expect(X_i)$가 존재함을 전제로 하고, iii의 경우 각 $i\leq n$에 대해 $\var(X_i)$가 존재하며 $0$이 아님을 전제로 한다.
\end{proposition}

\begin{proof}
    만약 $k=0$이면 명제가 자명하므로 $k>0$이라 하자.

    i $\Leftrightarrow$ ii. 만약 $X$의 모든 $k$차 적률이 존재하면 명제 \ref{prop:lowerJointMomentExist}로부터 $X$의 모든 $1,\,\cdots,\,k$차 적률이 존재한다. 이제 $|\alpha|=k$인 임의의 $\alpha\in\mathbb{N}_0^n$에 대해 $(X_i-\mu_{X_i})^\alpha$의 전개식에서 $X^\alpha$가 최고차항임을 생각해보면 충분조건임이 자명하고, 필요조건임도 이와 비슷하게 보일 수 있다.

    ii $\Leftrightarrow$ iii. 이는 정의로부터 자명하다.

    i $\Rightarrow$ iv. 명제 \ref{prop:lowerJointMomentExist}로부터 $X$의 모든 $1,\,\cdots,\,k$차 적률이 존재하는데, $|\alpha|=k$인 임의의 $\alpha\in\mathbb{N}_0^n$에 대해 $X^{\underline{\alpha}}=\prod_{i=1}^n\prod_{j=0}^{\alpha_i-1}(X_i-j)$의 전개식에서 $X^\alpha$가 최고차항임을 생각해보면 명제가 자명하다.

    iv $\Rightarrow$ i. 수학적 귀납법을 사용하기 위해 증명하고자 하는 명제를 $\mathsf{P}(k)$라 하자. 우선 $\mathsf{P}(1)$은 명제 \ref{prop:momentExist}로부터 자명하다. 이제 귀납가정으로서 $l<k$에 대해 $\mathsf{P}(1),\,\cdots,\,\mathsf{P}(l)$이 모두 성립한다고 하고 모든 $l+1$차 하향계승적률이 존재한다고 하여 $|\alpha|=l+1$인 임의의 $\alpha\in\mathbb{N}_0^n$을 택하자. 그렇다면 명제 \ref{prop:lowerJointMomentExist}로부터 $X$의 모든 $1,\,\cdots,\,l+1$차 하향계승적률이 존재하고, $X^{\underline{\alpha}}=\prod_{i=1}^n\prod_{j=0}^{\alpha_i-1}(X_i-j)$의 전개식에서 $X^\alpha$가 최고차항이므로 $X^\alpha$는 $X^{\underline{\alpha}}$와 $1,\,\cdots,\,l$차항 그리고 상수항의 선형결합으로 쓸 수 있어서 $\expect(X^\alpha)$가 존재하여 $\mathsf{P}(l+1)$도 성립하고, 곧 임의의 $k\in\mathbb{N}$에 대해 $\mathsf{P}(k)$가 성립한다.

    i $\Leftrightarrow$ v. 이는 i $\Leftrightarrow$ iv의 증명과 비슷하게 하면 된다.
\end{proof}

보통 적률에 대한 이론을 전개할 때에는 적률을 그 자체로 다루는 것보다 아래의 \texttt{MGF}를 통해 다루는 것이 더 편리하다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$가 존재하여 임의의 $t\in U$에 대해 $\expect(e^{t^\trans X})$가 존재하면 \texttt{rv.} $X$의 \textbf{적률생성함수(\texttt{moment generating function})}를 $M_X:U\to\mathbb{R}$로 쓰고 $M_X:t\mapsto\expect(e^{t^\trans X})$로 정의한다. 특별히, $n\geq2$인 경우 $M_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합적률생성함수(\texttt{joint moment generating function})}라 하기도 한다.
\end{definition}

\begin{theorem}\label{thm:MGFProp}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $M_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재하면 다음이 성립한다.
    \begin{enumerate}
        \item $M_X(0)=1$.
        \item $M_X>0$.
        \item \texttt{MGF} $M_X$는 \texttt{log}-볼록하다.
        \item 임의의 $a\in\mathbb{R}$와 임의의 $b\in\mathbb{R}^n$에 대해 $M_{aX+b}$가 적당한 $0$의 근방 $V\subseteq\mathbb{R}^n$ 위에서 존재하고, $at\in U$인 임의의 $t\in V$에 대해 $M_{aX+b}(t)=e^{t^\trans b}M_X(at)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 $M_X(0)=\expect(1)=1$에서 자명하다.

    ii. 따름정리 \ref{cor:zeroAeIntegral}의 iii으로부터 임의의 $t\in\mathbb{R}^n$에 대해 $M_X(t)=\expect(e^{t^\trans X})>\expect(0)=0$이므로 이는 자명하다.

    iii. 임의의 $s,\,t\in U$와 $\lambda\in(0,\,1)$에 대해 \texttt{H\"older}의 부등식으로부터 $M_X(\lambda s+(1-\lambda)t)=\expect(e^{[\lambda s+(1-\lambda)t]^\trans X})\leq[\expect(e^{s^\trans X})]^\lambda[\expect(e^{t^\trans X})]^{1-\lambda}=M_X(s)^\lambda M_X(t)^{1-\lambda}$이고, ii로부터 $M_X>0$이므로 양변에 \texttt{log}를 취하면 $\log M_X(\lambda s+(1-\lambda)t)\leq\lambda\log M_X(s)+(1-\lambda)\log M_X(t)$이다. 이 부등식이 $\lambda=0,\,1$인 경우에도 성립함이 자명하므로 $M_X$는 \texttt{log}-볼록하다.

    iv. 집합 $V=\{t\in\mathbb{R}^n:at\in U\}$를 생각하면 이는 명백히 $0$의 근방이고, 임의의 $t\in V$에 대해 $\expect(e^{t^\trans(aX+b)})=e^{t^\trans b}\expect(e^{(at)^\trans X})=e^{t^\trans b}M_X(at)$이므로 정리가 성립한다.
\end{proof}

\texttt{MGF}의 정의만 보아서는 이와 적률 사이의 관계를 눈치채기가 쉽지 않다. 이에 다음 정리는 \texttt{MGF}와 적률의 관계를 명시적으로 잘 보여준다.

\begin{lemma}\label{lem:MGFTaylor}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $M_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재하면, 적당한 $0$의 근방 $V\subseteq U$가 존재하여 임의의 $t\in V$에 대해 $\expect(e^{|t|^\trans|X|})$가 존재한다. 특별히, $U=\mathbb{R}^n$이면 $V=\mathbb{R}^n$으로 잡을 수 있다.
\end{lemma}

\begin{proof}
    먼저 $V:=B(||t_0||)\subseteq U$인 $0$이 아닌 $t_0\in U$를 택하고, 이어서 모든 성분이 음이 아닌 임의의 $t\in V$를 택한 뒤, $\mathbb{R}^n$을 $2^n$개의 사분공간으로 나누어 각각을 $A_1,\,\cdots,\,A_{2^n}$이라 하자. (이때 각 사분면의 경계도 적당히 나눈다.) 이제 임의의 $A_j$를 고정하고 임의의 $x\in A_j^\circ$에 대해 $v=(\sgn(x_i))$라 하면 이는 $x$의 선택과는 무관하게 \texttt{well-define}된다. 그렇다면 $s=(v_it_i)\in V$임이 명백하므로
    \begin{align*}
        \int_\Omega e^{t^\trans|X|}\ind_{A_j}(X)\,d\mathbb{P}&=\int_{A_j}e^{t^\trans|x|}\,d\prob_X(x)\\
        &=\int_{A_j}\exp\bigg(\sum_{i=1}^nv_it_ix_i\bigg)\,d\prob_X(x)\\
        &=\int_{A_j}e^{s^\trans x}\,d\prob_X(x)\\
        &\leq\int_{\mathbb{R}^n}e^{s^\trans x}\,d\prob_X(x)\\
        &=\expect(e^{s^\trans X})\\
        &<\infty
    \end{align*}
    에서 $e^{t^\trans|X|}\ind_{A_j}(X)$가 적분가능하고, 곧 $e^{t^\trans|X|}=\sum_{j=1}^{2^n}e^{t^\trans|X|}\ind_{A_j}(X)$도 적분가능하여 $\expect(e^{t^\trans|X|})$가 존재한다. 이는 임의의 $t\in V$에 대해 $\expect(e^{|t|^\trans|X|})$가 존재함을 함의하는 한편, $U=\mathbb{R}^n$인 경우에는 이상의 논의에서 $V=\mathbb{R}^n$으로 택할 수 있음이 분명하므로 증명이 끝난다.
\end{proof}

\begin{theorem}\label{thm:MGFTaylor}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $M_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재하면 $X$의 모든 적률이 존재하고, 적당한 $0$의 근방 $V\subseteq U$가 존재하여 임의의 $t\in V$에 대해 $M_X(t)=\sum_{i=0}^\infty\sum_{|\alpha|=i}\expect(X^\alpha)t^\alpha/\alpha!=\sum_{\alpha\in\mathbb{N}_0^n}\expect(X^\alpha)t^\alpha/\alpha!$이다. 특별히, $U=\mathbb{R}^n$이면 $V=\mathbb{R}^n$으로 잡을 수 있으며, 여기서 급수는 절대수렴하여 \texttt{well-define}된다.
\end{theorem}

\begin{proof}
    먼저 임의의 $\alpha\in\mathbb{N}_0^n$에 대해 $\expect(X^\alpha)$가 존재함을 보이자. 이를 위해 각 성분이 양수인 $t\in U$를 택하면
    \begin{align*}
        |X^\alpha|&=\frac{(t_i|X_i|)^\alpha}{t^\alpha}\\
        &\leq\frac{1}{t^\alpha}\bigg(\sum_{i=1}^nt_i|X_i|\bigg)^{|\alpha|}\bigg/\binom{|\alpha|}{\alpha}\\
        &=\frac{\alpha!}{t^\alpha}\cdot\frac{(t^\trans|X|)^{|\alpha|}}{|\alpha|!}\\
        &\leq\frac{\alpha!}{t^\alpha}\sum_{i=0}^\infty\frac{(t^\trans|X|)^i}{i!}\\
        &=\frac{\alpha!}{t^\alpha}e^{t^\trans|X|}
    \end{align*}
    인데, 보조정리로부터 $t$를 충분히 작게 잡아주면 $\expect(e^{t^\trans|X|})$가 존재하므로 $\expect(X^\alpha)$도 존재함을 알고, 곧 $X$의 모든 적률이 존재한다.

    다음으로, 임의의 $k\in\mathbb{N}_0$와 $t\in U$에 대해
    \begin{align*}
        \bigg|\sum_{i=0}^k\frac{(t^\trans X)^i}{i!}\bigg|&\leq\sum_{i=0}^k\frac{|t^\trans X|^i}{i!}\\
        &\leq\sum_{i=0}^\infty\frac{|t^\trans X|^i}{i!}\\
        &=e^{|t^\trans X|}\\
        &\leq e^{t^\trans X}\ind_{\{t^\trans X\geq0\}}+\ind_{\{t^\trans X<0\}}\\
        &\leq e^{t^\trans X}+1
    \end{align*}
    이므로 \texttt{DCT}에서
    \begin{align*}
        M_X(t)&=\expect\bigg(\sum_{i=0}^\infty\frac{(t^\trans X)^i}{i!}\bigg)\\
        &=\sum_{i=0}^\infty\frac{\expect((t^\trans X)^i)}{i!}\\
        &=\sum_{i=0}^\infty\frac{1}{i!}\sum_{|\alpha|=i}\binom{i}{\alpha}\expect((t_iX_i)^\alpha)\\
        &=\sum_{i=0}^\infty\sum_{|\alpha|=i}\expect(X^\alpha)\frac{t^\alpha}{\alpha!}&\qquad\qquad\qquad\qquad\qquad\qquad(*)
    \end{align*}
    이다. 이제 $V:=B(||t_0||)\subseteq U$인 $0$이 아닌 $t_0\in U$를 택하자. 그렇다면 $\sum_{i=0}^\infty\sum_{|\alpha|=i}|\expect(X^\alpha)t^\alpha/\alpha!|\leq\sum_{i=0}^\infty\sum_{|\alpha|=i}\expect(|X|^\alpha)|t|^\alpha/\alpha!$이므로 보조정리로부터 $t_0$를 충분히 작게 잡아주면 $\expect(e^{|t|^{\,\trans}|X|})$가 존재하고, 위에서와 비슷하게 하여 (*)의 급수가 절대수렴함을 쉽게 보일 수 있다. 이로부터 (*)의 급수에서의 합의 순서를 바꿀 수 있으므로 원하는 형태의 식을 얻고, $U=\mathbb{R}^n$인 경우에는 이상의 논의에서 $V=\mathbb{R}^n$으로 택할 수 있음이 분명하므로 증명이 끝난다.
\end{proof}

한편, \texttt{MGF}는 적률을 계산하는 방법으로도 유용하게 쓰인다.

\begin{theorem}\label{thm:MGFDifferentiation}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $M_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재한다고 하자. 그렇다면 임의의 $\alpha\in\mathbb{N}_0^n$에 대해 $\expect(X^\alpha)=\partial^\alpha M_X(0)$이다.
\end{theorem}

\begin{proof}
    정리 \ref{thm:MGFTaylor}로부터 적당한 $0$의 근방 $V\subseteq U$가 존재하여 임의의 $t\in V$에 대해 $M_X(t)=\sum_{\beta\in\mathbb{N}_0^n}\expect(X^\beta)t^\beta/\beta!$가 절대수렴하는 멱급수이므로 $\partial^\alpha M_X(0)=\sum_{\beta\in\mathbb{N}_0^n}\expect(X^\beta)\partial^\alpha t^\beta\vert_{t=0}/\beta!=\sum_{\beta\geq\alpha}\expect(X^\beta)t^{\beta-\alpha}\vert_{t=0}/(\beta-\alpha)!=\expect(X^\alpha)$이다.
\end{proof}

이렇게 적률과 긴밀하게 연결되어 있는 \texttt{MGF}이지만 이는 그 존재성이 항상 보장되지 않는다는 큰 단점을 가진다. 이론 전개에 있어 이러한 단점은 많은 귀찮음을 유발하므로 자연스럽게 항상 존재하면서도 \texttt{MGF}의 역할을 해 줄수 있는 대체재를 생각해내기에 이르렀는데, 그것이 바로 확률벡터의 \texttt{PDF}의 \texttt{Fourier} 변환인 \texttt{CF}이다. 아래의 정의에서 기댓값에 복소함수가 들어갔는데, 측도론의 에필로그에서 논한 복소함수의 적분에 대한 내용을 그대로 적용하면 된다. 즉, 확률변수 $X,\,Y$에 대해 $\expect(X)$와 $\expect(Y)$가 존재한다면 $\expect(X+\imag Y)=\expect(X)+\imag\expect(Y)$이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{rv.} $X$의 \textbf{특성함수(\texttt{characteristic function})}를 $\varphi_X:\mathbb{R}^n\to\mathbb{C}$로 쓰고 $\varphi_X:t\mapsto\expect(e^{\imag\,t^\trans X})$로 정의한다. 특별히, $n\geq2$인 경우 $\varphi_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합특성함수(\texttt{joint characteristic function})}라 하기도 한다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 임의의 $t\in\mathbb{R}^n$에 대해 $\expect(e^{\imag\,t^\trans X})$가 항상 존재한다. 따라서 $\varphi_X$는 \texttt{well-define}된다.
\end{proposition}

\begin{proof}
    함수 $e^{\imag\,t^\trans X}$의 실수부 $\cos t^\trans X$와 허수부 $\sin t^\trans X$가 모두 적분가능함을 보이면 되는데, 이는 $|\cos t^\trans X|,\,|\sin t^\trans X|\leq1$에서 자명하다.
\end{proof}

\texttt{CF}는 항상 존재한다는 장점과 더불어 함수로서도 훌륭한 성질을 가진다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $\varphi_X(0)=1$.
        \item $|\varphi_X|\leq1$.
        \item $\varphi_X$는 균등연속이다.
        \item 임의의 $a\in\mathbb{R}$와 임의의 $b,\,t\in\mathbb{R}^n$에 대해 $\varphi_{aX+b}(t)=e^{\imag\,t^\trans b}\varphi_X(at)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 $\varphi_X(0)=\expect(1)=1$에서 자명하다.

    ii. 임의의 $t\in\mathbb{R}^n$에 대해 $|\varphi_X(t)|=|\expect(e^{\imag\,t^\trans X})|\leq\expect(|e^{\imag\,t^\trans X}|)=\expect(1)=1$이므로 이는 자명하다.

    iii. 함수 $f:\Omega\times\mathbb{R}^n$를 $f:(\omega,\,t)\mapsto|e^{\imag\,t^\trans X(\omega)}-1|$로 두면 임의의 $\omega\in\Omega$에 대해 \texttt{section} $f_\omega$는 연속이다. 또한, 임의의 $(\omega,\,t)\in\Omega\times\mathbb{R}^n$에 대해 $|e^{\imag\,t^\trans X(\omega)}-1|\leq|e^{\imag\,t^\trans X(\omega)}|+1=2$이므로 임의의 $t\in\mathbb{R}^n$에 대해 \texttt{section} $f^t$는 적분가능하고 $|f|\leq2$이다. 이상으로부터 $f$가 따름정리 \ref{cor:integralContinuous}의 조건을 모두 만족시킴을 알 수 있으므로 함수 $t\mapsto\int_\Omega|e^{\imag\,t^\trans X}-1|\,d\mathbb{P}=\expect(|e^{\imag\,t^\trans X}-1|)$는 연속이다. 특히 이가 $0$에서 연속이므로 $t\to0$이면 $\expect(|e^{\imag\,t^\trans X}-1|)\to0$이고, 곧 임의의 $\epsilon>0$을 택하면 적당한 $\delta>0$가 존재하여 $|t|<\delta$이면 $\expect(|e^{\imag\,t^\trans X}-1|)<\epsilon$이다. 이로부터 $||s-t||<\delta$인 임의의 $s,\,t\in\mathbb{R}^n$에 대해 $|\varphi_X(s)-\varphi_X(t)|=|\expect(e^{\imag\,s^\trans X}-e^{\imag\,t^\trans X})|\leq\expect(|e^{\imag\,t^\trans X}(e^{\imag(s-t)^\trans X}-1)|)=\expect(|e^{\imag(s-t)^\trans X}-1|)<\epsilon$이 되어 $\varphi_X$가 균등연속임을 안다.

    iv. 이는 $\expect(e^{\imag\,t^\trans(aX+b)})=e^{\imag\,t^\trans b}\expect(e^{\imag\,(at)^\trans X})=e^{\imag\,t^\trans b}\varphi_X(at)$에서 자명하다.
\end{proof}

나아가, \texttt{MGF}와 적률의 관계를 잘 보여주었던 정리 \ref{thm:MGFTaylor}, \ref{thm:MGFDifferentiation}가 \texttt{CF}에 대해서도 거의 비슷하게 (사실은 더 잘) 성립한다.

\begin{lemma}\label{lem:expComplex}
    임의의 $x,\,y\in\mathbb{R}^n$와 임의의 $k\in\mathbb{N}_0$에 대해
    \begin{equation*}
        \bigg|e^{\imag x^\trans y}-\sum_{i=0}^k\imag^i\frac{(x^\trans y)^i}{i!}\bigg|\leq\min\bigg\{\frac{(|x|^\trans|y|)^{k+1}}{(k+1)!},\,\frac{2(|x|^\trans|y|)^k}{k!}\bigg\}
    \end{equation*}
    이다.
\end{lemma}

\begin{proof}
    만약 $k=0$이면 임의의 $t\in\mathbb{R}$에 대해 $\cos t\geq 1-|t|$가 성립하여 곧
    \begin{align*}
        |e^{\imag\,x^\trans y}-1|&=|\cos x^\trans y+\imag\sin x^\trans y-1|\\
        &\leq|\cos x^\trans y-1|+|\imag\sin x^\trans y|\\
        &\leq|x^\trans y|+1
    \end{align*}
    에서 보조정리가 자명하므로 $k>0$이라 하자. 그렇다면 \texttt{Taylor}의 정리로부터
    \begin{align*}
        e^{\imag\,x^\trans y}&=\sum_{i=0}^{k-1}\imag^i\frac{(x^\trans y)^i}{i!}+\imag^k\frac{(x^\trans y)^k}{(k-1)!}\int_0^1(1-t)^{k-1}e^{\imag\,tx^\trans y}\,dt\\
        &=\sum_{i=0}^k\imag^i\frac{(x^\trans y)^i}{i!}+\imag^k\frac{(x^\trans y)^k}{(k-1)!}\int_0^1(1-t)^{k-1}(e^{\imag\,tx^\trans y}-1)\,dt
    \end{align*}
    이다. 여기서 마지막 등호는 $\int_0^1(1-t)^{k-1}\,dt=1/k$에서 성립한다. 이로부터
    \begin{align*}
        \bigg|e^{\imag\,x^\trans y}-\sum_{i=0}^k\imag^i\frac{(x^\trans y)^i}{i!}\bigg|&=\bigg|\imag^{k+1}\frac{(x^\trans y)^{k+1}}{k!}\int_0^1(1-t)^ke^{\imag\,tx^\trans y}\,dt\bigg|\\
        &\leq\frac{(|x|^\trans|y|)^{k+1}}{k!}\int_0^1(1-t)^k|e^{\imag\,tx^\trans y}|\,dt\\
        &=\frac{(|x|^\trans|y|)^{k+1}}{k!}\int_0^1(1-t)^k\,dt\\
        &=\frac{(|x|^\trans|y|)^{k+1}}{(k+1)!}
    \end{align*}
    이고
    \begin{align*}
        \bigg|e^{\imag\,x^\trans y}-\sum_{i=0}^k\imag^i\frac{(x^\trans y)^i}{i!}\bigg|&=\bigg|\imag^k\frac{(x^\trans y)^k}{(k-1)!}\int_0^1(1-t)^{k-1}(e^{\imag\,tx^\trans y}-1)\,dt\bigg|\\
        &\leq\frac{(|x|^\trans|y|)^k}{(k-1)!}\int_0^1(1-t)^{k-1}|e^{\imag\,tx^\trans y}-1|\,dt\\
        &\leq\frac{(|x|^\trans|y|)^k}{(k-1)!}\int_0^1(1-t)^{k-1}(|e^{\imag\,tx^\trans y}|+1)\,dt\\
        &=\frac{(|x|^\trans|y|)^k}{(k-1)!}\int_0^12(1-t)^{k-1}\,dt\\
        &=\frac{2(|x|^\trans|y|)^k}{k!}
    \end{align*}
    이므로
    \begin{equation*}
        \bigg|e^{\imag\,x^\trans y}-\sum_{i=0}^k\imag^i\frac{(x^\trans y)^i}{i!}\bigg|\leq\min\bigg\{\frac{(|x|^\trans|y|)^{k+1}}{(k+1)!},\,\frac{2(|x|^\trans|y|)^k}{k!}\bigg\}
    \end{equation*}
    이다.
\end{proof}

\begin{theorem}\label{thm:CFTaylor}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $M_X$가 $\mathbb{R}^n$ 위에서 존재하면 임의의 $t\in\mathbb{R}^n$에 대해 $\varphi_X(t)=\sum_{i=0}^\infty\imag^i\sum_{|\alpha|=i}\expect(X^\alpha)t^\alpha/\alpha!=\sum_{\alpha\in\mathbb{N}_0^n}\imag^{|\alpha|}\expect(X^\alpha)t^\alpha/\alpha!$이다. 여기서 급수는 절대수렴하여 \texttt{well-define}된다.
\end{theorem}

\begin{proof}
    \texttt{MGF} $M_X$가 $\mathbb{R}^n$ 위에서 존재하므로 보조정리 \ref{lem:MGFTaylor}로부터 임의의 $t\in\mathbb{R}^n$에 대해 $\expect(e^{|t|^\trans|X|})$가 존재한다. 또한, 임의의 $t\in\mathbb{R}^n$에 대해 $e^{t^\trans |X|}\leq e^{|t|^\trans |X|}$이므로 이상으로부터 $M_{|X|}$가 $\mathbb{R}^n$ 위에서 존재함을 안다. 한편, 위의 보조정리로부터 임의의 $t\in\mathbb{R}^n$와 임의의 $k\in\mathbb{N}$를 택하면
    \begin{align*}
        \bigg|\varphi_X(t)&-\sum_{i=0}^k\imag^i\sum_{|\alpha|=i}\expect(X^\alpha)\frac{t^\alpha}{\alpha!}\bigg|\\
        &=\bigg|\varphi_X(t)-\sum_{i=0}^k\frac{\imag^i}{i!}\sum_{|\alpha|=i}\binom{i}{\alpha}\expect((t_iX_i)^\alpha)\bigg|\\
        &=\bigg|\varphi_X(t)-\sum_{i=0}^k\imag^i\frac{\expect((t^\trans X)^i)}{i!}\bigg|\\
        &=\bigg|\expect\bigg(e^{\imag\,t^\trans X}-\sum_{i=0}^k\imag^i\frac{(t^\trans X)^i}{i!}\bigg)\bigg|\\
        &\leq\expect\bigg(\bigg|e^{\imag\,t^\trans X}-\sum_{i=0}^k\imag^i\frac{(t^\trans X)^i}{i!}\bigg|\bigg)\\
        &\leq\min\bigg\{\frac{\expect((|t|^\trans|X|)^{i+1})}{(i+1)!},\,\frac{2\expect((|t|^\trans|X|)^i)}{i!}\bigg\}\\
        &=\min\bigg\{\frac{1}{(i+1)!}\sum_{|\alpha|=i+1}\binom{i+1}{\alpha}\expect(|X|^\alpha)|t|^\alpha,\,\frac{2}{i!}\sum_{|\alpha|=i}\binom{i}{\alpha}\expect(|X|^\alpha)|t|^\alpha\bigg\}
    \end{align*}
    인데, 이미 $\mathbb{R}^n$ 위에서 $M_{|X|}$가 존재함을 알고 있으므로 정리 \ref{thm:MGFTaylor}로부터 $k\to\infty$이면 우변의 두 항이 모두 $0$으로 수렴하여 $\varphi_X(t)=\sum_{i=0}^\infty\imag^i\sum_{|\alpha|=i}\expect(X^\alpha)t^\alpha/\alpha!$이다. 한편, 다시 정리 \ref{thm:MGFTaylor}로부터 이 급수가 절대수렴함을 알고, 곧 합의 순서를 바꿀 수 있으므로 원하는 형태의 식을 얻는다.
\end{proof}

\begin{theorem}\label{thm:CFDifferentiation}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 $\alpha\in\mathbb{N}_0^n$에 대해 $\expect(X^\alpha)$가 존재한다고 하자. 그렇다면 임의의 $t\in\mathbb{R}^n$에 대해 $\expect(X^\alpha e^{\imag\,t^\trans X})$도 존재하고 $\partial^\alpha\varphi_X(t)=\imag^{|\alpha|}\expect(X^\alpha e^{\imag\,t^\trans X})$이다.
\end{theorem}

\begin{proof}
    간결한 논의를 위해 $\alpha_n\ne0$이라 하자. ($\alpha_n=0$인 경우에도 이와 비슷하게 하면 된다.) 임의의 $t\in\mathbb{R}^n$를 고정하고 함수 $f:\Omega\times\mathbb{R}$를 $f:(\omega,\,h)\mapsto e^{\imag(t+h\mathbf{e}_n)^\trans X(\omega)}$로 두면 임의의 $(\omega,\,h)\in\Omega\times\mathbb{R}$에 대해 $|(\partial/\partial h)f(\omega,\,h)|=|\imag X_n(\omega)e^{\imag(t+h\mathbf{e}_n)^\trans X(\omega)}|=|X_n(\omega)|$이고 $\expect(X_n)$이 존재하므로 $f$가 \texttt{Leibniz}의 법칙의 모든 조건을 만족시킨다. 따라서 함수 $h\mapsto\int_\Omega e^{\imag(t+h\mathbf{e}_n)^\trans X}\,d\mathbb{P}=\varphi_X(t+h\mathbf{e}_n)$는 미분가능하고 $\expect(X_ne^{\imag\,t^\trans X})$가 존재하며, $(\partial/\partial t_n)\varphi_X(t)=(d/dh)\varphi_X(t+h\mathbf{e}_n)\vert_{h=0}=\int_\Omega\imag X_ne^{\imag\,t^\trans X}\,d\mathbb{P}=\imag\expect(X_ne^{\imag\,t^\trans X})$이다. 이제 이와 비슷하게 $|\alpha|-1$번 반복하면 원하는 결과를 얻는다.
\end{proof}

\begin{corollary}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 $\alpha\in\mathbb{N}_0^n$에 대해 $\expect(X^\alpha)$가 존재한다고 하자. 그렇다면 $\expect(X^\alpha)=\partial^\alpha\varphi_X(0)/\imag^{|\alpha|}$이다.
\end{corollary}

\begin{proof}
    이는 위의 정리로부터 자명하다.
\end{proof}

앞서 적률을 도입하며 이를 이용하면 분포의 정보를 손실 없이 전달할 수 있다고 하였는데, 지금부터는 이에 대해 조금 자세히 알아보도록 하자. 분포의 정보를 손실 없이 전달할 수 있다고 함은 곧 적률만 알면 그 분포를 다시 복원해 낼 수 있음을 의미하는데, 기껏해야 가산개인 적률로써 $\mathcal{B}_n$ 위의 측도인 분포를 유일하게 특정해 내는 것은 결코 쉬운 일이 아니며, 이와 같은 문제를 흔히 \textbf{\texttt{problem of moments}}라 한다. 다음의 정리는 사실상 \texttt{Fourier} 역변환 공식으로 이 문제를 공략하는 좋은 출발점이 된다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 유계인 $B=(x,\,y]\in\mathcal{S}_n$에 대해 $\prob_X(\partial B)=0$이면
    \begin{equation*}
        \prob_X(B)=\lim_{M\to\infty}\frac{1}{(2\pi)^n}\int_{[-M,\,M]^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_X(t)\,d\mu_n(t)
    \end{equation*}
    이다.\footnotemark
\end{theorem}

\begin{proof}
    임의의 $M>0$을 택하여 $\mathcal{A}=\mathcal{B}_n\vert_{[-M,\,M]^n}$이라 하면 $\prob_X\otimes\mu_n\vert_\mathcal{A}$가 유한하고, 모든 성분이 $0$이 아닌 임의의 $t\in\mathbb{R}^n$와 임의의 $u\in\mathbb{R}^n$에 대해
    \begin{align*}
        \bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)e^{\imag\,t^\trans u}&=\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}e^{\imag\,t_iu_i}\\
        &=\prod_{i=1}^n\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}
    \end{align*}
    이므로 곧
    \begin{align*}
        \bigg|\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)e^{\imag\,t^\trans u}\bigg|&=\prod_{i=1}^n\frac{|e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}|}{|\imag t_i|}\\
        &=\prod_{i=1}^n\frac{|e^{\imag\,t_i(u_i-x_i)}||1-e^{\imag\,t_i(x_i-y_i)}|}{|t_i|}\\
        &\leq\prod_{i=1}^n\frac{|t_i(x_i-y_i)|}{|t_i|}\\
        &=\prod_{i=1}^n(y_i-x_i)\\
        &=\mu_n(B)\\
        &<\infty
    \end{align*}
    가 되어 함수 $(u,\,t)\mapsto[\prod_{i=1}^n(e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i})/\imag t_i]e^{\imag\,t^\trans u}$는 $\prob_X\otimes\mu_n\vert_\mathcal{A}$-적분가능하다. 여기서 첫번째 부등호는 보조정리 \ref{lem:expComplex}로부터 성립한다. 그렇다면 \texttt{Fubini}의 정리로부터
    \begin{align*}
        \int_{[-M,\,M]^n}\bigg(\prod_{i=1}^n&\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_X(t)\,d\mu_n(t)\\
        &=\int_{([-M,\,M]\setminus\{0\})^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_X(t)\,d\mu_n(t)\\
        &=\int_{([-M,\,M]\setminus\{0\})^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_X(t)\,d\mu_n\vert_\mathcal{A}(t)\\
        &=\int_{\mathbb{R}^n\times([-M,\,M]\setminus\{0\})^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)e^{\imag\,t^\trans u}\,d(\prob_X\otimes\mu_n\vert_\mathcal{A})(u,\,t)\\
        &=\int_{\mathbb{R}^n}\bigg(\int_{([-M,\,M]\setminus\{0\})^n}\prod_{i=1}^n\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}\,d\mu_n\vert_\mathcal{A}(t)\bigg)\,d\prob_X(u)\\
        &=\int_{\mathbb{R}^n}\bigg(\int_{([-M,\,M]\setminus\{0\})^n}\prod_{i=1}^n\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}\,d\mu_n(t)\bigg)\,d\prob_X(u)\\
        &=\int_{\mathbb{R}^n}\prod_{i=1}^n\bigg(\int_{[-M,\,M]\setminus\{0\}}\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}\,d\mu_1(t_i)\bigg)\,d\prob_X(u)
    \end{align*}
    인데, 여기서 각 $i\leq n$에 대해
    \begin{align*}
        &\int_{[-M,\,M]\setminus\{0\}}\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}\,d\mu_1(t_i)\\
        &\qquad=\int_{[-M,\,M]\setminus\{0\}}\frac{\cos t(u_i-x_i)+\imag\sin t(u_i-x_i)-\cos t(u_i-y_i)-\imag\sin t(u_i-y_i)}{\imag t}\,d\mu_1(t)\\
        &\qquad=2\int_{(0,\,M]}\frac{\sin t(u_i-x_i)}{t}\,d\mu_1(t)-2\int_{(0,\,M]}\frac{\sin t(u_i-y_i)}{t}\,d\mu_1(t)\\
        &\qquad=2\sgn(u_i-x_i)\int_{(0,\,M|u_i-x_i|]}\frac{\sin t}{t}\,d\mu_1(t)-2\sgn(u_i-y_i)\int_{(0,\,M|u_i-y_i|]}\frac{\sin t}{t}\,d\mu_1(t)
    \end{align*}
    이다. 표기의 편의를 위해 함수 $\mathrm{Si}:\mathbb{R}^+_0\to\mathbb{R}$를 $\mathrm{Si}:x\mapsto\int_{(0,\,x]}\sin t/t\,d\mu_1(t)$로 두면 이는 \texttt{FTC}로부터 연속이고 $x\to\infty$일 때 $\pi/2$로 수렴하므로 곧 $\mathrm{Si}$는 적당한 $N>0$에 대해 유계이다. 이로부터 $M_j\to\infty$인 임의의 수열 $\{M_j\}$를 생각하여 $j\in\mathbb{N}$가 충분히 크다고 하면
    \begin{align*}
        \bigg|\int_{[-M_j,\,M_j]}&\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}\,d\mu_1(t_i)\bigg|\\
        &=|2\sgn(u_i-x_i)\mathrm{Si}(M_j|u_i-x_i|)-2\sgn(u_i-y_i)\mathrm{Si}(M_j|u_i-y_i|)|\\
        &\leq2|\mathrm{Si}(M_j|u_i-x_i|)|+2|\mathrm{Si}(M_j|u_i-y_i|)|\\
        &\leq4N
    \end{align*}
    이 되어 \texttt{DCT}에서
    \begin{align*}
        \lim_{j\to\infty}&\int_{[-M_j,\,M_j]^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_X(t)\,d\mu_n(t)\\
        &=\int_{\mathbb{R}^n}\lim_{j\to\infty}\prod_{i=1}^n\bigg(\int_{[-M_j,\,M_j]}\frac{e^{\imag\,t_i(u_i-x_i)}-e^{\imag\,t_i(u_i-y_i)}}{\imag t_i}\,d\mu_1(t_i)\bigg)\,d\prob_X(u)\\
        &=\int_{\mathbb{R}^n}\lim_{j\to\infty}\prod_{i=1}^n[2\sgn(u_i-x_i)\mathrm{Si}(M_j|u_i-x_i|)-2\sgn(u_i-y_i)\mathrm{Si}(M_j|u_i-y_i|)]\,d\prob_X(u)\\
        &=\int_{\mathbb{R}^n}\prod_{i=1}^n\pi[\sgn(u_i-x_i)-\sgn(u_i-y_i)]\,d\prob_X(u)\\
        &=\int_{B^\circ}(2\pi)^n\,d\prob_X(u)+\int_{\partial B}\prod_{i=1}^n\pi[\sgn(u_i-x_i)-\sgn(u_i-y_i)]\,d\prob_X(u)\\
        &=(2\pi)^n\prob_X(B)
    \end{align*}
    이고, 증명이 끝난다. 여기서 마지막 등호는 $\prob_X(\partial B)=0$이므로 성립한다.
\end{proof}

위의 정리는 \texttt{CF}를 알면 이를 통해 그 분포를 (거의) 알 수 있음을 의미한다. 여기서 이론적인 기교를 조금 더 부리면 다음 따름정리를 얻는다.

\begin{lemma}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $\mathbb{R}^n$의 각 축에 수직인 초평면 중에 $\prob_X$-영집합이 아닌 것은 가산개이다.
\end{lemma}

\begin{proof}
    임의의 $i\leq n$에 대해 \texttt{CDF} $F_{X_i}$가 $x_0\in\mathbb{R}$에서 연속이라면 $\prob_X(\mathbb{R}^{i-1}\times\{x_0\}\times\mathbb{R}^{n-i})=\mathbb{P}\{X_i=x_0\}=\prob_{X_i}\{x_0\}=F_{X_i}(x_0)-F_{X_i}(x_0-)=0$이므로 초평면 $\pi:x_i=x_0$는 $\prob_X$-영집합이다. 그런데 정리 \ref{thm:CDFContinuousDense}로부터 각 $i\leq n$에 대해 $F_{X_i}$는 가산개의 불연속점만을 가지고, 곧 보조정리가 성립한다.
\end{proof}

\begin{corollary}\label{cor:CFEquivalent}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P}),\,(\Omega',\,\mathcal{F}',\,\mathbb{P}')$에서 각각 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n,\,Y:\Omega'\to\mathbb{R}^n$에 대해 $X\equiv Y$일 필요충분조건은 $\varphi_X=\varphi_Y$인 것이다.
\end{corollary}

\begin{proof}
    만약 $X\equiv Y$이면 $\prob_X=\prob_Y$에서 $\varphi_X=\varphi_Y$임이 자명하므로 역만 성립함을 보이면 된다. 이를 위해 $\varphi_X=\varphi_Y$라 하면 위의 정리로부터 유계인 $B=(x,\,y]\in\mathcal{S}_n$에 대해 $\prob_X(\partial B)=\prob_Y(\partial B)=0$이면
    \begin{align*}
        \prob_X(B)&=\lim_{M\to\infty}\frac{1}{(2\pi)^n}\int_{[-M,\,M]^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_X(t)\,d\mu_n(t)\\
        &=\lim_{M\to\infty}\frac{1}{(2\pi)^n}\int_{[-M,\,M]^n}\bigg(\prod_{i=1}^n\frac{e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i}}{\imag t_i}\bigg)\varphi_Y(t)\,d\mu_n(t)\\
        &=\prob_Y(B)
    \end{align*}
    이다. 따라서 만약 집합족 $\mathcal{A}=\{B\in\mathcal{S}_n:\prob_X(\partial B)=\prob_Y(\partial B)=0\}$가 $\pi$-\texttt{system}이고 $\mathcal{B}_n$의 생성자이면 정리 \ref{thm:measureUnique}로부터 증명이 끝난다. 우선 임의의 $B,\,B'\in\mathcal{A}$를 생각하면 $\partial(B\cap B')\subseteq\partial B\cup\partial B'$이므로 $\mathcal{A}$가 $\pi$-\texttt{system}임은 거의 자명하다. 한편, 임의의 $B=(x,\,y]\in\mathcal{S}_n$를 택하면 위의 보조정리로부터 $\prob_X$-영집합이 아니거나 $\prob_Y$-영집합이 아닌 $\mathbb{R}^n$의 축에 수직인 초평면이 가산개이므로 적당한 수열 $\{z_j\},\,\{w_j\}$가 존재하여 각 $j\in\mathbb{N}$에 대해 $\prob_X(\partial(z_j,\,w_j])=\prob_Y(\partial(z_j,\,w_j])=0$이고 $z_j\downarrow x,\,w_j\downarrow y$이다. 이제 각 $j\in\mathbb{N}$에 대해 $B_j=(z_j,\,w_j]\in\mathcal{A}$로 두면 $B_j\to B$이므로 $B\in\sigma(\mathcal{A})$이고, 곧 $\mathcal{S}_n\subseteq\sigma(\mathcal{A})$에서 $\mathcal{B}_n\subseteq\sigma(\mathcal{A})$인데, 그 역의 포함관계는 자명하므로 $\mathcal{A}$가 $\mathcal{B}_n$의 생성자가 되어 증명이 끝난다.
\end{proof}

위의 따름정리에 의하면 \texttt{CF}와 분포는 정확히 일대일로 대응한다. 한편, 앞서 보인 정리 \ref{thm:CFTaylor}에서 확률벡터의 모든 적률을 알면 (\texttt{MGF}가 존재한다는 가정 하에) 그로부터 \texttt{CF}를 구할 수 있으므로 이상을 종합하면 \texttt{problem of moments}에 어느 정도 만족스러운 답이 된다. 즉, 적률을 알면 \texttt{CF}를 알고, 그런 \texttt{CF}를 가지는 분포는 유일하게 특정된다. 한편, \texttt{MGF}와 \texttt{CF}는 이론적으로 그 역할이 비슷하므로 \texttt{CF} 대신 \texttt{MGF}를 이용하는 방법도 생각해 볼 수 있다. 다음 정리와 따름정리는 이에 대한 이론적인 전개를 담고 있다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 이의 모든 적률이 존재하고 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$가 존재하여 임의의 $t\in U$에 대해 급수 $\sum_{i=0}^\infty\sum_{|\alpha|=i}\expect(X^\alpha)t^\alpha/\alpha!$가 절대수렴한다고 하자. 이제 확률공간 $(\Omega',\,\mathcal{F}',\,\mathbb{P}')$에서 정의된 \texttt{rv.} $Y:\Omega'\to\mathbb{R}^n$에 대해 $Y$의 모든 적률이 존재하여 $X$의 적률과 같다면 $X\equiv Y$이다.
\end{theorem}

\begin{proof}
    먼저 $|\alpha|\to\infty$이면 모든 성분이 양수인 임의의 $h\in U$에 대해 $\expect(|X|^\alpha)h^\alpha/\alpha!\to0$임을 보이자. 간결한 논의를 위해 $n=2$라 하고 모든 성분이 $1$보다 작은 양수인 임의의 $h\in U$를 택하면 $\sum_{i=0}^\infty\sum_{|\alpha|=i}\expect(X^\alpha)h^\alpha/\alpha!$가 절대수렴하므로 $i\to\infty$이면 $\sum_{|\alpha|=i}|\expect(X^\alpha)h^\alpha/\alpha!|\to0$이고, 곧 $|\alpha|\to\infty$이면 $\expect(X^\alpha)h^\alpha/\alpha!\to0$이다. ($n=1$인 경우를 포함한 일반적인 경우에도 이와 비슷하게 하면 된다.) 이로부터 적당한 $M>0$이 존재하여 임의의 $\alpha\in\mathbb{N}_0^2$에 대해 $|\expect(X^\alpha)h^\alpha/\alpha!|\leq M$이고, 임의의 $\epsilon>0$을 택하면 적당한 $i_0\in\mathbb{N}$가 존재하여 $|\alpha|\geq i_0$이면 $|\expect(X^\alpha)h^\alpha/\alpha!|<h_1h_2\epsilon/16$이다. 이제 $|\alpha|\geq \max\{K_0+2,\,K_0+8M/h_1h_2\epsilon,\,8/\epsilon\}$인 임의의 $\alpha\in\mathbb{N}_0^2$를 택하고 경우를 나누어 생각한다.
    
    만약 $\alpha_1,\,\alpha_2$가 모두 짝수라면 $\expect(|X|^\alpha)h^\alpha/\alpha!<\epsilon$임은 자명하다. 만약 $\alpha_1$은 홀수이지만 $\alpha_2$는 짝수라면 적당한 $\beta_1\in\mathbb{N}$에 대해 $\alpha_1=2\beta_1-1$로 쓸 수 있고, 임의의 $x\in\mathbb{R}$에 대해 $|x|^{\alpha_1}\leq x^{2\beta_1}\ind_{\{|x|\geq1\}}+\ind_{\{|x|<1\}}\leq x^{2\beta_1}+1$이므로
    \begin{align*}
        \bigg|\expect(|X|^\alpha)\frac{h^\alpha}{\alpha!}\bigg|&=\bigg[\int_{\mathbb{R}^n}|x_1|^{\alpha_1}x_2^{\alpha_2}\,d\prob_X(x)\bigg]\frac{h^\alpha}{\alpha!}\\
        &\leq\bigg[\int_{\mathbb{R}^n}(x_1^{2\beta_1}+1)x_2^{\alpha_2}\,d\prob_X(x)\bigg]\frac{h_1^{\alpha_1}h_2^{\alpha_2}}{\alpha_1!\alpha_2!}\\
        &=\frac{2\beta_1}{\alpha_1h_1}\expect(X_1^{2\beta_1}X_2^{\alpha_2})\frac{h_1^{2\beta_1}h_2^{\alpha_2}}{(2\beta_1)!\alpha_2!}+\frac{h_1^{\alpha_1}}{\alpha_1!}\expect(X_2^{\alpha_2})\frac{h_2^{\alpha_2}}{\alpha_2!}\\
        &\leq\frac{2}{h_1}\expect(X_1^{2\beta_1}X_2^{\alpha_2})\frac{h_1^{2\beta_1}h_2^{\alpha_2}}{(2\beta_1)!\alpha_2!}+\frac{1}{\alpha_1}\expect(X_2^{\alpha_2})\frac{h_2^{\alpha_2}}{\alpha_2!}
    \end{align*}
    이다. 그렇다면 $2\beta_1+\alpha_2\geq i_0+1$에서 $(2/h_1)\expect(X_1^{2\beta_1}X_2^{\alpha_2})h_1^{2\beta_1}h_2^{\alpha_2}/(2\beta_1)!\alpha_2!<h_2\epsilon/8<\epsilon/2$이고 $\alpha_2\geq i_0$인 경우에는 $(1/\alpha_1)\expect(X_2^{\alpha_2})h_2^{\alpha_2}/\alpha_2!<h_1h_2\epsilon/16\alpha_1<\epsilon/2$이며 그렇지 않은 경우에는 $\alpha_1>8M/h_1h_2\epsilon>2M/\epsilon$에서 $(1/\alpha_1)\expect(X_2^{\alpha_2})h_2^{\alpha_2}/\alpha_2!<M/\alpha_1<\epsilon/2$이다. 이상으로부터 $\alpha_1$은 홀수이지만 $\alpha_2$는 짝수라면 $\expect(|X|^\alpha)h^\alpha/\alpha!<\epsilon$임을 안다. 반대로 $\alpha_1$은 짝수이지만 $\alpha_2$는 홀수인 경우에도 위와 비슷하게 하면 같은 결론을 얻는다. 마지막으로 $\alpha_1,\,\alpha_2$ 모두 홀수인 경우에는 위의 과정을 비슷하게 한 번 더 반복하면 되는데, 적당한 $\beta\in\mathbb{N}^2$에 대해 $\alpha=2\beta-1$이라 하면 위의 결과로부터
    \begin{align*}
        \expect(|X|^\alpha)\frac{h^\alpha}{\alpha!}&\leq\frac{2}{h_1}\expect(X_1^{2\beta_1}|X_2|^{\alpha_2})\frac{h_1^{2\beta_1}h_2^{\alpha_2}}{(2\beta_1)!\alpha_2!}+\frac{1}{\alpha_1}\expect(|X_2|^{\alpha_2})\frac{h_2^{\alpha_2}}{\alpha_2!}\\
        &\leq\frac{4}{h_1h_2}\expect(X^{2\beta})\frac{h^{2\beta}}{(2\beta)!}+\frac{2}{h_1\alpha_2}\expect(X_1^{2\beta_1})\frac{h_1^{2\beta_1}}{(2\beta_1)!}+\frac{2}{h_2\alpha_1}\expect(X_2^{2\beta_2})\frac{h_2^{2\beta_2}}{(2\beta_2)!}+\frac{1}{\alpha_1\alpha_2}
    \end{align*}
    임을 쉽게 보일 수 있다. 그렇다면 $|2\beta|\geq i_0$에서 $(4/h_1h_2)\expect(X^{2\beta})h^{2\beta}/(2\beta)!<\epsilon/4$이고 $2\beta_1\geq i_0$인 경우에는 $(2/h_1\alpha_2)\expect(X_1^{2\beta_1})h_1^{2\beta_1}/(2\beta_1)!<\epsilon/8\alpha_2<\epsilon/4$이며 그렇지 않은 경우에는 $\alpha_2\geq 8M/h_1h_2\epsilon>8M/h_1\epsilon$에서 $(2/h_1\alpha_2)\expect(X_1^{2\beta_1})h_1^{2\beta_1}/(2\beta_1)!<2M/h_1\alpha_2<\epsilon/4$이다. 비슷하게 $(2/h_2\alpha_1)\expect(X_2^{2\beta_2})h_2^{2\beta_2}/(2\beta_2)!<\epsilon/4$임을 알고, $1/\alpha_1\alpha_2\leq1/\max\{\alpha_1,\,\alpha_2\}\leq\epsilon/4$이므로 이상으로부터 $\alpha_1$과 $\alpha_2$가 모두 홀수라도 $\expect(|X|^\alpha)h^\alpha/\alpha!<\epsilon$임을 안다. 곧 어떠한 경우에도 $\expect(|X|^\alpha)h^\alpha/\alpha!<\epsilon$이 되어 $|\alpha|\to\infty$이면 $\expect(|X|^\alpha)h^\alpha/\alpha!\to0$임을 안다. 나아가, $h\in U$가 $0$인 성분을 가지더라도 이가 성립함을 위와 비슷하게 보일 수 있다.
    
    이제 보조정리 \ref{lem:expComplex}로부터 임의의 $k\in\mathbb{N}$과 임의의 $t\in\mathbb{R}^n$, 임의의 $h\in U$에 대해
    \begin{align*}
        \bigg|\varphi_X(t+h)-\sum_{i=0}^k\frac{\imag^i}{i!}\int_{\mathbb{R}^n}(h^\trans x)^ie^{\imag\,t^\trans x}\,&d\prob_X(x)\bigg|\\
        &=\bigg|\expect(e^{\imag\,(t+h)^\trans X})-\sum_{i=0}^k\frac{1}{i!}\expect((\imag h^\trans X)^ie^{\imag\,t^\trans X})\bigg|\\
        &=\bigg|\expect\bigg(e^{\imag\,(t+h)^\trans X}-\sum_{i=0}^k\frac{1}{i!}(\imag h^\trans X)^ie^{\imag\,t^\trans X}\bigg)\bigg|\\
        &\leq\expect\bigg(\bigg|e^{\imag\,(t+h)^\trans X}-\sum_{i=0}^k\frac{1}{i!}(\imag h^\trans X)^ie^{\imag\,t^\trans X}\bigg|\bigg)\\
        &=\expect\bigg(|e^{\imag\,t^\trans X}|\bigg|e^{\imag\,h^\trans X}-\sum_{i=0}^k\frac{1}{i!}(\imag h^\trans X)^i\bigg|\bigg)\\
        &=\expect\bigg(\bigg|e^{\imag\,h^\trans X}-\sum_{i=0}^k\frac{1}{i!}(\imag h^\trans X)^i\bigg|\bigg)\\
        &\leq\expect\bigg(\frac{(|h|^\trans|X|)^k}{k!}\bigg)\\
        &=\frac{2}{k!}\sum_{|\alpha|=k}\binom{k}{\alpha}\expect(|(h_iX_i)^\alpha|)\\
        &=2\sum_{|\alpha|=k}\expect(|X|^\alpha)\frac{h^\alpha}{\alpha!}
    \end{align*}
    이고 앞선 결론으로부터 $k\to\infty$이면 위 식의 우변이 $0$으로 수렴하여 정리 \ref{thm:CFDifferentiation}로부터
    \begin{align*}
        \varphi_X(t+h)&=\sum_{i=0}^\infty\frac{\imag^i}{i!}\int_{\mathbb{R}^n}(h^\trans x)^ie^{\imag\,t^\trans x}\,d\prob_X(x)\\
        &=\sum_{i=0}^\infty\frac{1}{i!}\sum_{|\alpha|=i}\binom{i}{\alpha}\imag^i\int_{\mathbb{R}^n}(h_ix_i)^\alpha e^{\imag\,t^\trans x}\,d\prob_X(x)\\
        &=\sum_{i=0}^\infty\frac{1}{i!}\sum_{|\alpha|=i}\binom{i}{\alpha}\imag^i\expect(X^\alpha e^{\imag\,t^\trans X})h^\alpha\\
        &=\sum_{i=0}^\infty\frac{1}{i!}\sum_{|\alpha|=i}\binom{i}{\alpha}\partial^\alpha\varphi_X(t)h^\alpha\\
        &=\sum_{i=0}^\infty\frac{1}{i!}\D^i\varphi_X(t)(h,\,\cdots,\,h)
    \end{align*}
    이다. 이는 $Y$에 대해서도 성립하므로 임의의 $t\in\mathbb{R}^n$와 임의의 $h\in U$에 대해 $\varphi_Y(t+h)=\sum_{i=0}^\infty\D^i\varphi_Y(t)(h,\,\cdots,\,h)/i!$인데, $X$와 $Y$의 적률이 모두 같으므로 다시 정리 \ref{thm:CFDifferentiation}로부터 임의의 $i\in\mathbb{N}_0$에 대해 $\D^i\varphi_X(0)=\D^i\varphi_Y(0)$이고, 곧 $U$에서 $\varphi_X$와 $\varphi_Y$가 일치한다. 그런데 위의 결론에서 $t\in\mathbb{R}^n$가 임의의 점이었음을 상기한다면 이는 곧 $\varphi_X=\varphi_Y$임을 의미하여 곧 따름정리 \ref{cor:CFEquivalent}로부터 $X\equiv Y$이다.
\end{proof}

\begin{corollary}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P}),\,(\Omega',\,\mathcal{F}',\,\mathbb{P}')$에서 각각 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n,\,Y:\Omega'\to\mathbb{R}^n$에 대해 $M_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재한다고 하자. 그렇다면 $X\equiv Y$일 필요충분조건은 $M_Y$가 적당한 $0$의 근방 $V\subseteq\mathbb{R}^n$ 위에서 존재하여 $U\cap V$에서 $M_X=M_Y$인 것이다.
\end{corollary}

\begin{proof}
    만약 $X\equiv Y$이면 $\prob_X=\prob_Y$에서 정리가 자명하므로 역만 성립함을 보이면 된다. 이를 위해 $M_Y$가 적당한 $0$의 근방 $V\subseteq\mathbb{R}^n$ 위에서 존재하여 $U\cap V$에서 $M_X=M_Y$라 하자. 그렇다면 정리 \ref{thm:MGFTaylor}와 \ref{thm:MGFDifferentiation}로부터 $X$와 $Y$의 모든 적률이 존재하여 서로 같으며 $\sum_{i=0}^\infty\sum_{|\alpha|=i}\expect(X^\alpha)t^\alpha/\alpha!$가 적당한 $0$의 근방에서 절대수렴하므로 위의 정리로부터 $X\equiv Y$이다.
\end{proof}

\texttt{Problem of moments}에 대한 논의를 마무리하기 전에, 한 가지 유의해야 할 점이 있다. 우리가 적률을 통해 \texttt{MGF}나 \texttt{CF}를 계산할 수 있고, 곧 분포를 유일하게 특정할 수 있지만, 이는 어디까지나 \texttt{MGF}가 존재할 때에만 가능한 것이다. 따라서 어떤 확률벡터의 \texttt{MGF}가 존재하지 않는다면 적률을 모두 알아도 이로부터 분포를 특정지을 수가 없다. 즉, 그러한 적률을 만들어내는 서로다른 분포가 얼마든지 존재할 수 있다.

다음으로 살펴볼 \texttt{CF}에 대한 흥미로운 주제는 연속확률벡터와 \texttt{CF}의 관계이다. 앞서 정리 \ref{thm:rvContinuous}는 어떤 확률벡터가 연속인지를 판단할 수 있는 방법을 제시했는데, 다음 정리는 \texttt{CF}를 이용한 새로운 방법을 하나 제시한다.

\begin{theorem}[Riemann-Lebesgue]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 연속활률벡터 $X:\Omega\to\mathbb{R}^n$에 대해 $\lim_{|t_1|,\,\cdots,\,|t_n|\to\infty}\varphi_X(t)\to0$이다.
\end{theorem}

\begin{proof}
    임의의 $\epsilon>0$을 택하면 $f_X$가 $\mu_n$-적분가능하므로 정리 \ref{thm:integrableApprox}의 i로부터 적당한 단순함수 $g:\mathbb{R}^n\to\mathbb{R}$가 존재하여 이는 적당한 $a_1,\,\cdots,\,a_k\in\mathbb{R}$와 유계인 $B_1,\,\cdots,\,B_k\in\mathcal{S}_n$에 대해 $g=\sum_{i=1}^na_i\ind_{B_i}$로 쓸 수 있으며 $\int_{\mathbb{R}^n}|f_X-g|\,d\mu_n<\epsilon$이고, 곧 임의의 $t\in\mathbb{R}^n$에 대해
    \begin{align*}
        \bigg|\int_{\mathbb{R}^n}[f_X(x)-g(x)]e^{\imag\,t^\trans x}\,d\mu_n(x)\bigg|&\leq\int_{\mathbb{R}^n}|[f_X(x)-g(x)]e^{\imag\,t^\trans x}|\,d\mu_n(x)\\
        &=\int_{\mathbb{R}^n}|f_X(x)-g(x)|\,d\mu_n(x)\\
        &<\frac{\epsilon}{2}
    \end{align*}
    이다. 이제 각 $i\leq k$에 대해 적당한 $x_i,\,y_i\in\mathbb{R}^n$에 대해 $B_i=\prod_{j=1}^n(x_i^j,\,y_i^j]$라 하자. 그렇다면 \texttt{Fubini}의 정리로부터 $0$을 성분으로 갖지 않는 임의의 $t\in\mathbb{R}^n$에 대해
    \begin{align*}
        \bigg|\int_{\mathbb{R}^n}g(x)e^{\imag\,t^\trans x}\,d\mu_n(x)\bigg|&=\bigg|\int_{\mathbb{R}^n}\sum_{i=1}^ka_i\ind_{B_i}e^{\imag\,t^\trans x}\,d\mu_n(x)\bigg|\\
        &=\bigg|\sum_{i=1}^ka_i\int_{B_i}\prod_{j=1}^ne^{\imag\,t_jx_j}\,d\mu_n(x)\bigg|\\
        &=\bigg|\sum_{i=1}^ka_i\prod_{j=1}^n\int_{x_i^j}^{y_i^j}e^{\imag\,t_jx_j}\,d\mu_1(x_j)\bigg|\\
        &=\bigg|\sum_{i=1}^ka_i\prod_{j=1}^n\frac{e^{\imag\,t_jy_i^j}-e^{\imag\,t_jx_i^j}}{\imag t_j}\bigg|\\
        &\leq\sum_{i=1}^k|a_i|\prod_{j=1}^n\bigg|\frac{e^{\imag\,t_jy_i^j}-e^{\imag\,t_jx_i^j}}{\imag t_j}\bigg|\\
        &\leq\sum_{i=1}^k|a_i|\prod_{j=1}^n\frac{|e^{\imag\,t_jy_i^j}|+|e^{\imag\,t_jx_i^j}|}{|t_j|}\\
        &=2^n\sum_{i=1}^k|a_i|\bigg/\prod_{j=1}^n|t_j|
    \end{align*}
    이므로 $\lim_{|t_1|,\,\cdots,\,|t_n|\to\infty}|\int_{\mathbb{R}^n}g(x)e^{\imag\,t^\trans x}\,d\mu_n(x)|=0$에서 적당한 $M>0$이 존재하여 $|t_1|,\,\cdots,\,|t_n|\geq M$이면 $|\int_{\mathbb{R}^n}g(x)e^{\imag\,t^\trans x}\,d\mu_n(x)|<\epsilon/2$이다. 이상으로부터 $|t_1|,\,\cdots,\,|t_n|\geq M$이면 $|\varphi_X(t)|=|\int_{\mathbb{R}^n}f_X(x)e^{\imag\,t^\trans x}\,d\mu_n(x)|\leq|\int_{\mathbb{R}^n}[f_X(x)-g(x)]e^{\imag\,t^\trans x}\,d\mu_n(x)|+|\int_{\mathbb{R}^n}g(x)e^{\imag\,t^\trans x}\,d\mu_n(x)|<\epsilon$이 되어 증명이 끝난다.
\end{proof}

심지어 \texttt{CF}를 이용해 \texttt{PDF}를 바로 구할 수도 있다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 연속확률벡터 $X:\Omega\to\mathbb{R}$에 대해 $\int_{\mathbb{R}^n}|\varphi_X|\,d\mu_n<\infty$이면
    \begin{equation*}
        f_X(x)=\frac{1}{(2\pi)^n}\int_{\mathbb{R}^n}e^{-\imag\,t^\trans x}\varphi_X(t)\,d\mu_n(t)
    \end{equation*}
    이다.
\end{theorem}

이제 앞서 기댓값에 대한 다양한 부등식을 소개할 때 미쳐 소개하지 못한 부등식을 하나 소개하고 \texttt{MGF}와 \texttt{CF}에 대한 내용을 마무리하자. 이 부등식도 \texttt{tail probability}를 \texttt{bounding}하는 부등식이다.

\begin{theorem}[Chernoff's bound]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $0$의 적당한 근방 $U\in\mathbb{R}$에서 $M_X$가 존재하면 임의의 $x\in\mathbb{R}$에 대해 $\mathbb{P}\{X\geq x\}\leq\inf_{0\leq t\in U}e^{-xt}M_X(t)$이다. 비슷하게, 임의의 $x\in\mathbb{R}$에 대해 $\mathbb{P}\{X\leq x\}\leq\inf_{0\geq t\in U}e^{-xt}M_X(t)$이다.
\end{theorem}

\begin{proof}
    임의의 $x,\,y\in\mathbb{R}$와 임의의 음이 아닌 $t\in U$에 대해 $\ind_{[x,\,\infty)}(y)\leq e^{t(y-x)}$이므로
    \begin{align*}
        \mathbb{P}\{X\geq x\}&=\prob_X([x,\,\infty))\\
        &=\int_\mathbb{R}\ind_{[x,\,\infty)}\,d\prob_X\\
        &\leq\int_\mathbb{R}e^{t(y-x)}\,d\prob_X(y)\\
        &=\expect(e^{t(X-x)})\\
        &=e^{-xt}M_X(t)
    \end{align*}
    에서 $\mathbb{P}\{X\geq x\}\leq\inf_{0\leq t\in U}e^{-xt}M_X(t)$이고, 이와 비슷하게 $\mathbb{P}\{X\leq x\}\leq\inf_{0\geq t\in U}e^{-xt}M_X(t)$임을 보일 수 있다.
\end{proof}

이번 절의 후반부에서는 \texttt{MGF}와 관련되거나 혹은 유사한 함수들을 간단히 살펴본다. 먼저 첫째로 볼 것은 \texttt{MGF}에 로그를 취하여 얻는 \texttt{CGF}, 그리고 이의 \texttt{Taylor} 전개의 계수로 주어지는 누율이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $M_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재하면 \texttt{rv.} $X$의 \textbf{누율생성함수(\texttt{cumulant generating function})}를 $C_X:U\to\mathbb{R}$로 쓰고 $C_X=\log M_X$로 정의한다. 특별히, $n\geq2$인 경우 $C_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합누율생성함수(\texttt{joint cumulant generating function})}라 하기도 한다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $C_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재한다면 $C_X$는 $U$에서 해석적이다.
\end{proposition}

\begin{proof}
    가정으로부터 $M_X$가 $U$ 위에서 존재하고 정리 \ref{thm:MGFTaylor}로부터 이는 $U$에서 해석적이다. 한편, 함수 $x\mapsto\log x$가 $(0,\,\infty)$에서 해석적이므로 $C_X=\log M_X$도 $U$에서 해석적이다.
\end{proof}

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $C_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재한다고 하자. 이제 $\alpha\in\mathbb{N}_0^n$에 대해 $C_X(t)$의 $0$에서의 \texttt{Taylor} 전개에서 $t^\alpha/\alpha!$의 계수를 $X$의 \textbf{$|\alpha|$차 (결합)누율($|\alpha|$\texttt{th} (\texttt{joint}) \texttt{cumulant})}이라 하고 $c_{\alpha,\,X}$ 혹은 간단히 $c_\alpha$로 쓴다.
\end{definition}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $C_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재한다고 하면 임의의 $\alpha\in\mathbb{N}_0^n$에 대해 $c_{X,\,\alpha}=\partial^\alpha C_X(0)$이다.
\end{theorem}

\begin{proof}
    이는 누율의 정의로부터 자명하다.
\end{proof}

\texttt{CGF}의 기본적인 성질은 \texttt{MGF}의 성질로부터 거의 자명하게 얻어진다.

\begin{theorem}\label{thm:CGFProp}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $C_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}^n$ 위에서 존재하면 다음이 성립한다.
    \begin{enumerate}
        \item $C_X(0)=0$.
        \item \texttt{CGF} $C_X$는 볼록하다.
        \item 임의의 $a\in\mathbb{R}$와 임의의 $b\in\mathbb{R}^n$에 대해 $C_{aX+b}$가 적당한 $0$의 근방 $V\subseteq\mathbb{R}^n$ 위에서 존재하고, $at\in U$인 $t\in V$에 대해 $C_{aX+b}(t)=C_X(at)+t^\trans b$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 $C_X(0)=\log M_X(0)=0$에서 자명하다.

    ii. 정리 \ref{thm:MGFProp}의 iii으로부터 이는 자명하다.

    iii. 정리 \ref{thm:MGFProp}의 iv로부터 $C_{aX+b}$가 적당한 $0$의 근방 $V\subseteq\mathbb{R}^n$에서 존재하고 $at\in U$인 $t\in V$에 대해 $C_{aX+b}(t)=\log M_{aX+b}(t)=\log e^{t^\trans b}M_X(at)=C_X(at)+t^\trans b$이다.
\end{proof}

앞서 배운 적률이 확률변수의 거듭제곱의 기댓값으로 깔끔하게 주어진 것에 비해, 누율과 기댓값을 깔끔하게 연결짓는 것은 쉽지 않다. 다만, 몇몇 낮은 차수의 누율의 경우 특별한 의미를 가진다. 그리고 때로는 이러한 관계를 잘 사용하면 기댓값이나 분산 등을 복잡한 계산을 피해 쉽고 간단하게 구할 수 있다.

\begin{proposition}\label{prop:firstSecondCumulant}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $C_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}$ 위에서 존재한다고 하면 $c_{X,\,1}=\expect(X)$이고 $c_{X,\,2}=\var(X)$이다.
\end{proposition}

\begin{proof}
    이는 정리 \ref{thm:MGFDifferentiation}으로부터 $C_X'(0)=(\log M_X)'(0)=(M_X'/M_X)(0)=\expect(X)$이고
    \begin{align*}
        C_X''(0)&=(\log M_X)''(0)\\
        &=\bigg(\frac{M_X'}{M_X}\bigg)'(0)\\
        &=\bigg[\frac{M_X''M_X-(M_X')^2}{M_X^2}\bigg](0)\\
        &=\expect(X^2)-[\expect(X)]^2\\
        &=\var(X)
    \end{align*}
   이므로 자명하다.
\end{proof}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $C_X$가 적당한 $0$의 근방 $U\subseteq\mathbb{R}$ 위에서 존재하며 $\var(X)\ne0$이라 하자. 이제 $Z=(X-\mu_X)/\sigma_X$라 하면 $C_Z$가 적당한 $0$의 근방 $V\subseteq\mathbb{R}$ 위에서 존재하고 $c_{Z,\,1}=0,\,c_{Z,\,2}=1,\,c_{Z,\,3}=\skew(X),\,c_{Z,\,4}=\kurt(X)$이다.
\end{proposition}

\begin{proof}
    정리 \ref{thm:CGFProp}의 iii으로부터 적당한 $0$의 근방 $V\subseteq\mathbb{R}$에서 $C_Z$가 존재함을 안다. 이제 정리 \ref{thm:MGFDifferentiation}으로부터
    \begin{align*}
        &M_Z(0)=1\\
        &M_Z'(0)=\expect\bigg(\frac{X-\mu_X}{\sigma_X}\bigg)=\frac{\expect(X)-\mu_X}{\sigma_X}=0\\
        &M_Z''(0)=\expect\bigg(\bigg(\frac{X-\mu_X}{\sigma_X}\bigg)^2\bigg)=\frac{\var(X)}{\sigma_X^2}=1,\\
        &M_Z'''(0)=\expect\bigg(\bigg(\frac{X-\mu_X}{\sigma_X}\bigg)^3\bigg)=\skew(X)\\
        &M_Z^{(4)}(0)=\expect\bigg(\bigg(\frac{X-\mu_X}{\sigma_X}\bigg)^4\bigg)=\kurt(X)+3
    \end{align*}
    이다. 그렇다면 명제 \ref{prop:firstSecondCumulant}로부터 $c_{Z,\,1}=\expect(Z)=0,\,c_{Z,\,2}=\var(Z)=1$이고
    \begin{align*}
        C_Z'''(0)&=(\log M_Z)'''(0)\\
        &=\bigg(\frac{M_Z'}{M_Z}\bigg)''(0)\\
        &=\bigg[\frac{M_Z''M_Z-(M_Z')^2}{M_Z^2}\bigg]'(0)\\
        &=\bigg\{\frac{(M_Z'''M_Z+M_Z''M_Z'-2M_Z'M_Z'')M_Z^2-[M_Z''M_Z-(M_Z')^2]2M_ZM_Z'}{M_Z^4}\bigg\}(0)\\
        &=\bigg[\frac{M_Z'''M_Z^2-3M_Z''M_Z'M_Z+2(M_Z')^3}{M_Z^3}\bigg](0)\\
        &=\skew(X)
    \end{align*}
    이며
    \begin{align*}
        C_Z^{(4)}(0)&=(\log M_Z)^{(4)}(0)\\
        &=\bigg(\frac{M_Z'}{M_Z}\bigg)'''(0)\\
        &=\bigg[\frac{M_Z''M_Z-(M_Z')^2}{M_Z^2}\bigg]''(0)\\
        &=\bigg[\frac{M_Z'''M_Z^2-3M_Z''M_Z'M_Z+2(M_Z')^3}{M_Z^3}\bigg]'(0)\\
        &=\left\{\frac{\splitfrac{[M_Z^{(4)}M_Z^2+M_Z'''2M_ZM_Z'-3M_Z'''M_Z'M_Z-3(M_Z'')^2M_Z}{-3M_Z''(M_Z')^2+6(M_Z')^2M_Z'']M_Z^3-[M_Z'''M_Z^2-3M_Z''M_Z'M_Z+2(M_Z')^3]3M_Z^2M_Z'}}{M_Z^6}\right\}(0)\\
        &=\bigg[\frac{M_Z^{(4)}M_Z^3-4M_Z'''M_Z'M_Z^2+12M_Z''(M_Z')^2M_Z-3(M_Z'')^2M_Z^2-6(M_Z')^4}{M_Z^4}\bigg](0)\\
        &=\kurt(X)
    \end{align*}
    이다.
\end{proof}

\section*{Notes}
\footnotesize
\begin{enumerate}[label = \textsf{\textbf{\arabic*}}]
    \item 여기서 $\lim_{x_i\to-\infty}F_X(x)=0$은 임의의 $\cdots,\,x_{i-1},\,x_{i+1},\,\cdots\in\mathbb{R}$와 임의의 $\epsilon>0$에 대해 적당한 $M\in\mathbb{R}$이 존재하여 $x_i<M$인 임의의 $x_i\in\mathbb{R}$에 대해 $F_X(x)<\epsilon$이라는 의미이다.
    \item 여기서 $\lim_{x_1,\,\cdots,\,x_n\to\infty}F_X(x)=1$은 임의의 $\epsilon>0$에 대해 적당한 $M\in\mathbb{R}$이 존재하여 $x\geq M\ind$인 임의의 $x\in\mathbb{R}^n$에 대해 $|F_X(x)-1|<\epsilon$이라는 의미이다.
    \item 만약 $x\in\mathbb{R}^n$에 대해 $F$가 $x$에서 \texttt{symmetric differentiable}하지 않으면 $F^{(s)}(x)$의 값을 $0$과 같은 \texttt{dummy value}로 정하는 관례를 전제하였다. 따름정리 \ref{cor:FTC1}로부터 이러한 점의 집합이 영집합을 이루고, \texttt{PDF}는 거의 어디서나 같은 함수를 하나로 볼 때 유일하므로 정리의 성립여부는 이때의 \texttt{dummy value}의 선택과 무관하다.
    \item 만약 $t\in\mathbb{R}^n$에 대해 이가 $0$을 성분으로 가지면 $\prod_{i=1}^n(e^{-\imag\,t_ix_i}-e^{-\imag\,t_iy_i})/\imag t_i$의 값을 $0$과 같은 \texttt{dummy value}로 정하는 관례를 전제하였다. 이러한 $t$의 집합이 영집합을 이루므로 적분의 결과는 이때의 \texttt{dummy value}의 선택과 무관하다.
\end{enumerate}

\section*{References}
\normalsize\ttfamily
\begin{enumerate}[label = {[\arabic*]}]
    \item Sheldon Ross, \textit{A First Course in Probability}, Prentice Hall, ????.
    \item Patrick Billingsley, \textit{Probability and Measure 3rd Edition}, Wiley, 1995.
    \item \textrm{김우철}, \textrm{『수리통계학』}, \textrm{민영사}, 2012.
    \item Mathematics Stack Exchange, Available: https://math.stackexchange.com.
    \item Wolfram MathWorld, Available: http://mathworld.wolfram.com.
    \item Wikipedia, Available: https://en.wikipedia.org.
    \item \textrm{나무위키}, Available: https://namu.wiki.
\end{enumerate}
\rmfamily