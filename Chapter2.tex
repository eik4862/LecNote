\abstract{확률론은 20세기 들어 급격하게 발전한 분야이다. 애초에 확률이라는 개념이 수학에 편입된 것이 그리 오래되지 않았다. 이는 \texttt{Descart}의 연역주의의 영향이 진하게 남아있던 근대 유럽의 수학에서 불확실성을 다루기를 꺼려했기 때문이다. 오죽했으면 ``거의 확실한 것은 거의 확실히 거짓이다.''라고까지 했을까. 하지만 도박 문제(\texttt{de M\'er\'e's problem})와 같이 불확실성을 계량하여 다루어야 할 필요성은 조금씩 늘어갔고, 이러한 현실적 요구에 확률은 \texttt{Pascal}, \texttt{Fermat}, \texttt{Lagrange} 등의 기라성같은 수학자들에 의해 조금씩 건드려지기 시작했다. 이때까지만 하더라도 확률이 무엇인지에 대한 수학자들의 생각은 `어떤 사건이 발생할 가능성' 정도였다. 이러한 확률의 의미가 직관적으로 분명하였기에 이에 의문을 제기하는 사람도 없었고, 그럴 필요도 느끼지 못했다. 그러나 미적분학에서 극한의 개념이 그러하였듯, 확률에 대한 연구가 계속될수록 미묘한 잡음이 발생하기 시작했고, 이는 확률의 개념에 대한 엄밀한 수학적 접근이 필요함을 암시했다. 결국 `확률은 무엇인가?'라는 질문의 답을 찾기 위한 긴 여정이 시작되었고, \texttt{Laplace}가 확률에 해석학을 끼얹은 것을 시작으로 \texttt{Kolomogorov}가 그의 명저 \textit{\texttt{Grundbegriffe der Wahrscheinlichkeitsrechnung}}(영어: \texttt{\textit{Foundations of The Theory of Probability}})에서 측도론으로 확률을 정의하면서 그 여정은 일단락되게 된다. 본 장에서는 그 여정의 끝에서 수학자들이 괘뚫어본 확률의 본질에 대해 살펴보도록 하자.}

\section{Probability Spaces}

단도직입적으로 말하면, 확률은 측도의 특별한 한 종류에 불과하다. 곧 확률은 일종의 넓이나 부피와 같은 개념으로 무언가를 재는 역할을 한다. 현실적인 의미를 생각하면 `가능성'을 잰다고도 할 수 있겠다.

\begin{definition}
    측도공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 $\mathbb{P}(\Omega)=1$이면 이때의 유한 측도 $\mathbb{P}$를 \textbf{확률측도(\texttt{probability measure})}라 하고, 유한 측도공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$를 \textbf{확률공간(\texttt{probability space})}이라 한다. 나아가 집합 $\Omega$를 \textbf{표본공간(\texttt{sample space})}이라 하고, $\sigma$-대수 $\mathcal{F}$에 속하는 임의의 집합 $E$를 \textbf{사건(\texttt{event})}이라 하여 $\mathbb{P}(E)$의 값을 사건 $E$의 \textbf{확률(\texttt{probability})}이라 한다.
\end{definition}

확률의 본질이 측도라는 위의 정의는 나름 설득력이 있다. 그렇다면 이걸로 다 된 것일까? 아쉽게도 이제부터 해야 할 일이 태산이다. 일단 위의 정의를 받아들이기로 했다면, 지금까지 우리가 배웠던 확률의 대한 모든 내용들을 측도론의 언어로 다시 써야 한다. 곧 확률론을 다루는 본 장의 내용은 기본적으로 `번역 작업'으로, 다행히 대부분의 경우 이 번역 작업은 크게 어렵지 않을 것이다. 이는 측도론이 확률의 내용들을 형식화하기에 좋은 이론이라서이기도 하지만, 앞서 우리가 측도론을 배우며 이 순간을 위해 조금씩 준비해 둔 것들이 꽤 많기 때문이다.

본격적으로 시작하기에 앞서, 맥락상 다소 뜬금없기는 하지만, 우리의 확률에 대한 인식의 근간을 이루는 \texttt{equally likely outcome model}을 한 번은 언급하고 지나가는 것이 좋을 것 같다. 고등학교에서 경우의 수를 세는 문제로 흔히 접하는 \texttt{equally likely outcome model}은 표본공간으로 항상 유한집합 $\Omega$를 가지고, 이의 모든 부분집합은 사건으로 간주된다. 나아가 한원소 집합인 사건은 특별히 \textbf{근원사건(\texttt{elementary event})}이라 불리며 각 근원사건의 확률은 정확히 $1/|\Omega|$로 주어진다. (이렇게 각 근원사건의 확률이 같으므로 `\texttt{equally likely}'이다. 고등학교에서는 흔히 `같은 정도로 확실하다'로 번역한다.) 이러한 \texttt{setting}에서 우리는 임의의 사건 $E$의 확률을 $|E|/|\Omega|$로 정하고, 여기서의 $|E|$를 구하기 위해 여태껏 경우의 수를 열심히 계산하여 왔다. 이상의 내용을 측도론의 언어로 담백하게 번역하면 \texttt{equally likely outcome model}은 `표본공간 $\Omega$에서의 셈측도 $\#$에 대해 $(\Omega,\,\mathcal{P}(\Omega),\,\#/|\Omega|)$로 주어진 확률공간'이 된다. 곧 측도론으로 바라보면 \texttt{equally likely outcome model}도 측도공간의 특별한 한 종류에 불과하다.

보통 초급 확률론 교재에서는 고등학교에서와 마찬가지로 이 \texttt{equally likely outcome model}에 집중하여 경우의 수를 계산하는 \texttt{fancy}한 \texttt{trick}을 소개하는 데 많은 분량을 할애하곤 하지만, 여기서는 이에 대한 논의는 Sheldon Ross의 A First Course in Probability를 참고문헌으로 실어두는 것으로 대신한다. 우리는 일반적인 이론의 전개에 보다 관심이 있기에 확률공간의 한 예시에 불과한 \texttt{equally likely outcome model}에 대해서는 그다지 관심이 없고, 곧 이 책에서 \texttt{equally likely outcome model}이 다시 등장하는 일은 (아마) 없을 것이다. 또한, 일반적으로 표본공간 위의 $\sigma$-대수 $\mathcal{F}$가 모든 한원소 집합을 포함한다는 보장이 없으므로 근원사건이라는 개념도 그다지 쓸모가 없을 것이다.

다시 원래의 이야기로 돌아와, 본격적으로 번역 작업을 시작해보자. 우선 확률의 기본적인 성질 정도는 측도의 성질들로부터 거의 자명하게 얻어진다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건 $E,\,F$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $\mathbb{P}(\emptyset)=0$.
        \item ($\sigma$-가법성) 서로소인 사건열 $\{E_i\}$에 대해 $\mathbb{P}(\bigsqcup_{i=1}^\infty E_i)=\sum_{i=1}^\infty\mathbb{P}(E_i)$이다.
        \item $0\leq\mathbb{P}(E)\leq1$.
        \item $\mathbb{P}(E^c)=1-\mathbb{P}(E)$.
        \item (단조성) 만약 $E\subseteq F$이면 $\mathbb{P}(E)\leq\mathbb{P}(F)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    이는 정의와 측도의 기본적인 성질로부터 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item (포함배제의 원리) 사건 $E_1,\,\cdots,\,E_l$에 대해
        \begin{equation*}
            \mathbb{P}\bigg(\bigcup_{i=1}^lE_i\bigg)=\sum_{i=1}^l(-1)^{i-1}\sum_{1\leq j_1<\cdots<j_i\leq l}\mathbb{P}\bigg(\bigcap_{k=1}^i E_{j_k}\bigg)
        \end{equation*}
        이다.
        \item ($\sigma$-반가법성) 사건열 $\{E_i\}$에 대해 $\mathbb{P}(\bigcup_{i=1}^\infty E_i)\leq\sum_{i=1}^\infty\mathbb{P}(E_i)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i는 측도론의 포함배제의 원리를 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 적용한 결과이고, ii는 측도의 $\sigma$-가법성이 $\sigma$-반가법성을 함의한다는 점에서 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건열 $\{E_i\}$에 대해 
    \begin{equation*}
        \mathbb{P}(\liminf_{i\to\infty}E_i)\leq\liminf_{i\to\infty}\mathbb{P}(E_i)\leq\limsup_{i\to\infty}\mathbb{P}(E_i)\leq\mathbb{P}(\limsup_{i\to\infty}E_i)
    \end{equation*}
    가 성립한다. 특별히, $E_i\to E$이면 $\mathbb{P}(E_i)\to\mathbb{P}(E)$이다.
\end{theorem}

\begin{proof}
    이는 정리 \ref{thm:generalSeriesMeasure}로부터 자명하다.
\end{proof}

위의 정리의 단서를 흔히 \textbf{확률측도의 연속성(\texttt{continuity of probability measure})}이라 한다. 한편, 확률론에서는 사건열 $\{E_i\}$에 대해 이의 상극한 $\limsup_{i\to\infty}E_i$를 간단히 $E_i\io$라 쓰기도 한다. 여기서 \texttt{io.}는 \texttt{infinitely often}의 줄임말로 곧 $\omega\in E_i\io$는 $\omega\in\Omega$가 사건 $E_1,\,E_2,\,\cdots$에 무한히 많이 속한다는 것인데, 이는 $\limsup_{i\to\infty}E_i=\bigcap_{j=1}^\infty\bigcup_{i=j}^\infty E_i$임을 생각해보면 나름 \texttt{make sense}하는 표기법이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 영집합인 사건을 \textbf{영사건(\texttt{null event})}이라 한다.
\end{definition}

확률측도도 측도이기에 `($\mathbb{P}$-)거의 어디서나'라는 개념이 자주 쓰이는데, 확률론에서는 이를 \textbf{($\mathbb{P}$-)거의 확실하게(($\mathbb{P}$-)\texttt{almost surely})}라 하기도 한다. 이는 영사건이 확률이 $0$인 사건이므로 어떤 성질이 $\mathbb{P}$-거의 어디서나 성립하면 곧 $1$의 확률로 성립하게 되기 때문에 생겨난 관례이다.

이와 관련하여 `확률이 $0$인 사건'과 `불가능한 사건'은 서로 다르다는 것에 주의할 필요가 있다. 확률인 $0$인 사건은 표본공간 위의 $\sigma$-대수 $\mathcal{F}$에 속하는 사건이지만 그 확률이 $0$일 뿐이고, 불가능한 사건은 애초에 $\mathcal{F}$에 속하지 않아 그 이름과는 달리 엄밀히는 사건이 아니다. 간단한 예시를 위해 $[0,\,1]$에서 임의로 점 하나를 택하는 상황을 생각해보자. 이를 확률공간으로 형식화한다면, 표본공간은 $\Omega=[0,\,1]$이고 $\mathcal{F}=\mathcal{B}_1\vert_\Omega$, 확률측도는 $\mathbb{P}=(\mu_1)_\mathcal{F}$ 정도로 둘 수 있을 것이다. 그렇다면 $\mathbb{P}\{0.5\}=0$이므로 정확히 $0.5$를 뽑는 사건은 확률이 $0$인 사건이지만, 그렇다고 이가 일어나는 것 자체가 불가능한 것은 아니다. 반대로, $2$를 뽑는 사건은 애초에 발생이 불가능한 사건으로 이 경우에 $\{2\}\notin\mathcal{F}$이므로 이는 엄밀하게는 사건이 아니어서 확률의 부여가 불가능하다. 이와 비슷하게, `확률이 $1$인 사건'과 `항상 발생하는 사건'도 서로 다른다.

이어서, 조건부확률을 도입하고 그 성질을 측도론으로 보이자. 다만, 이후에 조건부기댓값과 조건부분포를 엄밀히 도입하기 위해서는 조건부확률의 개념을 격변에 준할 정도로 일반화시켜야 하는데, 이에 하나의 절을 오롯히 할애해야 할 정도의 논의가 필요하므로 여기에서는 아주 간단하게만 다루도록 한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 영사건이 아닌 사건 $E$에 대해 \textbf{사건 $E$에 대한 조건부확률(\texttt{conditional probability under event} $E$)}을  $\mathbb{P}(\cdot\vert E):\mathcal{F}\to\mathbb{R}^+_0$로 쓰고 $\mathbb{P}(\cdot\vert E):F\mapsto\mathbb{P}(F\cap E)/\mathbb{P}(E)$로 정의한다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 영사건이 아닌 사건 $E$에 대한 조건부확률 $\mathbb{P}(\cdot\vert E)$는 확률측도이다. 따라서 $(\Omega,\,\mathcal{F},\,\mathbb{P}(\cdot\vert E))$는 확률공간을 이룬다.
\end{proposition}

\begin{proof}
    우선 $\mathbb{P}(\emptyset\vert E)=\mathbb{P}(\emptyset)/\mathbb{P}(E)=0,\,\mathbb{P}(\Omega\vert E)=\mathbb{P}(E)/\mathbb{P}(E)=1$임은 분명하고, 임의의 서로소인 사건열 $\{E_i\}$에 대해
    \begin{align*}
        \mathbb{P}\bigg(\bigsqcup_{i=1}^\infty E_i\vert E\bigg)&=\frac{\mathbb{P}(\bigsqcup_{i=1}^\infty E_i\cap E)}{\mathbb{P}(E)}\\
        &=\frac{\mathbb{P}(\bigsqcup_{i=1}^\infty(E_i\cap E))}{\mathbb{P}(E)}\\
        &=\sum_{i=1}^\infty\frac{\mathbb{P}(E_i\cap E)}{\mathbb{P}(E)}\\
        &=\sum_{i=1}^\infty\mathbb{P}(E_i\vert E)
    \end{align*}
    이므로 $\mathbb{P}(\cdot\vert E)$가 확률측도임을 안다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item 사건 $E$와 영사건이 아닌 사건 $F$에 대해 $\mathbb{P}(E\cap F)=\mathbb{P}(E\vert F)\mathbb{P}(F)$이다.
        \item (전확률 공식) 서로소인 가산개의 사건 $E_1,\,E_2,\,\cdots$에 대해 각 $E_i$가 영사건이 아니고 $\bigsqcup_{i=1}^kE_i=\Omega$이면 임의의 사건 $E$에 대해 $\mathbb{P}(E)=\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)$이다. (여기서 $k$는 유한할 수도 있고, $\infty$일 수도 있다.)
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 조건부확률의 정의로부터 자명하다.
    
    ii. i로부터 $\mathbb{P}(E)=\mathbb{P}(E\cap\bigsqcup_{i=1}^kE_i)=\mathbb{P}(\bigsqcup_{i=1}^k(E\cap E_i))=\sum_{i=1}^k\mathbb{P}(E\cap E_i)=\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)$이다.
\end{proof}

\begin{theorem}[Bayes]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 서로소인 가산개의 사건 $E_1,\,E_2,\,\cdots$에 대해 각 $E_i$가 영사건이 아니고 $\bigsqcup_{i=1}^kE_i=\Omega$이면 임의의 사건 $E$에 대해
    \begin{equation*}
        \mathbb{P}(E_1\vert E)=\frac{\mathbb{P}(E\vert E_1)\mathbb{P}(E_1)}{\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)}
    \end{equation*}
    이다. (여기서 $k$는 유한할 수도 있고, $\infty$일 수도 있다.)
\end{theorem}

\begin{proof}
    전확률 공식으로부터 $\mathbb{P}(E_1\vert E)=\mathbb{P}(E\cap E_1)/\mathbb{P}(E)=\mathbb{P}(E\vert E_1)\mathbb{P}(E_1)/\sum_{i=1}^k\mathbb{P}(E\vert E_i)\mathbb{P}(E_i)$가 자명하다.
\end{proof}

비록 증명은 간단하지만 \texttt{Bayes}의 정리는 실험적으로 구하는 것이 불가능한 조건부확률을 구하게 해준다는 엄청난 실용성과 함의를 지닌다. 쉽고 즐거운 예시를 위해 유리가 예나에게 휴대전화로 0x2661(\texttt{UTF-16} ♡)과 0x2665(\texttt{UTF-16} ♥) 중 하나의 정보를 임의로 전송하였는데, 송수신의 과정에서 정보의 일부가 손상되어 결과적으로 예나는 0x2663(\texttt{UTF-16} ♣)을 수신한 상황을 생각해보자. 이를 복원하기 위해 예나는 $E$를 0x2663을 수신하는 사건, $F,\,G$를 각각 0x2661과 0x2665를 전송하는 사건이라 두고 두 조건부확률 $\mathbb{P}(F\vert E)$와 $\mathbb{P}(G\vert E)$를 비교하여 전자가 더 크다면 0x2661로 복원하고 후자가 더 크다면 0x2665로 복원하며, 만약 같다면 재전송을 요청하기로 하였다. 이는 훌륭한 통계적 사고방식이지만 $\mathbb{P}(F\vert E)$와 $\mathbb{P}(G\vert E)$는 일의 선후가 뒤바뀐 확률이라 실험적으로 구할 수가 없다는 치명적인 문제가 있다. 예나가 자신의 휴대전화로 자신에게 0x2661과 0x2665를 수 회 전송하는 실험을 통해 근사하게나마 구할 수 있는 확률은 $\mathbb{P}(E\vert F)$와 $\mathbb{P}(E\vert G)$ 뿐이다. 여기서 \texttt{Bayes}의 정리는 $\mathbb{P}(F\vert E)$와 $\mathbb{P}(G\vert E)$를 $\mathbb{P}(E\vert F)$와 $\mathbb{P}(E\vert G)$의 조합으로써 계산할 수 있도록 하여 문제를 해결하는 결정적인 역할을 한다. 따라서 예나가 실험적으로 구한 $\mathbb{P}(E\vert F)$와 $\mathbb{P}(E\vert G)$의 근사치가 만약 $1/200,\,1/300$이었다면 \texttt{Bayes}의 정리로부터 $\mathbb{P}(F\vert E)\approx3/5,\,\mathbb{P}(G\vert E)\approx2/5$가 되어 ♣를 ♡로 복원할 수 있다. 요컨대, \texttt{Bayes}의 정리는 선후관계나 인과관계를 역전시켜주는 마법의 공식이다.

이러한 \texttt{Bayes} 정리는 이후 통계학에 큰 지각변동을 일으켜 이를 기초로 하는 \texttt{Bayesian}이라는 독자적인 학파가 구성되기에 이르렀고, 오늘날 기계학습과 같은 분야에서 요긴하게 쓰이는 모양이다. (이와 구분하여 기존의 통계학 학파를 빈도주의라 한다.) 물론, 이런 학파는 어디까지나 확률의 해석에 대한 차이로 구분되는 것이지 확률의 측도론적 정의나 접근방식으로 구분되는 것은 아니기에 빈도주의와 \texttt{Bayesian}의 구분이 본 장에서는 필요하지 않지만, 이 책에서는 특별한 언급이 없는 이상 빈도주의의 관점에서 확률을 바라본다. 여기에는 통계학 교양 정도를 들은 수준에서는 빈도주의의 관점이 \texttt{Bayesian}의 관점보다 조금 더 친숙하다는 것을 빼면 다른 그럴싸한 이유는 없다. 만약 자신이 \texttt{Bayesian}이라면 그들의 방식대로 해석하면 그만이고, 당연히 \texttt{Bayesian}에게도 측도론적인 엄밀한 확률론은 훌륭한 이론의 토대가 될 것이다.

이번 절에서 마지막으로 다룰 것은 바로 독립에 관한 내용인데, 앞서 확률의 기본적인 성질과 기본적인 조건부확률을 큰 어려움 없이 도입할 수 있었던 것과는 달리, 독립성을 측도론의 언어로 번역해 내는 것은 살짝 어렵다. 이는 독립이라는 개념이 측도론에서는 그 느낌조차 찾아보기 힘든, 완전히 새로운 개념이기 때문이다. 우리는 측도론에서 적분을 정의할 때와 비슷하게 독립을 그 정의를 점차 일반화시키는 방법으로 도입할 것이다. 우선 가장 기본적인 독립의 정의로 시작한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건 $E_1,\,\cdots,\,E_k$를 생각하자. 만약 각 $l\leq k$와 임의의 서로다른 $i_1,\,\cdots,\,i_l\leq k$에 대해 $\mathbb{P}(\bigcap_{j=1}^lE_{i_j})=\prod_{j=1}^l\mathbb{P}(E_{i_j})$가 성립하면 이때의 사건 $E_1,\,\cdots,\,E_k$를 \textbf{(서로) 독립((\texttt{mutually}) \texttt{independent})}이라 한다. 한편, 만약 위의 성질이 $l=2$에 대해서만 만족되면, 즉 임의의 서로다른 $i,\,j\leq k$에 대해서 $\mathbb{P}(E_i\cap E_j)=\mathbb{P}(E_i)\mathbb{P}(E_j)$가 성립하는 것에 그치면 이때의 사건 $E_1,\,\cdots,\,E_k$를 \textbf{\texttt{pairwise} 독립(- \texttt{independent})}이라 한다.
\end{definition}

서로 독립인 것과 \texttt{pairwise} 독립이 다르다는 사실은 잘 알려진 사실이다. 흔해빠진 주사위와 동전 예시를 피하기 위해 해석개론을 수강신청한 수지와 이제훈이 같이 밤새 과제를 하게 된 것을 계기로 서로 어느정도 이성으로서 호감을 가지게 된, 이른바 `썸 탄다' 불리우는 상황을 생각하자. 수업을 듣던 어느날, 수지와 이제훈의 교재가 실수로 서로 바뀌어 다음 수업시간 전에 만나 책을 다시 바꾸기로 하였는데, 둘은 이를 앞두고 책 사이에 고백편지를 살짝 끼워넣을까 고민하고 있다고 하자. 여기서 사건 $E,\,F$를 각각 수지와 이제훈이 고백편지를 끼워넣는 사건이라 하고, 수지나 이제훈이 고백편지를 넣을 확률은 $1/2$로 같으며 이는 서로 독립이라 하자. 이제 사건 $G$를 어느 한쪽만 고백편지를 받는 사건이라 하면 $E,\,F,\,G$는 \texttt{pairwise} 독립이지만 서로 독립은 아니다. (직접 계산해보자.)

이제 유한개의 사건 사이의 독립을 무한개의 사건 사이의 독립으로 확장하는 것은 어렵지 않다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건의 모임 $\mathcal{C}$를 생각하자. 만약 임의의 사건 $E_1,\,\cdots,\,E_k\in\mathcal{C}$가 서로 독립이면 이때의 집합 $\mathcal{C}$를 \textbf{독립(\texttt{independent})}이라 한다.
\end{definition}

다음으로, 유한개의 사건의 모임 사이의 독립을 정의한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건의 모임 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k$를 생각하자. 만약 각 $i\leq k$에 대해 임의로 택한 사건 $E_i\in\mathcal{C}_i$가 서로 독립이면 이때의 집합족 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k$를 \textbf{독립(\texttt{independent})}이라 한다.
\end{definition}

마지막으로 이를 무한개의 사건의 모임 사이의 독립으로까지 확장하면 독립의 가장 일반적인 정의를 얻는다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건의 모임의 모임 $\Gamma$를 생각하자. 만약 임의의 사건의 모임 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k\in\Gamma$가 서로 독립이면 이때의 집합족 $\Gamma$를 \textbf{독립(\texttt{independent})}이라 한다.
\end{definition}

이렇게까지 일반적인 형태의 독립성을 고려하는 이유는 다음 정리 때문이다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 독립인 사건의 모임의 모임 $\{\mathcal{C}_\alpha\}$에 대해 각 $\mathcal{C}_\alpha$가 $\pi$-\texttt{system}이라 하면 $\{\sigma(\mathcal{C}_\alpha)\}$는 독립이다.
\end{theorem}

\begin{proof}
    집합족 $\{\mathcal{C}_\alpha\}$에서 임의로 유한개의 원소를 택하여 이를 $\mathcal{C}_1,\,\cdots,\,\mathcal{C}_k$라 하고 이들이 생성하는 $\sigma$-대수 $\sigma(\mathcal{C}_1),\,\cdots,\,\sigma(\mathcal{C}_k)$가 서로 독립임을 보이면 증명은 충분하다. 이를 위해 사건 $E_2\in\mathcal{C}_2,\,\cdots,\,E_k\in\mathcal{C}_k$를 임의로 택하고 집합족 $\mathcal{L}=\{F\in\mathcal{F}:F,\,E_2,\,\cdots,\,E_k\textrm{가 서로 독립}\}$을 생각하면 주어진 조건으로부터 $\mathcal{C}_1\subseteq\mathcal{L}$임은 분명하다. 나아가 $\Omega\in\mathcal{L}$ 또한 분명하고, 임의의 $F\in\mathcal{L}$에 대해 $F,\,E_2,\,\cdots,\,E_k$가 서로 독립이면 $F^c,\,E_2,\,\cdots,\,E_k$도 서로 독립임을 쉽게 보일 수 있으므로 $F^c\in\mathcal{L}$이다. 비슷한 방법으로 $\mathcal{L}$에 속하는 임의의 서로소인 사건열 $\{F_i\}$에 대해 $\bigsqcup_{i=1}^\infty F_i,\,E_2,\,\cdots,\,E_k$가 서로 독립임을 보일 수 있으므로 $\bigsqcup_{i=1}^\infty F_i\in\mathcal{L}$도 성립한다. 이로부터 $\mathcal{L}$은 $\lambda$-\texttt{system}이 되어 $\mathcal{C}_1$이 $\pi$-\texttt{system}이라는 사실과 \texttt{Dynkin}의 $\pi$-$\lambda$ 정리로부터 $\sigma(\mathcal{C}_1)=\lambda(\mathcal{C}_1)\subseteq\mathcal{L}$이고, 곧 $\sigma(\mathcal{C}_1),\,\mathcal{C}_2,\,\cdots,\,\mathcal{C}_k$는 서로 독립이다. 이제 이를 $k-1$번 반복하면 $\sigma(\mathcal{C}_1),\,\cdots,\,\sigma(\mathcal{C}_k)$가 서로 독립임을 보일 수 있고, 증명이 끝난다.
\end{proof}

위의 정리는 서로 독립인 사건의 모임들이 생성하는 $\sigma$-대수도 서로 독립임을 함의하는데, 잠시 이 결과의 의미에 대해 생각해보자. 독립성은 기본적으로 `정보'에 대한 이야기이다. 가장 기본적인 형태로 두 사건 $E,\,F$가 서로 독립인 경우를 살펴보면, 이는 사건 $E$의 발생여부에 대한 정보가 주어지더라도 사건 $F$의 발생여부에 대한 정보는 일체 추론해 낼 수 없음을 의미한다. 이는 2개 이상의 사건, 나아가 무한개의 사건의 독립에 대해서도 마찬가지이다. 예컨대 앞서 든 수지와 이제훈의 예시에서 $E,\,F,\,G$는 서로 독립이 아니었는데, 이는 수지가 고백편지를 넣는 사건 $E$와 이제훈이 고백편지를 넣는 사건 $F$의 발생여부에 대한 정보가 사건 $G$의 발생여부에 대한 정보를 100\% 함의하기 때문이다.

사건의 모임 사이의 독립도 이와 비슷하게 이해할 수 있다. 앞서 사건들 사이의 독립에서 각 사건은 그 사건의 발생여부에 대한 이진 정보를 의미했다. 그렇다면 사건의 모임은 그 모임에 속한 각 사건들의 발생여부에 대한 이진 정보의 조합으로 이루어진 보다 풍성한 정보로 이해하는 것이 자연스러울 것이다. 따라서 사건의 모임 사이의 독립은 각 사건의 모임이 함의하는 정보가 서로 독립적이라는, 즉 어느 하나를 안다고 해서 다른 하나를 일체 추론해내지 못한다는 것을 의미한다. 이러한 해석의 관점에서 보면, 위의 정리의 결과는 어떤 사건의 모임들이 함의하는 정보가 서로 추론이 불가능하다면, 각 모임을 그가 생성하는 $\sigma$-대수로 확장하여 훨씬 더 많은 정보로 얻어도, 여전히 서로 추론이 불가능함을 의미한다. 뭔가 자명한 듯 자명하지 않은 이 결과를 보다 효율적으로 쓰기 위해 따름정리 하나를 소개한다.

\begin{corollary}\label{cor:independence}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 가산개의 무한한 행과 열을 가지는 사건의 배열
    \begin{equation*}
        \begin{matrix}
            E_{11}&E_{12}&\cdots\\
            E_{21}&E_{22}&\cdots\\
            \vdots&\vdots&\ddots
        \end{matrix}
    \end{equation*}
    에 대해 $\{E_{ij}\}_{ij}$가 독립이라 하고, 각 $i\in\mathbb{N}$에 대해 집합족 $\mathcal{G}_i$를 $\{E_{ij}\}_j$가 생성하는 $\sigma$-대수라 하면 $\{\mathcal{G}_i\}$는 독립이다. 한편, 행이나 열의 개수가 유한한 경우에도 같은 결과가 성립하며, 나아가 각 행의 열의 개수가 달라도 가산개이기만 하면 여전히 같은 결과가 성립한다.
\end{corollary}

\begin{proof}
    각 $i\in\mathbb{N}$에 대해 $\{E_{ij}\}_j$의 모든 유한 교집합의 모임 $\mathcal{P}_i$를 생각하면 $\mathcal{P}_i$는 $\pi$-\texttt{system}이고 $\sigma(\mathcal{P}_i)=\mathcal{G}_i$임이 거의 분명하다. 따라서 $\{\mathcal{P}_i\}$가 서로 독립이라는 사실만 보이면 앞선 정리로부터 $\{\mathcal{G}_i\}$가 독립이 되어 증명이 끝난다. 이를 위해 $\{\mathcal{P}_i\}$에서 임의로 유한개의 원소를 택하여 이를 $\mathcal{P}_1,\,\cdots,\,\mathcal{P}_k$라 하고 다시 임의로 사건 $F_1\in\mathcal{P}_1,\,\cdots,\,F_k\in\mathcal{P}_k$를 택하면 각 $i\leq k$에 대해 $\mathcal{P}_i$의 구성으로부터 적당한 사건 $E_{i1},\,\cdots,\,E_{il_i}$가 존재하여 $F_i=\bigcap_{j=1}^{l_i}E_{ij}$이다. 그렇다면 $\{E_{ij}\}_{ij}$가 독립이라는 사실로부터 $\mathbb{P}(\bigcap_{i=1}^kF_i)=\mathbb{P}(\bigcap_{i=1}^k\bigcap_{j=1}^{l_i}E_{ij})=\prod_{i=1}^k\prod_{j=1}^{l_i}\mathbb{P}(E_{ij})=\prod_{i=1}^k\mathbb{P}(\bigcap_{j=1}^{l_i}E_{ij})=\prod_{i=1}^k\mathbb{P}(F_i)$가 되어 $\{\mathcal{P}_i\}$가 서로 독립임을 알고, 증명은 이로써 충분하다.
\end{proof}

이 따름정리를 적당히 응용하면 독립성에 대한 진부한 연습문제들, 예컨대 사건 $E,\,F,\,G,\,H$가 서로 독립이라면 $E\cap F$와 $G\setminus H$가 독립임을 보이라는 식의 문제들을 아주 깔끔하게 해결할 수 있다. 예시로 든 문제의 경우 배열 $E\,\,F//G\,\,H$를 생각하면 그만이다. 한편, 앞서 사건의 모임을 그에 포함된 각 사건의 발생여부로 구성된 정보의 집합으로 해석하였는데, 이는 독립의 경우에만 한정되는 해석이 아니어서 특히 그 모임이 $\sigma$-대수 $\mathcal{G}$인 경우 모든 사건의 집합 $\mathcal{F}$를 `전체 정보'로, $\mathcal{G}$는 이의 `부분 정보'로 해석하는 것이 유용한 경우가 많다.

나중을 위해 측도론에서 잠시 등장했던 \texttt{Borel-Cantelli}의 정리를 조금 보강하는 것으로 이번 절을 마친다.

\begin{theorem}[Borel-Cantelli]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$와 사건열 $\{E_i\}$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item 만약 $\sum_{i=1}^\infty\mathbb{P}(E_i)<\infty$이면 $\mathbb{P}(E_i\io)=0$이다.
        \item 만약 $\sum_{i=1}^\infty\mathbb{P}(E_i)=\infty$이고 $\{E_i\}$가 독립이면 $\mathbb{P}(E_i\io)=1$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는 측도론에서 배운 \texttt{Borel-Cantelli}의 정리로부터 자명하다.

    ii. 우선 $\{E_i\}$가 독립이므로 따름정리 \ref{cor:independence}로부터 $\{E_i^c\}$도 독립이다. 이제 임의의 $\epsilon>0$과 임의의 $j\in\mathbb{N}$를 택하면 $\sum_{i=j}^\infty\mathbb{P}(E_i)=\infty$이므로 $\lim_{k\to\infty}\exp(-\sum_{i=j}^k\mathbb{P}(E_i))=0$이다. 이로부터 적당한 $k_0\in\mathbb{N}$가 존재하여 $k_0\geq j$이고 $\exp(-\sum_{i=j}^{k_0}\mathbb{P}(E_i))<\epsilon$이므로 $\mathbb{P}(\bigcap_{i=j}^{k_0}E_i^c)=\prod_{i=j}^{k_0}\mathbb{P}(E_i^c)=\prod_{i=j}^{k_0}[1-\mathbb{P}(E_i)]\leq\prod_{i=j}^{k_0}\exp(-\mathbb{P}(E_i))=\exp(-\sum_{i=j}^{k_0}\mathbb{P}(E_i))<\epsilon$이다. 이는 곧 $\mathbb{P}(\bigcap_{i=j}^\infty E_i^c)\leq\mathbb{P}(\bigcap_{i=j}^{k_0}E_i^c)<\epsilon$임을 뜻하므로 $\mathbb{P}(\bigcap_{i=j}^\infty E_i^c)=0$임을 알고, 이는 다시 $\mathbb{P}(E_i\io)=\mathbb{P}((\liminf_{i\to\infty} E_i^c)^c)=1-\mathbb{P}(\liminf_{i\to\infty} E_i^c)\geq1-\mathbb{P}(\bigcap_{i=j}^\infty E_i^c)=1$에서 $\mathbb{P}(E_i\io)=1$임을 뜻한다.
\end{proof}

\section{Random Variables and Random Vectors}

앞선 절에서 사건 그 자체에 관련된 확률의 내용들을 측도론의 틀에 맞추어 열심히 옮겨 놓았으니, 이번 절에서는 확률변수라는 개념을 추가하여 보다 내용을 풍성하게 만들어보도록 하자. 확률변수를 통해 우리는 일일히 사건을 정의하지 않고도 확률의 여러 내용들을 보다 더 편리하게 사용할 수 있다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에 대해 가측함수 $X:\Omega\to\mathbb{R}^n$를 \textbf{($n$차원) 확률벡터(($n$ \texttt{dimensional}) \texttt{random vector})}라 하고, 특별히 $n=1$이면 \textbf{확률변수(\texttt{random variable})}라 한다.
\end{definition}

확률변수는 본질적으로 가측함수이기에 확률변수의 기본적인 성질들이 가측함수의 성질들로부터 자명하게 성립하는 것이 전혀 이상하지 않다.

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 함수 $X:\Omega\to\mathbb{R}^n$에 대해 $X$가 \texttt{rv.}일 필요충분조건은 $X_1,\,\cdots,\,X_n$이 모두 \texttt{rv.}인 것이다.
\end{proposition}

\begin{proof}
    이는 가측함수의 성분도 가측함수라는 점에서 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^m$와 \texttt{Borel} 함수 $g:\mathbb{R}^m\to\mathbb{R}^n$에 대해 합성 $g\circ X:\Omega\to\mathbb{R}^n$도 \texttt{rv.}이다.
\end{theorem}

\begin{proof}
    이는 \texttt{Borel} 함수와 가측함수의 합성은 가측이라는 점에서 자명하다.
\end{proof}

비록 정의상 \texttt{rv.}는 엄연한 함수이지만 그 이름에서도 잘 드러나듯이 확률론에서는 이를 마치 변수처럼 생각하고 사용하는 경우가 많다. 이는 이론적인 이유에서라기보다 실생활의 응용에서 이렇게 생각하는 편이 조금 더 직관적으로 편하기 때문이다. 이러한 우리의 인식은 \texttt{rv.}와 관련된 여러 표기상의 관례에 잘 나타나는데, 위의 정리에서의 합성 $g\circ X$를 마치 $g$에 $X$라는 변수를 대입한 것으로 생각하여 $g(X)$로 쓰는 관례가 대표적인 예시이다. 그러나 이런 표기법은 어디까지나 관례일 뿐, \texttt{rv.}가 변수가 아닌 함수라는 사실은 항상 염두에 두고 있어야 한다.

이어서, 측도론에서 \texttt{FTC}를 일반화하는 과정에서 잠시 스쳐 지나갔던 \texttt{pushfowarding}이 다시 등장한다. 비록 측도론에서의 \texttt{pushfowarding}은 도구 역할에 그쳤지만, 확률론에서의 \texttt{pushfowarding}은 빼놓을 수 없는 핵심적인 개념이다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{pushfoward} 측도 $X_*\mathbb{P}$를 \texttt{rv.} $X$의 \textbf{분포(\texttt{distribution})}라 하고 $\prob_X$로 쓴다. 특별히, $n\geq2$인 경우 $\prob_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합분포(\texttt{joint distribution})}라 하고 $\prob_{X_1,\,\cdots,\,X_n}$으로 쓰기도 한다.
\end{definition}

교양 통계학에서 배운 \texttt{PDF}나 \texttt{\texttt{CDF}}와 같이 확률론에는 방금 정의한 분포와 쉽게 혼동될 법한 개념들이 많고, 실제로 각자의 정의도 서로 긴밀히 연결되어 있다. 여기에 한술 더 떠서 문헌마다 조금씩 용어를 다르게 쓰는 바람에 혼란이 가중되는 부분이 없지 않지만, 대부분 논의의 맥락으로 적당히 구별할 수 있다. 아무튼 구태여 혼란을 초래할 필요는 없기에, 이 책에서는 용어를 최대한 잘 구별하여 사용하였다.

\begin{proposition}\label{prop:rvProbSpace}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\prob_X)$는 확률공간을 이룬다.
\end{proposition}

\begin{proof}
    먼저 $\mathcal{B}_n\subseteq X_*\mathcal{F}$임을 보이기 위해 임의의 $A\in\mathcal{B}_n$를 택하면 $X^{-1}(A)\in\mathcal{F}$이므로 $A\in X_*\mathcal{A}$에서 $\mathcal{B}_n\subseteq X_*\mathcal{F}$이다. 따라서 $\prob_X$가 확률측도임을 보이면 충분한데, 이는 $\prob_X(\mathbb{R}^n)=\mathbb{P}(X^{-1}(\mathbb{R}^n))=\mathbb{P}(\Omega)=1$에서 쉽게 알 수 있고, 곧 증명이 끝난다.
\end{proof}

위의 명제는 분포를 통해 서로다른 확률공간에 정의된 확률측도를 각각 다루는 대신 이들을 \texttt{pushfowarding}하여 $\mathcal{B}_n$에서 정의된 확률측도로 일관되게 다룰 수 있음을 함의한다. 그리고 생각해보면, 이가 곧 사건을 직접 정의하고 사용하는 대신 \texttt{rv.}를 도입하여 사용하는 이유이다. 무엇이 될 지 모르는 확률공간 대신 우리가 잘 알고있는 실수공간에서의 확률측도를 다루는 것이 훨씬 편하다. 한편, 위의 정리의 역이 성립한다는 것도 꽤나 흥미로운 사실이다.

\begin{theorem}\label{thm:probSpaceRv}
    \texttt{Borel} $\sigma$-대수 $\mathcal{B}_n$ 위의 확률측도 $\mu$에 대해 적당한 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$가 존재하여 $\mu=\prob_X$이다. 특별히, 이때 $(\Omega,\,\mathcal{F})=(\mathbb{R}^n,\,\mathcal{B}_n)$이도록 잡을 수 있다.
\end{theorem}

\begin{proof}
    거의 자명하다. 함수 $X:\mathbb{R}^n\to\mathbb{R}^n$를 항등함수로 두면 이는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mu)$에서 정의된 \texttt{rv.}이고, 임의의 사건 $E$에 대해 $\prob_X(E)=\mu(X^{-1}(E))=\mu(E)$에서 $\mu=\prob_X$이다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^m$와 \texttt{Borel} 함수 $g:\mathbb{R}^m\to\mathbb{R}^n$에 대해 $\prob_{g(X)}=\prob_X\circ g^{-1}$이다.
\end{theorem}

\begin{proof}
    임의의 $A\in\mathcal{B}_n$에 대해 $\prob_{g(X)}(A)=\mathbb{P}((g\circ X)^{-1}(A))=\mathbb{P}(X^{-1}(g^{-1}(A)))=\prob_X(g^{-1}(A))=(\prob_X\circ g^{-1})(A)$이므로 $\prob_{g(X)}=\prob_X\circ g^{-1}$이다.
\end{proof}

자연스러운 다음 순서는 고등학교 시절부터 들어와 이름만은 익숙한 이산확률변수와 연속확률변수를 엄밀하게 측도론의 언어로 정의하는 것이다. 물론, 고등학교나 교양 통계학에서 각각을 정의하지 않는 것은 아니지만, 그 정의가 뭔가 어색하고 작위적이라는 느낌을 지우기 힘든데, 아래의 측도론적인 정의는 더할 나위 없이 깔끔하고 명쾌하다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $\prob_X$가 이산측도이면 이때의 \texttt{rv.} $X$를 \textbf{이산확률벡터(\texttt{discrete rv.})}라 한다. 또한, 만약 $\prob_X$가 $\mu_n$에 대해 절대연속이거나 특이연속이면 이때의 \texttt{rv.} $X$를 각각 \textbf{연속확률벡터(\texttt{continuous rv.})} 혹은 \textbf{특이확률벡터(\texttt{singular rv.})}라 한다. 특별히, $n=1$인 경우 이산확률벡터, 연속확률벡터, 특이확률벡터를 각각 \textbf{이산확률변수}, \textbf{연속확률변수}, \textbf{특이확률변수}라 한다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 이는 이산확률벡터, 연속확률벡터, 특이확률벡터의 정의 중에서 두 개의 이상을 동시에 만족시킬 수 없다.
\end{proposition}

\begin{proof}
    모순을 유도하기 위해 $X$가 이산확률벡터인 동시에 연속확률벡터라고 하자. 그렇다면 $\prob_X$는 가산 지지집합 $A\in\mathcal{B}_n$를 가지는데, $\mu_n(A)=0$에서 $\prob_X(A)=0$의 모순이 발생한다. 이번에는 $X$가 이산확률벡터인 동시에 특이확률벡터라 하자. 그렇다면 이건과 같이 $\prob_X$는 가산 지지집합 $A\in\mathcal{B}_n$를 가지는데, 이의 가산개의 원소를 $x_1,\,x_2,\,\cdots$와 같이 나열하면 $\prob_X(A)=\sum_{i=1}^k\prob_X\{x_i\}=0$에서 모순이 발생한다. (여기서 $k$는 유한할 수도 있고, $\infty$일 수도 있다.) 마지막으로 $X$가 연속확률벡터인 동시에 특이확률벡터라 하면 $\prob_X\ll\mu_n$이고 $\prob_X\perp\mu_n$이므로 $\prob_X=0$의 모순이 발생하고, 증명은 이로써 충분하다.
\end{proof}

일반적으로, 어떤 \texttt{rv.}가 이산인지, 연속인지, \texttt{singular}인지는 확률측도 $\mathbb{P}$와 \texttt{rv.} $X$ 모두에 의해 결정되는 것이지, 이 중 어느 하나에 의해 일방적으로 결정되는 것이 아니다. 즉, 둘 중 어느 하나만 보고서 $X$가 이산인지, 연속인지, \texttt{singular}인지는 알 수 없다. 이로 말미암아 우리가 \texttt{rv.}에 대해 당연하게 생각하던 사실들에 미묘한 혼동이 생겨나게 된다.

우선 $X$가 이산확률벡터이지만 그 치역은 가산이 아닐 수 있다. 물론, 대부분의 응용에서는 이산확률변수의 치역도 가산으로 주어지지만, 이는 우연의 일치 그 이상도 이하도 아니다. 극단적인 예시로 가측공간 $(\mathbb{R},\,\mathcal{B}_1)$ 위의 측도 $\mathbb{P}$를
\begin{equation*}
    \mathbb{P}:A\mapsto
    \begin{dcases*}
        1&when $0\in A$\\
        0&ow.
    \end{dcases*}
\end{equation*}
으로 잡아 확률공간 $(\mathbb{R},\,\mathcal{B}_1,\,\mathbb{P})$를 구성하고 \texttt{rv.} $X:\mathbb{R}\to\mathbb{R}$를 항등함수로 두면 명백히 $X$는 모든 실수를 그 함숫값으로 가지고 심지어 연속이지만, 분포 $\prob_X$가 한원소 집합 $\{0\}$을 지지집합으로 가지므로 $X$는 이산확률벡터이다. 다만, 정의로부터 분포가 가산 지지집합을 가지므로 $X$가 그 가산개의 값을 제외한 나머지 값을 가질 확률이 $0$이 되어 `사실상' 치역이 가산이라고 생각할 수는 있다. 하지만 영집합과 공집합이 비슷하지만 완전히 같지는 않은 것처럼 이 경우에도 `사실상' 치역이 가산인 것과 치역이 정말 가산인 것은 구분해야 할 것이다.

비슷하게, $X$가 연속확률벡터이지만 함수로서 연속이 아닐 수 있다. 애초에 표본공간 $\Omega$에 위상구조가 존재한다는 보장이 없으므로 연속성을 논할 수조차 없다. 그렇다고 표본공간에 위상구조가 적당히 정의되어 있고, 이에 대해 $X$가 연속이라고 해서 이가 연속확률변수냐 하면 이것 또한 아니다. 앞서 든 예시를 생각해보면 표본공간이 $\mathbb{R}$이고 이 위에 표준위상을 잡더라도 $X$가 연속이지만 연속확률변수가 아닐 수 있다. 다만, 정의로부터 연속확률벡터와 특이확률벡터는 \texttt{point mass}를 가질 수 없으므로 확률이 표본공간의 어느 한 점에 집중되어 있지 않고 전체에 고르게 퍼져 있으니, 이런 의미에서 `연속'이라 생각할 수는 있다.

한편, 위의 정의에서 고등학교나 교양 통계학에서는 들어보지 못한 특이확률벡터라는 새로운 종류의 \texttt{rv.}가 등장했다. 다른 두 종류의 \texttt{rv.}는 고등학교 수준에서도 접할 수 있는 반면, 이제서야 특이확률벡터를 도입하는 것에는 그럴만한 이유가 있다. 우선 특이확률벡터는 다분히 이론적인 필요에 의한 \texttt{rv.}로 실생활의 응용에서는 거의 쓸모가 없다. 또한, 이산확률변수나 연속확률변수의 경우 기댓값이나 분산과 같은 개념의 도입과 계산이 쉬운 반면, 특이확률변수의 경우 이에 상당한 이론적 뒷받침이 필요하다. 이런 이유에서 이 책에서도 특이확률변수가 구체적인 예시로 주어지는 것은 이후에 배울 \texttt{Cantor} 분포 하나 뿐이다. 그렇다면 이런 단점에도 불구하고 특이확률벡터를 도입해야 할 이론적인 필요가 대체 무엇인가? 다음 정리는 이 질문에 대한 답이자 측도론의 에필로그에서 예고한 이번 절의 클라이막스이다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$ 위의 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 다음의 조건
    \begin{enumerate}
        \item \texttt{Rv.} $X_\mathrm{ac}:\mathbb{R}^n\to\mathbb{R}^n$는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{ac})$에서 정의된 연속확률벡터이다.
        \item \texttt{Rv.} $X_\mathrm{pp}:\mathbb{R}^n\to\mathbb{R}^n$는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{pp})$에서 정의된 이산확률벡터이다.
        \item \texttt{Rv.} $X_\mathrm{sc}:\mathbb{R}^n\to\mathbb{R}^n$는 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{sc})$에서 정의된 특이확률벡터이다.
    \end{enumerate}
    를 만족하는 적당한 $\mathcal{B}_n$ 위의 확률측도 $\mathbb{P}_\mathrm{ac},\,\mathbb{P}_\mathrm{pp},\,\mathbb{P}_\mathrm{sc}$와 \texttt{rv.} $X_\mathrm{ac},\,X_\mathrm{pp},\,X_\mathrm{sc}$가 존재하여 $\alpha+\beta+\gamma=1$인 적당한 $\alpha,\,\beta,\,\gamma\geq0$에 대해 $\prob_X=\alpha\prob_{X_\mathrm{ac}}+\beta\prob_{X_\mathrm{pp}}+\gamma\prob_{X_\mathrm{sc}}$이다.
\end{theorem}

\begin{proof}
    정리 \ref{prop:rvProbSpace}로부터 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\prob_X)$가 확률공간이므로 \texttt{Lebesgue}의 분해정리로부터 $\prob_X$는 절대연속성분 $(\prob_X)_\mathrm{ac}$, 순수 점 성분 $(\prob_X)_\mathrm{pp}$, 특이연속성분 $(\prob_X)_\mathrm{sc}$에 대해 $\prob_X=(\prob_X)_\mathrm{ac}+(\prob_X)_\mathrm{pp}+(\prob_X)_\mathrm{cs}$와 같이 분해된다. 또한, $\prob_X(\mathbb{R}^n)=1$이므로 $\alpha=(\prob_X)_\mathrm{ac}(\mathbb{R}^n),\,\beta=(\prob_X)_\mathrm{pp}(\mathbb{R}^n),\,\gamma=(\prob_X)_\mathrm{cs}(\mathbb{R}^n)$라 하면 $\alpha,\,\beta,\,\gamma$는 모두 유한하고 $\alpha+\beta+\gamma=1$이다. 이제 $\alpha,\,\beta,\,\gamma$가 모두 $0$이 아닌 특별한 경우를 생각해보자. 그렇다면 $\mathbb{P}_1:=(\prob_X)_\mathrm{ac}/\alpha,\,\mathbb{P}_2:=(\prob_X)_\mathrm{pp}/\beta,\,\mathbb{P}_3:=(\prob_X)_\mathrm{cs}/\gamma$가 모두 $\mathcal{B}_n$ 위의 확률측도이므로 $(\prob_X)_\mathrm{ac},\,(\prob_X)_\mathrm{pp},\,(\prob_X)_\mathrm{cs}$의 성질과 정리 \ref{thm:probSpaceRv}로부터 적당한 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{ac})$에서 정의된 연속확률벡터 $X_\mathrm{ac}:\mathbb{R}^n\to\mathbb{R}^n$, 적당한 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{pp})$에서 정의된 이산확률벡터 $X_\mathrm{pp}:\mathbb{R}^n\to\mathbb{R}^n$, 적당한 확률공간 $(\mathbb{R}^n,\,\mathcal{B}_n,\,\mathbb{P}_\mathrm{sc})$에서 정의된 특이확률벡터 $X_\mathrm{cs}:\mathbb{R}^n\to\mathbb{R}^n$가 존재하여 $\mathbb{P}_1=\prob_{X_\mathrm{ac}},\,\mathbb{P}_2=\prob_{X_\mathrm{pp}},\,\mathbb{P}_3=\prob_{X_\mathrm{cs}}$이고, 곧 $\prob_X=(\prob_X)_\mathrm{ac}+(\prob_X)_\mathrm{pp}+(\prob_X)_\mathrm{cs}=\alpha\mathbb{P}_1+\beta\mathbb{P}_2+\gamma\mathbb{P}_3=\alpha\prob_{X_\mathrm{ac}}+\beta\prob_{X_\mathrm{pp}}+\gamma\prob_{X_\mathrm{cs}}$이다. 한편, $\alpha,\,\beta,\,\gamma$ 중에 일부가 $0$인 경우에 대해서도 이와 비슷하게 하면 된다.
\end{proof}

연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 분류가 서로 배타적인 관계인 것은 맞지만 그렇다고 임의의 \texttt{rv.}가 반드시 이 셋 중 하나에 속하는 것은 아니다. 즉, \texttt{rv.} 중에는 연속도, 이산도, \texttt{singular}도 아닌 골치아픈 것들이 존재한다. (이런 \texttt{rv.}를 흔히 \textbf{\texttt{mixed type}}이라 부르며 특이확률벡터에 비할 바는 아니지만 그 실용성은 많이 떨어지는 편이다.) 이런 상황에서 위의 정리는 임의의 \texttt{rv.}에 대해 비록 이가 \texttt{mixed type}이더라도 그 분포는 적당한 연속확률벡터, 이산확률벡터, 특이확률벡터의 분포의 합으로 분해할 수 있다는 놀라운 결과를 함의한다. 곧 연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 분류는 \texttt{rv.}의 공간의 기저와 비슷한 역할을 하며, 이 세 가지 \texttt{rv.}를 정의한 순간 사실상 모든 \texttt{rv.}의 분류를 끝마친 것과 다름없다.

이러한 이유로 이론 전개에 있어서는 \texttt{mixed type rv.}를 고려할 필요 없이 연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 \texttt{rv.}만 생각하면 되고, \texttt{mixed type rv.}는 이 세 종류의 \texttt{rv.}의 성질들을 적당히 섞어 가질 뿐이다. 이러니 고등학교 시절부터 연속확률벡터, 이산확률벡터의 두 가지 종류에만 지대한 관심을 가진 것이 너무나 당연하다. 이론적으로 다루기 힘든 특이확률벡터를 제외하면 이 둘을 다룸으로써 우리는 고등학교때부터 우리도 모르는 사이에 사실상 온갖 종류의 \texttt{rv.}를 모두 다루고 있던 셈이다!

이제 클라이막스의 여운을 뒤로 하고, \texttt{CDF}를 살펴볼 순서이다. 흔히 교양 통계학에서는 \texttt{PDF}를 배운 뒤 \texttt{CDF}를 배우므로 \texttt{PDF}의 개념을 도입하지도 않고 \texttt{CDF}를 정의하는 것이 의아할 수 있다. 하지만, 적어도 이론적으로는 \texttt{CDF}가 \texttt{PDF}보다 더 기본적인 개념이기에 이를 먼저 도입한다.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 \texttt{rv.} $X$의 \textbf{(누적)분포함수((\texttt{cumulative}) \texttt{distribution function})}를 $F_X:\mathbb{R}^n\to\mathbb{R}$로 쓰고 $F_X:x\mapsto\prob_X(\prod_{i=1}^n(-\infty,\,x_i])$로 정의한다. 특별히, $n\geq2$인 경우 $F_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합(누적)분포함수(\texttt{joint} (\texttt{cumulative}) \texttt{distribution function})}라 하고 $F_{X_1,\,\cdots,\,X_n}$으로 쓰기도 한다.
\end{definition}

\texttt{CDF}의 기본적인 성질은 정리 \ref{thm:distributionProp}로부터 대부분 자명하게 유도된다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $0\leq F_X\leq 1$.
        \item 임의의 유계인 \texttt{semi-open box} $B\subseteq\mathbb{R}^n$에 대해 $\Delta_BF_X=\prob_X(B)\geq0$이다.
        \item \texttt{CDF} $F_X$는 각 변수에 대해 증가한다.
        \item \texttt{CDF} $F_X$는 오른쪽 연속이다.
        \item 각 $i\leq n$에 대해 $\lim_{x_i\to-\infty}F_X(x)=0$이다.\footnotemark
        \item $\lim_{x_1,\,\cdots,\,x_n\to\infty}F_X(x)=1$.\footnotemark
        \item 임의의 $x\in\mathbb{R}^n$에 대해 $B_x=\prod_{i=1}^n(-\infty,\,x_i]$라 하면 $F_X(x-)=\prob_X(B_x^\circ)$이고 $F_X(x)-F_X(x-)=\prob_X(\partial B_x)$이다.\footnotemark
    \end{enumerate}
\end{theorem}

\begin{proof}
    i - vi. 이는 \texttt{CDF}의 정의와 정리 \ref{thm:distributionProp}로부터 자명하다.
    
    vii. 임의의 $x\in\mathbb{R}^n$를 택하여 $B=\prod_{i=1}^n(-\infty,\,x_i]$라 하고, 집합열 $\{B_j\}$를 $B_j:=\prod_{i=1}^n(-\infty,\,x_i-1/j]$로 두면 이는 $\mathcal{S}_n$에 속하는 증가하는 집합열로서 $B_j\uparrow\prod_{i=1}^n(-\infty,\,x_i)=B^\circ$이다. 따라서 $F_X(x-\ind/j)=\prob_X(B_j)\uparrow\prob_X(B^\circ)$이므로 임의의 $\epsilon>0$을 택하면 적당한 $j_0\in\mathbb{N}$가 존재하여 $\prob_X(B^\circ)-\prob_X(B_{j_0})<\epsilon$이다. 이제 $\delta=1/j_0$라 하면 $||x-y||<\delta$이고 $x>y$인 모든 $y\in\mathbb{R}^n$에 대해 $B_{j_0}\subseteq\prod_{i=1}^n(-\infty,\,y_i)\subseteq B^\circ$에서 $\prob_X(B^\circ)-\epsilon<\prob_X(B_{j_0})\leq F_X(y)=\prob_X(\prod_{i=1}^n(-\infty,\,y_i])\leq\prob_X(B^\circ)$이므로 $|F_X(y)-\prob_X(B^\circ)|<\epsilon$가 되어 $F_X(x-)=\prob_X(B_x^\circ)$임을 안다. 이제 $F_X(x)-F_X(x-)=\prob_X(B)-\prob_X(B^\circ)=\prob_X(\partial B)$임은 자명하다.
\end{proof}

위의 정리에서 $n=1$인 경우 vii는 $F_X(x)-F_X(x-)=\prob_X\{x\}$가 되어 이 경우에는 \texttt{CDF}를 분포의 \texttt{point mass}를 구하는 용도로 사용할 수 있다. 한편, 위의 정리의 역 비슷한 정리도 성립한다.

\begin{theorem}
    함수 $F:\mathbb{R}^n\to[0,\,1]$에 대해 이가
    \begin{enumerate}
        \item 함수 $F$는 오른쪽 연속이고 각 변수에 대해 증가한다.
        \item 유계인 \texttt{semi-open box} $B\subseteq\mathbb{R}^n$에 대해 $\Delta_BF\geq0$이다.
        \item 각 $i\leq n$에 대해 $\lim_{x_i\to-\infty}F(x)=0$이고 $\lim_{x_1,\,\cdots,\,x_n\to\infty}F_X(x)=1$이다.
    \end{enumerate}
    를 만족하면 적당한 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$가 존재하여 $F=F_X$이다. 특별히, 이때 $(\Omega,\,\mathcal{F})=(\mathbb{R}^n,\,\mathcal{B}_n)$이도록 잡을 수 있다.
\end{theorem}

\begin{proof}
    정리 \ref{thm:finiteBorelSpecify}로부터 적당한 $\mathcal{B}_n$ 위의 측도 $\mu$가 존재하여 임의의 $x\in\mathbb{R}^n$에 대해 $F(x)=\mu(\prod_{i=1}^n(-\infty,\,x_i])$이다. 그런데 정리 \ref{thm:distributionProp}의 vii와 주어진 조건으로부터 $\mu(\mathbb{R}^n)=1$이 되어 $\mu$는 확률측도이고, 곧 정리 \ref{thm:probSpaceRv}로부터 적당한 확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$ 위의 $n$차원 \texttt{rv.} $X$가 존재하여 $\mu=\prob_X$이다. 이상으로부터 임의의 $x\in\mathbb{R}^n$에 대해 $F(x)=\mu(\prod_{i=1}^n(-\infty,\,x_i])=\prob_X(\prod_{i=1}^n(-\infty,\,x_i])=F_X(x)$가 성립한다. 한편, 이때 $(\Omega,\,\mathcal{F})=(\mathbb{R}^n,\,\mathcal{B}_n)$이도록 잡을 수 있음은 정리 \ref{thm:probSpaceRv}로부터 자명하다.
\end{proof}

곧 우리는 \texttt{CDF}가 될 수 있는 함수를 위의 정리의 조건 i - iii으로 완벽히 \texttt{characterize}할 수 있다. 한편, \texttt{CDF}의 연속성에 대한 다음 정리들도 꽤나 흥미롭다.

\begin{theorem}\label{thm:CDFContinuous}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 한 점 $x_0\in\mathbb{R}^n$ 대해 $B_{x_0}=\prod_{i=1}^n(-\infty,\,x_0^i]$라 하면 \texttt{TFAE}.
    \begin{enumerate}
        \item \texttt{CDF} $F_X$가 $x_0$에서 연속이다.
        \item $F_X(x_0)=\prob_X(B_{x_0})=\prob_X(B_{x_0}^\circ)$.
        \item $\prob_X(\partial B_{x_0})=0$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i $\Rightarrow$ ii. 집합열 $\{A_j\}$를 $A_j=\prod_{i=1}^n(-\infty,\,x_0^i-1/j]$로 두면 이는 $B_{x_0}^\circ$로 수렴하는 증가하는 집합열이므로 $F_X(x_0-\ind/j)=\prob_X(A_j)\uparrow\prob_X(B_{x_0}^\circ)$이다. 한편, 가정으로부터 $F_X$가 $x_0$에서 연속이므로 $\prob_X(A_j)=F_X(x_0-\ind/j)\uparrow F_X(x_0)=\prob_X(B_{x_0})$가 되어 $F_X(x_0)=\prob_X(B_{x_0})=\prob_X(B_{x_0}^\circ)$임을 안다.

    ii $\Rightarrow$ iii. 이는 $\prob_X(\partial B_{x_0})=\prob_X(B_{x_0})-\prob_X(B_{x_0}^\circ)=0$에서 자명하다.

    iii $\Rightarrow$ i. $0$으로 수렴하는 $\mathbb{R}^n$에 속하는 임의의 수열 $\{h_j\}$를 택하여 각 $j\in\mathbb{N}$에 대해 $a_j=\min_{i=1}^nh_j^i,\,b_j=\max_{i=1}^nh_j^i$라 하면 $F_X(x_0+a_j\ind)\leq F_X(x_0+h_j)\leq F_X(x_0+b_j\ind)$이고 $a_j,\,b_j\to 0$이다. 따라서 함수 $f:\mathbb{R}\to[0,\,1]$를 $f:x\mapsto F_X(x_0+x\ind)$로 두고 이가 $0$에서 연속임을 보이는 것으로 증명은 충분한데, \texttt{CDF}의 성질로부터 $\lim_{x\downarrow0}f(x)=f(0)$임은 이미 알고 있으므로 $\lim_{x\uparrow0}f(x)=f(0)$이라는 사실만 보이면 된다. 이를 위해 $x_j\uparrow0$인 임의의 실수열 $\{x_j\}$를 택하여 집합열 $\{A_j\}$를 $A_j=\prod_{i=1}^n(-\infty,\,x_0^i+x_j^i]$로 두면 이는 $B_{x_0}^\circ$로 수렴하는 증가하는 집합열이다. 그렇다면 가정으로부터 $f(x_j)=F_X(x_0+x_j\ind)=\prob_X(A_j)\uparrow\prob_X(B_{x_0}^\circ)=\prob_X(B_{x_0})=F_X(x_0)=f(0)$이고, 증명이 끝난다.
\end{proof}

\begin{lemma}
    단조함수 $f:\mathbb{R}\to\mathbb{R}$는 가산개의 불연속점만을 가진다.
\end{lemma}

\begin{proof}
    우선 $f$가 증가함수라 하고 집합 $A=\{x\in\mathbb{R}:f\textrm{가 $x$에서 불연속}\}$를 생각하자. 그렇다면 임의의 $x\in A$에 대해 $f(x-)<f(x+)$이므로 $f(x-)<p_x<f(x+)$인 적당한 $p_x\in\mathbb{Q}$를 택할 수 있고, 이로써 함수 $g:A\to\mathbb{Q}$를 $g:x\mapsto p_x$로 두자. 한편, 임의의 $x,\,y\in A$에 대해 $x<y$인데 $f(y-)<f(x+)$이면 $z=(x+y)/2$에 대해 $f(z)\leq f(y-)<f(x+)\leq f(z)$의 모순이 발생하므로 $(f(x-),\,f(x+))$와 $(f(y-),\,f(y+))$는 서로소가 되어 $g$는 단사이고, 곧 $A$는 가산이다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 $F_X$의 연속점의 집합은 조밀하다. 나아가, $n=1$인 경우 $F_X$가 가산개의 불연속점만을 가진다.
\end{theorem}

\begin{proof}
    임의의 $x_0\in\mathbb{R}^n$를 택하여 함수 $f:\mathbb{R}\to[0,\,1]$를 $f:h\mapsto F_X(x_0+h\ind)$로 두자. 그렇다면 $f$는 증가함수가 되어 위의 보조정리로부터 가산개의 불연속점만을 가지고, 곧 $0$으로 수렴하면서 각 점에서 $f$가 연속인 실수열 $\{h_i\}$를 적당히 택할 수 있다. 이는 각 $i\in\mathbb{N}$에 대해 $\prob_X(\prod_{i=1}^n(-\infty,\,x_0^i+h_i))=F_X((x_0+h_i\ind)-)=f(h_i-)=f(h_i)=F_X(x_0+h_i\ind)$임을 함의하므로 정리 \ref{thm:CDFContinuous}로부터 $F_X$는 $x_0+h_i\ind$에서 연속이고, $x_0+h_i\ind\to x_0$임은 자명하므로 $F_X$의 연속점의 집합이 조밀함을 안다. 한편, $n=1$인 경우에는 $F_X$가 증가함수이므로 다시 위의 보조정리로부터 가산개의 불연속점만을 가짐이 자명하다.
\end{proof}

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 적당한 $\mathcal{B}_n$ 위의 $\sigma$-유한 측도 $\mu$가 존재하여 $\prob_X\ll\mu$라 하자. 이때 \texttt{Radon-Nikod\'ym} 도함수 $d\prob_X/d\mu$를 $X$의 $\mu$에 대한 \textbf{(확률)밀도함수((\texttt{probability}) \texttt{density function})}라 하고 $f_X$로 쓴다. 특별히, $n\geq2$인 경우 $f_X$를 \texttt{rv.} $X_1,\,\cdots,\,X_n$의 \textbf{결합(확률)밀도함수(\texttt{joint} (\texttt{probability}) \texttt{density function})}라 하고 $f_{X_1,\,\cdots,\,X_n}$으로 쓰기도 한다.
\end{definition}

이렇게 \texttt{Radon-Nikod\'ym} 도함수로 \texttt{PDF}를 정의하면서 이번에도 우리가 \texttt{PDF}에 대해 당연하게 생각하던 사실들에 미묘한 균열이 생겨나게 된다. 우선, \texttt{Radon-Nikod\'ym} 도함수가 유일하기는 하지만 그 유일성이 `$\mu$-거의 어디서나 같은 함수를 하나로 볼 때' 성립하는 것이므로 엄밀히는 유일하지 않다. 즉, $\mu$-영집합에서 조금씩 다른 무한히 많은 함수들이 모두 하나의 \texttt{rv.}의 \texttt{PDF}가 될 수 있으므로 일반적으로 특정 점에서의 \texttt{PDF}의 값을 물어보는 것은 의미가 없다. 그러나 \texttt{Radon-Nikod\'ym} 도함수를 추상적인 도구로만 사용했던 측도론에서와 달리 확률론에서는 \texttt{PDF}를 구체적인 함수로 다루어야 할 필요가 있으므로 혼란을 피하기 위해 \texttt{PDF}가 될 수 있는 무한히 많은, $\mu$-거의 어디서나 같은 함수 중 특정한 하나를 \texttt{PDF}의 \textbf{\texttt{version}}이라 한다. 물론, 표기상의 편의를 이유로 논의의 대상이 \texttt{PDF}인지, \texttt{PDF}의 \texttt{version}인지를 명시적으로 밝히지 않는 경우가 대부분이지만, $L^p$ 공간에서 동치류로서의 $f$와 구체적인 함수 $f$를 논의의 맥락으로 큰 혼란 없이 구분하였듯이 이 둘 또한 구분에 큰 어려움은 없을 것이다.

다음으로, 지금까지는 연속확률벡터와 이산확률벡터에 대해서만 \texttt{PDF}를 생각했지만 위의 정의에서 볼 수 있듯이 임의의 \texttt{rv.}에 대해서도 $\prob_X\ll\mu$인 $\sigma$-유한 측도 $\mu$만 잘 잡아주면 얼마든지 $X$의 \texttt{PDF}를 생각할 수 있다. 한편, 연속확률벡터, 이산확률벡터, 특이확률벡터의 세 가지 \texttt{rv.}만 생각해도 충분하다는 사실에 놀라워했던 것이 불과 몇 페이지 전인데 굳이 또 이렇게 지나칠 정도록 일반적으로 \texttt{PDF}를 도입하는 것에 의문이 들 수도 있다. 그러나 이는 \texttt{mixed-type rv.}의 \texttt{PDF}를 직접 다루기 위함이 아니라 연속확률벡터와 이산확률벡터의 \texttt{PDF}를 동시에 다루기 위함이다. 고등학교나 교양 통계학에서 연속확률벡터와 이산확률벡터의 기댓값이나 분산 같은 성질들을 논할 때, 각각 경우를 나누어 전자는 적분으로, 후자는 합으로 접근했던 것을 기억할 것이다. 우리는 이런 일반적인 \texttt{PDF}와 측도론의 에필로그에서 소개한 셈측도를 이용해 드디어 이런 번거로움에서 벗어날 수 있다.

정의에서 볼 수 있듯이 $\prob_X\ll\mu$인 $\sigma$-유한 측도 $\mu$를 무엇으로 택하는지에 따라 그 \texttt{PDF}가 달라지므로 $\mu$를 반드시 명시해 주어야 하는데, 우리가 주로 다룰 연속확률벡터와 이산확률벡터의 경우 이에 대한 관례가 있다. 먼저 연속확률벡터 $X:\Omega\to\mathbb{R}^n$의 경우 그 정의상 $\prob_X\ll\mu_n$이 항상 성립하므로 특별한 언급이 없는 이상 연속확률벡터의 \texttt{PDF}는 $\mu_n$에 대한 \texttt{PDF}로 생각한다. 이산확률벡터 $X:\Omega\to\mathbb{R}^n$의 경우는 조금 복잡한데, 우선 정의상 $\prob_X$는 가산 지지집합 $A\in\mathcal{B}_n$를 가진다. 물론, 이때의 가산 지지집합은 유일하지 않지만 임의의 $x\in A$에 대해 $\prob_X\{x\}>0$이라는 조건을 추가하면 유일성하게 주어진다. 한편, $\prob_X\ll\#_A$임이 자명하고, 이때 셈측도의 제한 $\#_A$가 $\sigma$-유한임도 자명하므로 특별한 언급이 없는 이상 이산확률벡터의 \texttt{PDF}는 $\#_A$에 대한 \texttt{PDF}로 생각한다. 나아가, 이산확률벡터의 경우 \texttt{PDF}의 \texttt{version}으로 특별한 언급이 없는 이상 $\mathbb{R}^n\setminus A$에서 $0$인 \texttt{version}을 택하는 관례도 있다. 이런 관례를 따르면 이때의 \texttt{PDF}가 바로 우리가 기존에 알던 \texttt{PMF}라는 사실을 잠시 후에 알게 될 것이다.

이제 \texttt{PDF}의 기본적인 성질들을 보자.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$에 대해 적당한 $\mathcal{B}_n$ 위의 $\sigma$-유한 측도 $\mu$가 존재하여 $\prob_X\ll\mu$라 하자. 그렇다면 $\mu$에 대한 $X$의 \texttt{PDF} $f_X$에 대해 다음이 성립한다.
    \begin{enumerate}
        \item $f_X\geq0$ ($\mu$-\texttt{ae.}).
        \item $\int_{\mathbb{R}^n}f_X\,d\mu=1$.
        \item 임의의 $A\in\mathcal{B}_n$에 대해 $\int_Af_X\,d\mu=\prob_X(A)=\mathbb{P}\{X\in A\}$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    iii. 이는 $\int_Af_X\,d\mu=\int_A(d\prob_X/d\mu)\,d\mu=\int_A\,d\prob_X=\prob_X(A)$에서 자명하다.

    i. 만약 $f_X\geq0$ ($\mu$-\texttt{ae.})가 아니라면 집합 $A=\{x\in\mathbb{R}^n:-f_X(x)>0\}$이 양의 측도를 가지므로 iii과 따름정리 \ref{cor:zeroAeIntegral}의 iii으로부터 $\prob_X(A)=\int_Af_X\,d\mu<0$의 모순이 발생한다. 따라서 $f_X\geq0$ ($\mu$-\texttt{ae.})이어야 한다.
    
    ii. iii으로부터 $\int_{\mathbb{R}^n}f_X\,d\mu=\prob_X(\mathbb{R}^n)=1$이므로 자명하다.
\end{proof}

특별히, 이산확률벡터의 경우 위의 정리는 다음 따름정리와 같이 합의 형태로 표현된다.

\begin{corollary}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 이산확률벡터 $X:\Omega\to\mathbb{R}^n$에 대해 $A\in\mathcal{B}_n$를 $\prob_X$의 가산 지지집합이라 하고 임의의 $x\in A$에 대해 $\prob_X\{x\}>0$이라 하면 다음이 성립한다.
    \begin{enumerate}
        \item 임의의 $x\in\mathbb{R}^n$에 대해 $f_X(x)=\prob_X\{x\}$이고, 따라서 $0\leq f_X\leq1$이다.
        \item $\sum_{x\in\mathbb{R}^n}f_X(x)=1$.
        \item 임의의 $B\in\mathcal{B}_n$에 대해 $\sum_{x\in B}f_X(x)=\prob_X(B)=\mathbb{P}\{X\in B\}$이다.
    \end{enumerate}
\end{corollary}

\begin{proof}
    표기의 편의를 위해 $\mathcal{A}=\mathcal{B}_n\vert_A$라 하면 $\#_A\vert_\mathcal{A}=\#\vert_\mathcal{A}$는 가측공간 $(A,\,\mathcal{A})$ 위의 셈측도이다.

    i. 만약 $x\in A$이면 정리 \ref{thm:intRistriction}의 iii으로부터 $\prob_X\{x\}=\int_{\{x\}}f_X\,d\#_A=\int_{\{x\}}f_X\vert_A\,d\#\vert_\mathcal{A}=f_X(x)$이고 $x\notin A$이면 $f_X$의 \texttt{version}을 택하는 관례로부터 $\prob_X\{x\}=0=f_X(x)$이다.

    ii. 위의 정리와 셈측도의 성질 그리고 $f_X$의 \texttt{version}을 택하는 관례와 정리 \ref{thm:intRistriction}의 iii으로부터 $1=\prob_X(A)=\int_Af_X\,d\#_A=\int_Af_X\vert_A\,d\#\vert_\mathcal{A}=\sum_{x\in A}f_X(x)=\sum_{x\in\mathbb{R}^n}f_X(x)$이다.

    iii. 위의 정리와 셈측도의 성질 그리고 $f_X$의 \texttt{version}을 택하는 관례와 정리 \ref{thm:intRistriction}의 iii으로부터 $\prob_X(B)=\prob_X(A\cap B)=\int_{A\cap B}f_X\,d\#_A=\int_{A\cap B}f_X\vert_A\,d\#\vert_\mathcal{A}=\sum_{x\in A\cap B}f_X(x)=\sum_{x\in B}f_X(x)$이다.
\end{proof}

\section{Expectation}

이번 절에서는 \texttt{rv.}의 대표적인 통계량 중 하나인 기댓값과 분산을 엄밀하게 도입하고, 이와 관련된 부등식을 증명하는 것을 목표로 한다. 통계학의 큰 연구주제 중 하나는 어떤 모집단의 정보를 단순화하여 전달하는 것이라 할 것이다. 물론, 이때 단순화의 정도와 이에 따른 정보의 손실은 서로 \texttt{trade-off}의 관계에 있어서 단순화를 많이 하면 할수록 용이한 정보의 전달이 가능하지만 그만큼 손실되는 정보도 많아지고, 역으로 손실되는 정보의 양을 줄이면 줄일수록 단순화의 정도가 떨어진다. 이런 상황에서 우리는 정보의 손실을 최소한으로 유지하면서도 정보를 단순하게 전달할 수 있는 좋은 방법을 찾고자 하는데, 이번 절에서 알아볼 기댓값은 어떤 분포의 정보를 간단화하여 전달할 수 있는 좋은 방법 중 하나이다. 어떤 \texttt{rv.} $X$의 분포 전체의 정보를 전달하려면 $X$가 정의된 확률공간과 $X$를 모두 전달해주어야 하는데, 이를 기댓값이라는 하나의 숫자로 대신하여 전달하니 엄청난 정도의 단순화를 이루면서도 이 하나의 숫자만으로 $X$의 값으로 기대할 수 있는 값, 즉 $X$가 가지는 가장 그럴싸한 값에 대한 정보를 유추할 수 있고, 나아가 특정 상황에서는 $X$의 분포에 대한 정보도 유추할 수 있는 등 정보의 손실도 크지 않다.

물론, 때로는 기댓값만을 전달하는 상황에서 발생하는 정보의 손실이 받아들일 수 없는 수준일 수도 있다. 이러한 경우에는 추가적인 정보를 전달하여 정보의 손실을 줄이면 되는데, 이대 전달할 수 있는 추가적인 정보 중 하나가 바로 분산이다. 분산은 말 그대로 분포가 퍼져 있는 정도로, \texttt{rv.}가 기댓값에서 벗어나는 값을 가지는 정도에 대한 정보를 추가로 전달해준다.

기본적으로 기댓값은 적분으로 정의되는데, 이로 말미암아 통계학에서는 미분보다 적분을 더 많이 사용하게 된다. 바로 정의를 보자.

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $X$가 적분가능하다면 $\int_\Omega X\,d\mathbb{P}$를 $X$의 \textbf{기댓값(\texttt{expectation})} 혹은 \textbf{평균(\texttt{mean})}이라 하고 $\expect(X),\,\mu_X$ 혹은 간단히 $\mu$로 쓴다.
\end{definition}

기댓값이 정의되기 위해서는 확률공간과 그 위에서 정의된 \texttt{rv.}만 있으면 충분하다는 점에 주목하기 바란다. 고등학교나 교양 통계학에서는 기댓값이 정의되기 위해서는 \texttt{rv.}가 반드시 연속이거나 이산이어서 \texttt{PDF}나 \texttt{PMF}가 있어야 했다. 그러나 위의 정의는 일반적인 \texttt{mixed-type rv.}에 대해서도 기댓값을 정의할 수 있도록 해준다.  한편, 정의에서 볼 수 있듯이 기댓값은 확률측도에 대한 적분의 또다른 이름에 불과하므로 이에 관한 기본적인 성질들은 대부분 적분의 성질들로부터 자명하게 유도된다.

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\expect(X)$가 존재할 필요충분조건은 $\expect(|X|)$가 존재하는 것이다.
\end{proposition}

\begin{proof}
    이는 $X$가 적분가능할 필요충분조건이 $|X|$가 적분가능할 것이라는 점에서 자명하다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$에 대해 $\expect(X),\,\expect(Y)$가 모두 존재한다면 다음이 성립한다.
    \begin{enumerate}
        \item (선형성) 임의의 $a,\,b\in\mathbb{R}$에 대해 $\expect(aX+bY)$가 존재하고 $\expect(aX+bY)=a\expect(X)+b\expect(Y)$이다.
        \item 만약 $X=Y$ (\texttt{as.})라면 $\expect(X)=\expect(Y)$이다.
        \item 만약 $X\leq Y$ (\texttt{as.})라면 $\expect(X)\leq\expect(Y)$이다.
        \item $\expect(1)=1$.
        \item $\inf_{\omega\in\Omega}X(\omega)\leq\expect(X)\leq\sup_{\omega\in\Omega}X(\omega)$.
        \item $|\expect(X)|\leq\expect(|X|)$.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i - iii, vi. 이는 적분의 성질로부터 자명하다.

    iv. 이는 $\expect(1)=\int_\Omega\,d\mathbb{P}=\mathbb{P}(\Omega)=1$에서 분명하다.

    v. 이는 iii과 iv로부터 자명하다.
\end{proof}

비록 기댓값을 아주 일반적으로 도입했지만 이 정의는 기댓값을 실질적으로 계산하는 데에는 큰 도움이 안된다. 이에 기댓값을 구체적으로 구할 수 있도록 해 주는 방법이 필요하다. 그리고 그 방법의 열쇠는 바로 \texttt{PDF}이다.

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 \texttt{Borel} 함수 $g:\mathbb{R}^n\to\mathbb{R}$에 대해 $\expect(g(X))$가 존재한다면(혹은 $g$가 $\prob_X$-적분가능하다면) $\expect(g(X))=\int_{\mathbb{R}^n}g\,d\prob_X$이고, 이때 $g$는 $\prob_X$-적분가능하다(혹은 $\expect(g(X))$가 존재한다).
\end{theorem}

\begin{proof}
    기댓값 $\expect(g(X))$가 존재한다면 $\expect(g(X))=\int_\Omega g\circ X\,d\mathbb{P}=\int_{\mathbb{R}^n}g\,d\prob_X<\infty$이므로 이는 자명하다. 한편, $\prob_X$-적분가능한 $g$에 대해서도 비슷하게 하면 된다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}^n$와 \texttt{Borel} 함수 $g:\mathbb{R}^n\to\mathbb{R}$에 대해 적당한 $\mathcal{B}_n$ 위의 $\sigma$-유한 측도 $\mu$가 존재하여 $\prob_X\ll\mu$라 하자. 만약 $\expect(g(X))$가 존재한다면(혹은 $f_Xg$는 $\mu$-적분가능하다면) $\expect(g(X))=\int_{\mathbb{R}^n}f_Xg\,d\mu$이고, 이때 $f_Xg$는 $\mu$-적분가능하다(혹은 $\expect(g(X))$가 존재한다).
\end{theorem}

\begin{proof}
    기댓값 $\expect(g(X))$가 존재한다면 $\expect(g(X))=\int_{\mathbb{R}^n}g\,d\prob_X=\int_{\mathbb{R}^n}f_Xg\,d\mu<\infty$이므로 이는 자명하다. 한편, $f_Xg$가 $\mu$-적분가능한 경우에 대해서도 비슷하게 하면 된다.
\end{proof}

이산확률벡터의 경우 다음과 같이 적분이 합으로 표현된다.

\begin{corollary}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 이산확률벡터 $X:\Omega\to\mathbb{R}^n$와 \texttt{Borel} 함수 $g:\mathbb{R}^n\to\mathbb{R}$에 대해 $\expect(g(X))$가 존재한다면 $\expect(g(X))=\sum_{x\in\mathbb{R}^n}f_X(x)g(x)$이다.
\end{corollary}

\begin{proof}
    가정으로부터 $\prob_X$의 가산 지지집합 $A\in\mathcal{B}_n$가 존재하여 \texttt{WLOG}, 필요하다면 몇몇 원소를 제거하여 임의의 $x\in A$에 대해 $\prob_X\{x\}>0$이라 해도 된다. 표기의 편의를 위해 $\mathcal{A}=\mathcal{B}_n\vert_A$라 하면 $\#_A\vert_\mathcal{A}=\#\vert_\mathcal{A}$는 가측공간 $(A,\,\mathcal{A})$ 위의 셈측도이므로 위의 정리와 $f_X$의 \texttt{version}을 택하는 관례 그리고 정리 \ref{thm:intRistriction}의 iii으로부터 $\expect(g(X))=\int_{\mathbb{R}^n}f_Xg\,d\#_A=\int_Af_Xg\,d\#_A=\int_A(f_Xg)\vert_A\,d\#\vert_\mathcal{A}=\sum_{x\in A}f_X(x)g(x)=\sum_{x\in\mathbb{R}^n}f_X(x)g(x)$이다.
\end{proof}

\begin{theorem}[Monotone convergence theorem]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 음이 아닌 \texttt{rv.} $X_i:\Omega\to\mathbb{R}^+_0$의 열 $\{X_i\}$와 음이 아닌 \texttt{rv.} $X:\Omega\to\mathbb{R}^+_0$에 대해 $X_i\uparrow X$ (\texttt{as.})이고 $\expect(X)$가 존재한다고 하면 모든 $i\in\mathbb{N}$에 대해 $\expect(X_i)$도 존재하고 $\expect(X_i)\uparrow\expect(X)$이다.
\end{theorem}

\begin{proof}
    모든 $i\in\mathbb{N}$에 대해 $0\leq X_i\leq X$이므로 $\expect(X_i)$가 존재한다. 그렇다면 정리는 측도론에서 배운 \texttt{MCT}에서 자명하다.
\end{proof}

\begin{theorem}[Fatou's lemma]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 음이 아닌 \texttt{rv.} $X_i:\Omega\to\mathbb{R}^+_0$의 열 $\{X_i\}$에 대해 $\liminf_{i\to\infty}\expect(X_i)\geq\expect(\liminf_{i\to\infty}X_i)$이다.
\end{theorem}

\begin{theorem}[Lebesgue's dominated convergence theorem]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X_i:\Omega\to\mathbb{R}$의 열 $\{X_i\}$와 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $X_i\to X$ (\texttt{as.})라 하자. 또한 어떤 \texttt{rv.} $Y:\Omega\to\mathbb{R}^+_0$가 존재하여 $\expect(Y)$가 존재하고 모든 $i\in\mathbb{N}$에 대해 $|X_i|\leq Y$이면 $\expect(X_i)$와 $\expect(X)$가 모두 존재하고 $\expect(X_i)\to\expect(X)$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{DCT}에서 자명하다.
\end{proof}

\begin{corollary}[Bounded convergence theorem]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X_i:\Omega\to\mathbb{R}$의 열 $\{X_i\}$와 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $X_i\to X$ (\texttt{as.})라 하자. 또한 $\{X_i\}$가 균등하게 유계라 하자. 즉, 어떤 $M>0$이 존재하여 모든 $i\in\mathbb{N}$에 대해 $|X_i|\leq M$이라 하자. 그렇다면 $\expect(X_i)$와 $\expect(X)$가 모두 존재하고 $\expect(X_i)\to\expect(X)$이다.
\end{corollary}

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $\expect((X-\mu_X)^2)$이 존재한다면 이를 $X$의 \textbf{분산(\texttt{variance})}이라 하고 $\var(X),\,\sigma_X^2$ 혹은 간단히 $\sigma^2$으로 쓴다. 나아가, $\var(X)$가 존재한다면 $\sqrt{\var(X)}$를 $X$의 \textbf{표준편차(\texttt{standard deviation})}라 하고 $\sd(X),\,\sigma_X$ 혹은 간단히 $\sigma$로 쓴다.
\end{definition}

\begin{proposition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재할 필요충분조건은 $\expect(X^2)$이 존재하는 것이다.
\end{proposition}

\begin{proof}
    만약 $\var(X)$가 존재한다면 정의로부터 $\expect(X)$와 $\expect((X-\mu_X)^2)$가 존재하고, 곧 $X^2=(X-\mu_X)^2+2\mu_XX-\mu_X^2$에서 $\expect(X^2)$이 존재함을 안다. 역으로 $\expect(X^2)$이 존재한다면 $|X|\leq X^2\ind_{\{|X|\geq1\}}+\ind_{\{|X|<1\}}\leq X^2+1$에서 $\expect(X)$가 존재함을 알고,곧 $(X-\mu_X)^2=X^2-2\mu_XX+\mu_X^2$에서 $\var(X)=\expect((X-\mu_X)^2)$이 존재한다.
\end{proof}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재한다면 다음이 성립한다.
    \begin{enumerate}
        \item $\var(X)=\expect(X^2)-\mu_X^2$.
        \item 임의의 $a,\,b\in\mathbb{R}$에 대해 $\var(aX+b)$가 존재하고 $\var(aX+b)=a^2\var(X)$이다.
    \end{enumerate}
\end{theorem}

\begin{proof}
    i. 이는
    \begin{align*}
        \var(X)&=\expect((X-\mu_X)^2)\\
        &=\expect(X^2-2\mu_XX+\mu_X^2)\\
        &=\expect(X^2)-2\mu_X\expect(X)+\mu_X^2\\
        &=\expect(X^2)-\mu_X^2
    \end{align*}
    에서 자명하다.

    ii. 우선 $\var(X)$가 존재하므로 $\expect(X)$와 $\expect(X^2)$이 존재하여 $\expect((aX+b)^2)=\expect(a^2X^2+2abX+b^2)$가 존재하여 $\var(aX+b)$도 존재한다. 이제
    \begin{align*}
        \var(aX+b)&=\expect([aX+b-\expect(aX+b)]^2)\\
        &=\expect(a^2[X-\expect(X)]^2)\\
        &=a^2\expect((X-\mu_X)^2)\\
        &=a^2\var(X)
    \end{align*}
   에서 정리는 자명하다.
\end{proof}

\begin{theorem}[Jensen's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$와 함수 $g:\mathbb{R}\to\mathbb{R}$에 대해 적당한 구간 $I\subseteq\mathbb{R}$가 존재하여 $g$가 $I$에서 볼록하고(혹은 오목하고) $X\in I$ (\texttt{as.})라 하자. 만약 $\expect(X)$와 $\expect(g(X))$가 존재한다면 $g(\expect(X))\leq\expect(g(X))$이다(혹은 $g(\expect(X))\geq\expect(g(X))$이다).
\end{theorem}

\begin{theorem}[H\"older's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$와 $1/p+1/q=1$인 $p,\,q>1$에 대해 $\expect(|X|^p)$와 $\expect(|Y|^q)$가 존재한다면 $\expect(|XY|)$도 존재하고 $\expect(|XY|)\leq[\expect(|X|^p)]^{1/p}[\expect(|Y|^q)]^{1/q}$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{H\"older}의 부등식으로부터 자명하다.
\end{proof}

\begin{corollary}[Cauchy-Schwarz's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X,\,Y:\Omega\to\mathbb{R}$에 대해 $\expect(X^2)$과 $\expect(Y^2)$이 존재한다면 $\expect(|XY|)$도 존재하고 $\expect(|XY|)\leq\sqrt{\expect(X^2)\expect(Y^2)}$이다.
\end{corollary}

\begin{proof}
    이는 위의 \texttt{H\"older}의 부등식에서 $p=q=2$인 특수한 경우이다.
\end{proof}

\begin{theorem}[Liapounov's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 $0<p<q$인 $p,\,q\in\mathbb{R}$에 대해 $\expect(|X|^q)$가 존재한다면 $\expect(|X|^p)$도 존재하고 $[\expect(|X|^p)]^{1/p}\leq[\expect(|X|^q)]^{1/q}$이다.
\end{theorem}

\begin{proof}
    우선 $|X|^p\leq|X|^q\ind_{\{|X|\geq1\}}+\ind_{\{|X|<1\}}\leq|X|^q+1$에서 $\expect(|X|^p)$이 존재함을 안다. 이제 함수 $g:\mathbb{R}\to\mathbb{R}$를 $g:x\mapsto x^{q/p}\ind_{\mathbb{R}^+}(x)$로 두면 이는 볼록함수이므로 \texttt{Jensen}의 부등식으로부터 $[\expect(|X|^p)]^{q/p}=g(\expect(|X|^p))\leq\expect(g(|X|^p))=\expect(|X|^q)$이고, 곧 증명이 끝난다.
\end{proof}

\begin{theorem}[Markov's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 $p>0$에 대해 $\expect(|X|^p)$이 존재한다면 임의의 $x>0$에 대해 $\mathbb{P}\{|X|\geq x\}\leq\expect(|X|^p)/x^p$이다.
\end{theorem}

\begin{proof}
    이는 측도론에서 배운 \texttt{Markov}의 부등식으로부터 자명하다.
\end{proof}

\begin{corollary}[Chebyshev's inequality]
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재한다면 임의의 $x>0$에 대해 $\mathbb{P}\{|X-\mu_X|\geq x\}\leq\var(X)/x^2$이다.
\end{corollary}

\begin{proof}
    이는 \texttt{rv.} $X-\mu_X$에 $p=2$인 경우의 \texttt{Markov}의 부등식을 적용한 결과이다.
\end{proof}

\section{Moments}

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$와 $n\in\mathbb{N}$에 대해 다음을 정의한다.
    \begin{enumerate}
        \item 만약 $\expect(X^n)$이 존재한다면 이를 $X$의 \textbf{$n$차 적률($n$\texttt{th moment})}이라 하고 $\mu_{n,\,X}$ 혹은 간단히 $\mu_n$으로 쓴다.
        \item 만약 $\expect((X-\mu_X)^n)$이 존재한다면 이를 $X$의 \textbf{$n$차 중심화된 적률($n$\texttt{th centeral moment})}이라 하고 $\tau_{n,\,X}$ 혹은 간단히 $\tau_n$으로 쓴다.
        \item 만약 $\expect([(X-\mu_X)/\sigma_X]^n)$이 존재한다면 이를 $X$의 \textbf{$n$차 표준화된 적률($n$\texttt{th standardized moment})}이라 하고 $\kappa_{n,\,X}$ 혹은 간단히 $\kappa_n$으로 쓴다.
        \item 만약 $\expect(X^{\underline{n}})$이 존재한다면 이를 $X$의 \textbf{$n$차 (하향)계승적률($n$\texttt{th} (\texttt{falling}) \texttt{factorial moment})}이라 하고 $\mu_{\underline{n},\,X}$ 혹은 간단히 $\mu_{\underline{n}}$으로 쓴다.
        \item 만약 $\expect(X^{\overline{n}})$이 존재한다면 이를 $X$의 \textbf{$n$차 (상향)계승적률($n$\texttt{th} (\texttt{rising}) \texttt{factorial moment})}이라 하고 $\mu_{\overline{n},\,X}$ 혹은 간단히 $\mu_{\overline{n}}$으로 쓴다.
    \end{enumerate}
\end{definition}

\begin{definition}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 만약 $X$의 3차 표준화된 적률이 존재한다면 이를 특별히 $X$의 \textbf{왜도(\texttt{skewness})}라 하고 $\skew(X),\,\tau_X$ 혹은 간단히 $\tau$로 쓴다. 비슷하게, $X$의 4차 표준화된 적률이 존재한다면 $\kappa_{4,\,X}-3$을 특별히 $X$의 \textbf{첨도(\texttt{kurtosis})}라 하고 $\kurt(X),\,\kappa_X$ 혹은 간단히 $\kappa$로 쓴다.
\end{definition}

\begin{theorem}
    확률공간 $(\Omega,\,\mathcal{F},\,\mathbb{P})$에서 정의된 \texttt{rv.} $X:\Omega\to\mathbb{R}$에 대해 $\var(X)$가 존재한다면 다음이 성립한다.
    \begin{enumerate}
        \item $\var(X)=\expect(X^2)-\mu_X^2$.
        \item 임의의 $a,\,b\in\mathbb{R}$에 대해 $a\ne0$이면 $\skew(aX+b)$가 존재하고 $\skew(aX+b)=\skew(X)/a^3$이다.
        \item 임의의 $a,\,b\in\mathbb{R}$에 대해 $a\ne0$이면 $\kurt(aX+b)$가 존재하고 $\kurt(aX+b)=\kurt(X)/a^4$이다.
    \end{enumerate}
\end{theorem}

\section*{Notes}
\footnotesize
\begin{enumerate}[label = \textsf{\textbf{\arabic*}}]
    \item 여기서 $\lim_{x_i\to-\infty}F_X(x)=0$은 임의의 $\cdots,\,x_{i-1},\,x_{i+1},\,\cdots\in\mathbb{R}$와 임의의 $\epsilon>0$에 대해 적당한 $M\in\mathbb{R}$이 존재하여 $x_i<M$인 임의의 $x_i\in\mathbb{R}$에 대해 $F_X(x)<\epsilon$이라는 의미이다.
    \item 여기서 $\lim_{x_1,\,\cdots,\,x_n\to\infty}F_X(x)=1$은 임의의 $\epsilon>0$에 대해 적당한 $M\in\mathbb{R}$이 존재하여 $x\geq M\ind$인 임의의 $x\in\mathbb{R}^n$에 대해 $|F_\mu(x)-1|<\epsilon$이라는 의미이다.
    \item 집합 $A\subseteq\mathbb{R}^m$에서 정의된 함수 $f:A\to\mathbb{R}^n$와 한 점 $x_0\in\mathrm{acc}\,A$에 대해 극한 $\lim_{x\uparrow x_0}f(x)$가 존재하는 경우 그 값을 $f(x_0-)$로 쓴다. 한편, 여기서 $\lim_{x\uparrow x_0}f(x)=f(x_0-)$는 임의의 $\epsilon>0$에 대해 적당한 $\delta>0$가 존재하여 $||x-x_0||<\delta$이고 $x<x_0$인 임의의 $x\in A$에 대해 $||f(x)-f(x_0-)||<\epsilon$이라는 의미이다. 이제 $f(x_0+)$도 비슷하게 정의된다.
\end{enumerate}